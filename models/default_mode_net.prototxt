#########################
##### part001 label #####
#########################
name: "DENSENET_161"
input: "data"
input_dim: 1
input_dim: 3
input_dim: 224
input_dim: 224
input: "label_008_008_ch068"
input_dim: 1
input_dim: 68
input_dim: 8
input_dim: 8
input: "label_008_008_ch2560"
input_dim: 1
input_dim: 2560
input_dim: 8
input_dim: 8
input: "label_016_016_ch1000"
input_dim: 1
input_dim: 1000
input_dim: 16
input_dim: 16
input: "label_032_032_ch1000"
input_dim: 1
input_dim: 1000
input_dim: 32
input_dim: 32
input: "label_064_064_ch1000"
input_dim: 1
input_dim: 1000
input_dim: 64
input_dim: 64

## Label part
# label 2nd order
layer {
    name: "label_008_008_ch068_inverse"
    bottom: "label_008_008_ch068"
    top: "label_008_008_ch068_inverse"
    type: "Power"
    power_param {
        power: 1
        scale: -1
        shift: 1
    }
}
layer {
    name: "label_008_008_ch2560_inverse"
    bottom: "label_008_008_ch2560"
    top: "label_008_008_ch2560_inverse"
    type: "Power"
    power_param {
        power: 1
        scale: -1
        shift: 1
    }
}
layer {
    name: "label_016_016_ch1000_inverse"
    bottom: "label_016_016_ch1000"
    top: "label_016_016_ch1000_inverse"
    type: "Power"
    power_param {
        power: 1
        scale: -1
        shift: 1
    }
}
layer {
    name: "label_032_032_ch1000_inverse"
    bottom: "label_032_032_ch1000"
    top: "label_032_032_ch1000_inverse"
    type: "Power"
    power_param {
        power: 1
        scale: -1
        shift: 1
    }
}
layer {
    name: "label_064_064_ch1000_inverse"
    bottom: "label_064_064_ch1000"
    top: "label_064_064_ch1000_inverse"
    type: "Power"
    power_param {
        power: 1
        scale: -1
        shift: 1
    }
}

#################################
##### part002 DenseBlock1~4 #####
#################################
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1/bn"
  top: "conv1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1/bn"
  top: "conv1/bn"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1/bn"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv2_1/x1/bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "conv2_1/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_1/x1/scale"
  type: "Scale"
  bottom: "conv2_1/x1/bn"
  top: "conv2_1/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1/x1"
  type: "ReLU"
  bottom: "conv2_1/x1/bn"
  top: "conv2_1/x1/bn"
}
layer {
  name: "conv2_1/x1"
  type: "Convolution"
  bottom: "conv2_1/x1/bn"
  top: "conv2_1/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv2_1/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_1/x1"
  top: "conv2_1/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_1/x2/scale"
  type: "Scale"
  bottom: "conv2_1/x2/bn"
  top: "conv2_1/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1/x2"
  type: "ReLU"
  bottom: "conv2_1/x2/bn"
  top: "conv2_1/x2/bn"
}
layer {
  name: "conv2_1/x2"
  type: "Convolution"
  bottom: "conv2_1/x2/bn"
  top: "conv2_1/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_2_1"
  type: "Concat"
  bottom: "pool1"
  bottom: "conv2_1/x2"
  top: "concat_2_1"
}
layer {
  name: "conv2_2/x1/bn"
  type: "BatchNorm"
  bottom: "concat_2_1"
  top: "conv2_2/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_2/x1/scale"
  type: "Scale"
  bottom: "conv2_2/x1/bn"
  top: "conv2_2/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2/x1"
  type: "ReLU"
  bottom: "conv2_2/x1/bn"
  top: "conv2_2/x1/bn"
}
layer {
  name: "conv2_2/x1"
  type: "Convolution"
  bottom: "conv2_2/x1/bn"
  top: "conv2_2/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv2_2/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_2/x1"
  top: "conv2_2/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_2/x2/scale"
  type: "Scale"
  bottom: "conv2_2/x2/bn"
  top: "conv2_2/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2/x2"
  type: "ReLU"
  bottom: "conv2_2/x2/bn"
  top: "conv2_2/x2/bn"
}
layer {
  name: "conv2_2/x2"
  type: "Convolution"
  bottom: "conv2_2/x2/bn"
  top: "conv2_2/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_2_2"
  type: "Concat"
  bottom: "concat_2_1"
  bottom: "conv2_2/x2"
  top: "concat_2_2"
}
layer {
  name: "conv2_3/x1/bn"
  type: "BatchNorm"
  bottom: "concat_2_2"
  top: "conv2_3/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_3/x1/scale"
  type: "Scale"
  bottom: "conv2_3/x1/bn"
  top: "conv2_3/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_3/x1"
  type: "ReLU"
  bottom: "conv2_3/x1/bn"
  top: "conv2_3/x1/bn"
}
layer {
  name: "conv2_3/x1"
  type: "Convolution"
  bottom: "conv2_3/x1/bn"
  top: "conv2_3/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv2_3/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_3/x1"
  top: "conv2_3/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_3/x2/scale"
  type: "Scale"
  bottom: "conv2_3/x2/bn"
  top: "conv2_3/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_3/x2"
  type: "ReLU"
  bottom: "conv2_3/x2/bn"
  top: "conv2_3/x2/bn"
}
layer {
  name: "conv2_3/x2"
  type: "Convolution"
  bottom: "conv2_3/x2/bn"
  top: "conv2_3/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_2_3"
  type: "Concat"
  bottom: "concat_2_2"
  bottom: "conv2_3/x2"
  top: "concat_2_3"
}
layer {
  name: "conv2_4/x1/bn"
  type: "BatchNorm"
  bottom: "concat_2_3"
  top: "conv2_4/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_4/x1/scale"
  type: "Scale"
  bottom: "conv2_4/x1/bn"
  top: "conv2_4/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_4/x1"
  type: "ReLU"
  bottom: "conv2_4/x1/bn"
  top: "conv2_4/x1/bn"
}
layer {
  name: "conv2_4/x1"
  type: "Convolution"
  bottom: "conv2_4/x1/bn"
  top: "conv2_4/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv2_4/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_4/x1"
  top: "conv2_4/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_4/x2/scale"
  type: "Scale"
  bottom: "conv2_4/x2/bn"
  top: "conv2_4/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_4/x2"
  type: "ReLU"
  bottom: "conv2_4/x2/bn"
  top: "conv2_4/x2/bn"
}
layer {
  name: "conv2_4/x2"
  type: "Convolution"
  bottom: "conv2_4/x2/bn"
  top: "conv2_4/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_2_4"
  type: "Concat"
  bottom: "concat_2_3"
  bottom: "conv2_4/x2"
  top: "concat_2_4"
}
layer {
  name: "conv2_5/x1/bn"
  type: "BatchNorm"
  bottom: "concat_2_4"
  top: "conv2_5/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_5/x1/scale"
  type: "Scale"
  bottom: "conv2_5/x1/bn"
  top: "conv2_5/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_5/x1"
  type: "ReLU"
  bottom: "conv2_5/x1/bn"
  top: "conv2_5/x1/bn"
}
layer {
  name: "conv2_5/x1"
  type: "Convolution"
  bottom: "conv2_5/x1/bn"
  top: "conv2_5/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv2_5/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_5/x1"
  top: "conv2_5/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_5/x2/scale"
  type: "Scale"
  bottom: "conv2_5/x2/bn"
  top: "conv2_5/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_5/x2"
  type: "ReLU"
  bottom: "conv2_5/x2/bn"
  top: "conv2_5/x2/bn"
}
layer {
  name: "conv2_5/x2"
  type: "Convolution"
  bottom: "conv2_5/x2/bn"
  top: "conv2_5/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_2_5"
  type: "Concat"
  bottom: "concat_2_4"
  bottom: "conv2_5/x2"
  top: "concat_2_5"
}
layer {
  name: "conv2_6/x1/bn"
  type: "BatchNorm"
  bottom: "concat_2_5"
  top: "conv2_6/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_6/x1/scale"
  type: "Scale"
  bottom: "conv2_6/x1/bn"
  top: "conv2_6/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_6/x1"
  type: "ReLU"
  bottom: "conv2_6/x1/bn"
  top: "conv2_6/x1/bn"
}
layer {
  name: "conv2_6/x1"
  type: "Convolution"
  bottom: "conv2_6/x1/bn"
  top: "conv2_6/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv2_6/x2/bn"
  type: "BatchNorm"
  bottom: "conv2_6/x1"
  top: "conv2_6/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_6/x2/scale"
  type: "Scale"
  bottom: "conv2_6/x2/bn"
  top: "conv2_6/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_6/x2"
  type: "ReLU"
  bottom: "conv2_6/x2/bn"
  top: "conv2_6/x2/bn"
}
layer {
  name: "conv2_6/x2"
  type: "Convolution"
  bottom: "conv2_6/x2/bn"
  top: "conv2_6/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_2_6"
  type: "Concat"
  bottom: "concat_2_5"
  bottom: "conv2_6/x2"
  top: "concat_2_6"
}
layer {
  name: "conv2_blk/bn"
  type: "BatchNorm"
  bottom: "concat_2_6"
  top: "conv2_blk/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv2_blk/scale"
  type: "Scale"
  bottom: "conv2_blk/bn"
  top: "conv2_blk/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_blk"
  type: "ReLU"
  bottom: "conv2_blk/bn"
  top: "conv2_blk/bn"
}
layer {
  name: "conv2_blk"
  type: "Convolution"
  bottom: "conv2_blk/bn"
  top: "conv2_blk"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_blk"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1/x1/bn"
  type: "BatchNorm"
  bottom: "pool2"
  top: "conv3_1/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_1/x1/scale"
  type: "Scale"
  bottom: "conv3_1/x1/bn"
  top: "conv3_1/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1/x1"
  type: "ReLU"
  bottom: "conv3_1/x1/bn"
  top: "conv3_1/x1/bn"
}
layer {
  name: "conv3_1/x1"
  type: "Convolution"
  bottom: "conv3_1/x1/bn"
  top: "conv3_1/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv3_1/x2/bn"
  type: "BatchNorm"
  bottom: "conv3_1/x1"
  top: "conv3_1/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_1/x2/scale"
  type: "Scale"
  bottom: "conv3_1/x2/bn"
  top: "conv3_1/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_1/x2"
  type: "ReLU"
  bottom: "conv3_1/x2/bn"
  top: "conv3_1/x2/bn"
}
layer {
  name: "conv3_1/x2"
  type: "Convolution"
  bottom: "conv3_1/x2/bn"
  top: "conv3_1/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_3_1"
  type: "Concat"
  bottom: "pool2"
  bottom: "conv3_1/x2"
  top: "concat_3_1"
}
layer {
  name: "conv3_2/x1/bn"
  type: "BatchNorm"
  bottom: "concat_3_1"
  top: "conv3_2/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_2/x1/scale"
  type: "Scale"
  bottom: "conv3_2/x1/bn"
  top: "conv3_2/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2/x1"
  type: "ReLU"
  bottom: "conv3_2/x1/bn"
  top: "conv3_2/x1/bn"
}
layer {
  name: "conv3_2/x1"
  type: "Convolution"
  bottom: "conv3_2/x1/bn"
  top: "conv3_2/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv3_2/x2/bn"
  type: "BatchNorm"
  bottom: "conv3_2/x1"
  top: "conv3_2/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_2/x2/scale"
  type: "Scale"
  bottom: "conv3_2/x2/bn"
  top: "conv3_2/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_2/x2"
  type: "ReLU"
  bottom: "conv3_2/x2/bn"
  top: "conv3_2/x2/bn"
}
layer {
  name: "conv3_2/x2"
  type: "Convolution"
  bottom: "conv3_2/x2/bn"
  top: "conv3_2/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_3_2"
  type: "Concat"
  bottom: "concat_3_1"
  bottom: "conv3_2/x2"
  top: "concat_3_2"
}
layer {
  name: "conv3_3/x1/bn"
  type: "BatchNorm"
  bottom: "concat_3_2"
  top: "conv3_3/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_3/x1/scale"
  type: "Scale"
  bottom: "conv3_3/x1/bn"
  top: "conv3_3/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3/x1"
  type: "ReLU"
  bottom: "conv3_3/x1/bn"
  top: "conv3_3/x1/bn"
}
layer {
  name: "conv3_3/x1"
  type: "Convolution"
  bottom: "conv3_3/x1/bn"
  top: "conv3_3/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv3_3/x2/bn"
  type: "BatchNorm"
  bottom: "conv3_3/x1"
  top: "conv3_3/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_3/x2/scale"
  type: "Scale"
  bottom: "conv3_3/x2/bn"
  top: "conv3_3/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_3/x2"
  type: "ReLU"
  bottom: "conv3_3/x2/bn"
  top: "conv3_3/x2/bn"
}
layer {
  name: "conv3_3/x2"
  type: "Convolution"
  bottom: "conv3_3/x2/bn"
  top: "conv3_3/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_3_3"
  type: "Concat"
  bottom: "concat_3_2"
  bottom: "conv3_3/x2"
  top: "concat_3_3"
}
layer {
  name: "conv3_4/x1/bn"
  type: "BatchNorm"
  bottom: "concat_3_3"
  top: "conv3_4/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_4/x1/scale"
  type: "Scale"
  bottom: "conv3_4/x1/bn"
  top: "conv3_4/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_4/x1"
  type: "ReLU"
  bottom: "conv3_4/x1/bn"
  top: "conv3_4/x1/bn"
}
layer {
  name: "conv3_4/x1"
  type: "Convolution"
  bottom: "conv3_4/x1/bn"
  top: "conv3_4/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv3_4/x2/bn"
  type: "BatchNorm"
  bottom: "conv3_4/x1"
  top: "conv3_4/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_4/x2/scale"
  type: "Scale"
  bottom: "conv3_4/x2/bn"
  top: "conv3_4/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_4/x2"
  type: "ReLU"
  bottom: "conv3_4/x2/bn"
  top: "conv3_4/x2/bn"
}
layer {
  name: "conv3_4/x2"
  type: "Convolution"
  bottom: "conv3_4/x2/bn"
  top: "conv3_4/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_3_4"
  type: "Concat"
  bottom: "concat_3_3"
  bottom: "conv3_4/x2"
  top: "concat_3_4"
}
layer {
  name: "conv3_5/x1/bn"
  type: "BatchNorm"
  bottom: "concat_3_4"
  top: "conv3_5/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_5/x1/scale"
  type: "Scale"
  bottom: "conv3_5/x1/bn"
  top: "conv3_5/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_5/x1"
  type: "ReLU"
  bottom: "conv3_5/x1/bn"
  top: "conv3_5/x1/bn"
}
layer {
  name: "conv3_5/x1"
  type: "Convolution"
  bottom: "conv3_5/x1/bn"
  top: "conv3_5/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv3_5/x2/bn"
  type: "BatchNorm"
  bottom: "conv3_5/x1"
  top: "conv3_5/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_5/x2/scale"
  type: "Scale"
  bottom: "conv3_5/x2/bn"
  top: "conv3_5/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_5/x2"
  type: "ReLU"
  bottom: "conv3_5/x2/bn"
  top: "conv3_5/x2/bn"
}
layer {
  name: "conv3_5/x2"
  type: "Convolution"
  bottom: "conv3_5/x2/bn"
  top: "conv3_5/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_3_5"
  type: "Concat"
  bottom: "concat_3_4"
  bottom: "conv3_5/x2"
  top: "concat_3_5"
}
layer {
  name: "conv3_6/x1/bn"
  type: "BatchNorm"
  bottom: "concat_3_5"
  top: "conv3_6/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_6/x1/scale"
  type: "Scale"
  bottom: "conv3_6/x1/bn"
  top: "conv3_6/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_6/x1"
  type: "ReLU"
  bottom: "conv3_6/x1/bn"
  top: "conv3_6/x1/bn"
}
layer {
  name: "conv3_6/x1"
  type: "Convolution"
  bottom: "conv3_6/x1/bn"
  top: "conv3_6/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv3_6/x2/bn"
  type: "BatchNorm"
  bottom: "conv3_6/x1"
  top: "conv3_6/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_6/x2/scale"
  type: "Scale"
  bottom: "conv3_6/x2/bn"
  top: "conv3_6/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_6/x2"
  type: "ReLU"
  bottom: "conv3_6/x2/bn"
  top: "conv3_6/x2/bn"
}
layer {
  name: "conv3_6/x2"
  type: "Convolution"
  bottom: "conv3_6/x2/bn"
  top: "conv3_6/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_3_6"
  type: "Concat"
  bottom: "concat_3_5"
  bottom: "conv3_6/x2"
  top: "concat_3_6"
}
layer {
  name: "conv3_7/x1/bn"
  type: "BatchNorm"
  bottom: "concat_3_6"
  top: "conv3_7/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_7/x1/scale"
  type: "Scale"
  bottom: "conv3_7/x1/bn"
  top: "conv3_7/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_7/x1"
  type: "ReLU"
  bottom: "conv3_7/x1/bn"
  top: "conv3_7/x1/bn"
}
layer {
  name: "conv3_7/x1"
  type: "Convolution"
  bottom: "conv3_7/x1/bn"
  top: "conv3_7/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv3_7/x2/bn"
  type: "BatchNorm"
  bottom: "conv3_7/x1"
  top: "conv3_7/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_7/x2/scale"
  type: "Scale"
  bottom: "conv3_7/x2/bn"
  top: "conv3_7/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_7/x2"
  type: "ReLU"
  bottom: "conv3_7/x2/bn"
  top: "conv3_7/x2/bn"
}
layer {
  name: "conv3_7/x2"
  type: "Convolution"
  bottom: "conv3_7/x2/bn"
  top: "conv3_7/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_3_7"
  type: "Concat"
  bottom: "concat_3_6"
  bottom: "conv3_7/x2"
  top: "concat_3_7"
}
layer {
  name: "conv3_8/x1/bn"
  type: "BatchNorm"
  bottom: "concat_3_7"
  top: "conv3_8/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_8/x1/scale"
  type: "Scale"
  bottom: "conv3_8/x1/bn"
  top: "conv3_8/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_8/x1"
  type: "ReLU"
  bottom: "conv3_8/x1/bn"
  top: "conv3_8/x1/bn"
}
layer {
  name: "conv3_8/x1"
  type: "Convolution"
  bottom: "conv3_8/x1/bn"
  top: "conv3_8/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv3_8/x2/bn"
  type: "BatchNorm"
  bottom: "conv3_8/x1"
  top: "conv3_8/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_8/x2/scale"
  type: "Scale"
  bottom: "conv3_8/x2/bn"
  top: "conv3_8/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_8/x2"
  type: "ReLU"
  bottom: "conv3_8/x2/bn"
  top: "conv3_8/x2/bn"
}
layer {
  name: "conv3_8/x2"
  type: "Convolution"
  bottom: "conv3_8/x2/bn"
  top: "conv3_8/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_3_8"
  type: "Concat"
  bottom: "concat_3_7"
  bottom: "conv3_8/x2"
  top: "concat_3_8"
}
layer {
  name: "conv3_9/x1/bn"
  type: "BatchNorm"
  bottom: "concat_3_8"
  top: "conv3_9/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_9/x1/scale"
  type: "Scale"
  bottom: "conv3_9/x1/bn"
  top: "conv3_9/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_9/x1"
  type: "ReLU"
  bottom: "conv3_9/x1/bn"
  top: "conv3_9/x1/bn"
}
layer {
  name: "conv3_9/x1"
  type: "Convolution"
  bottom: "conv3_9/x1/bn"
  top: "conv3_9/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv3_9/x2/bn"
  type: "BatchNorm"
  bottom: "conv3_9/x1"
  top: "conv3_9/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_9/x2/scale"
  type: "Scale"
  bottom: "conv3_9/x2/bn"
  top: "conv3_9/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_9/x2"
  type: "ReLU"
  bottom: "conv3_9/x2/bn"
  top: "conv3_9/x2/bn"
}
layer {
  name: "conv3_9/x2"
  type: "Convolution"
  bottom: "conv3_9/x2/bn"
  top: "conv3_9/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_3_9"
  type: "Concat"
  bottom: "concat_3_8"
  bottom: "conv3_9/x2"
  top: "concat_3_9"
}
layer {
  name: "conv3_10/x1/bn"
  type: "BatchNorm"
  bottom: "concat_3_9"
  top: "conv3_10/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_10/x1/scale"
  type: "Scale"
  bottom: "conv3_10/x1/bn"
  top: "conv3_10/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_10/x1"
  type: "ReLU"
  bottom: "conv3_10/x1/bn"
  top: "conv3_10/x1/bn"
}
layer {
  name: "conv3_10/x1"
  type: "Convolution"
  bottom: "conv3_10/x1/bn"
  top: "conv3_10/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv3_10/x2/bn"
  type: "BatchNorm"
  bottom: "conv3_10/x1"
  top: "conv3_10/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_10/x2/scale"
  type: "Scale"
  bottom: "conv3_10/x2/bn"
  top: "conv3_10/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_10/x2"
  type: "ReLU"
  bottom: "conv3_10/x2/bn"
  top: "conv3_10/x2/bn"
}
layer {
  name: "conv3_10/x2"
  type: "Convolution"
  bottom: "conv3_10/x2/bn"
  top: "conv3_10/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_3_10"
  type: "Concat"
  bottom: "concat_3_9"
  bottom: "conv3_10/x2"
  top: "concat_3_10"
}
layer {
  name: "conv3_11/x1/bn"
  type: "BatchNorm"
  bottom: "concat_3_10"
  top: "conv3_11/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_11/x1/scale"
  type: "Scale"
  bottom: "conv3_11/x1/bn"
  top: "conv3_11/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_11/x1"
  type: "ReLU"
  bottom: "conv3_11/x1/bn"
  top: "conv3_11/x1/bn"
}
layer {
  name: "conv3_11/x1"
  type: "Convolution"
  bottom: "conv3_11/x1/bn"
  top: "conv3_11/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv3_11/x2/bn"
  type: "BatchNorm"
  bottom: "conv3_11/x1"
  top: "conv3_11/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_11/x2/scale"
  type: "Scale"
  bottom: "conv3_11/x2/bn"
  top: "conv3_11/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_11/x2"
  type: "ReLU"
  bottom: "conv3_11/x2/bn"
  top: "conv3_11/x2/bn"
}
layer {
  name: "conv3_11/x2"
  type: "Convolution"
  bottom: "conv3_11/x2/bn"
  top: "conv3_11/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_3_11"
  type: "Concat"
  bottom: "concat_3_10"
  bottom: "conv3_11/x2"
  top: "concat_3_11"
}
layer {
  name: "conv3_12/x1/bn"
  type: "BatchNorm"
  bottom: "concat_3_11"
  top: "conv3_12/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_12/x1/scale"
  type: "Scale"
  bottom: "conv3_12/x1/bn"
  top: "conv3_12/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_12/x1"
  type: "ReLU"
  bottom: "conv3_12/x1/bn"
  top: "conv3_12/x1/bn"
}
layer {
  name: "conv3_12/x1"
  type: "Convolution"
  bottom: "conv3_12/x1/bn"
  top: "conv3_12/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv3_12/x2/bn"
  type: "BatchNorm"
  bottom: "conv3_12/x1"
  top: "conv3_12/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_12/x2/scale"
  type: "Scale"
  bottom: "conv3_12/x2/bn"
  top: "conv3_12/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_12/x2"
  type: "ReLU"
  bottom: "conv3_12/x2/bn"
  top: "conv3_12/x2/bn"
}
layer {
  name: "conv3_12/x2"
  type: "Convolution"
  bottom: "conv3_12/x2/bn"
  top: "conv3_12/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_3_12"
  type: "Concat"
  bottom: "concat_3_11"
  bottom: "conv3_12/x2"
  top: "concat_3_12"
}
layer {
  name: "conv3_blk/bn"
  type: "BatchNorm"
  bottom: "concat_3_12"
  top: "conv3_blk/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv3_blk/scale"
  type: "Scale"
  bottom: "conv3_blk/bn"
  top: "conv3_blk/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_blk"
  type: "ReLU"
  bottom: "conv3_blk/bn"
  top: "conv3_blk/bn"
}
layer {
  name: "conv3_blk"
  type: "Convolution"
  bottom: "conv3_blk/bn"
  top: "conv3_blk"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 384
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_blk"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1/x1/bn"
  type: "BatchNorm"
  bottom: "pool3"
  top: "conv4_1/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_1/x1/scale"
  type: "Scale"
  bottom: "conv4_1/x1/bn"
  top: "conv4_1/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1/x1"
  type: "ReLU"
  bottom: "conv4_1/x1/bn"
  top: "conv4_1/x1/bn"
}
layer {
  name: "conv4_1/x1"
  type: "Convolution"
  bottom: "conv4_1/x1/bn"
  top: "conv4_1/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_1/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_1/x1"
  top: "conv4_1/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_1/x2/scale"
  type: "Scale"
  bottom: "conv4_1/x2/bn"
  top: "conv4_1/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1/x2"
  type: "ReLU"
  bottom: "conv4_1/x2/bn"
  top: "conv4_1/x2/bn"
}
layer {
  name: "conv4_1/x2"
  type: "Convolution"
  bottom: "conv4_1/x2/bn"
  top: "conv4_1/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_1"
  type: "Concat"
  bottom: "pool3"
  bottom: "conv4_1/x2"
  top: "concat_4_1"
}
layer {
  name: "conv4_2/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_1"
  top: "conv4_2/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_2/x1/scale"
  type: "Scale"
  bottom: "conv4_2/x1/bn"
  top: "conv4_2/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2/x1"
  type: "ReLU"
  bottom: "conv4_2/x1/bn"
  top: "conv4_2/x1/bn"
}
layer {
  name: "conv4_2/x1"
  type: "Convolution"
  bottom: "conv4_2/x1/bn"
  top: "conv4_2/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_2/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_2/x1"
  top: "conv4_2/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_2/x2/scale"
  type: "Scale"
  bottom: "conv4_2/x2/bn"
  top: "conv4_2/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2/x2"
  type: "ReLU"
  bottom: "conv4_2/x2/bn"
  top: "conv4_2/x2/bn"
}
layer {
  name: "conv4_2/x2"
  type: "Convolution"
  bottom: "conv4_2/x2/bn"
  top: "conv4_2/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_2"
  type: "Concat"
  bottom: "concat_4_1"
  bottom: "conv4_2/x2"
  top: "concat_4_2"
}
layer {
  name: "conv4_3/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_2"
  top: "conv4_3/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_3/x1/scale"
  type: "Scale"
  bottom: "conv4_3/x1/bn"
  top: "conv4_3/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3/x1"
  type: "ReLU"
  bottom: "conv4_3/x1/bn"
  top: "conv4_3/x1/bn"
}
layer {
  name: "conv4_3/x1"
  type: "Convolution"
  bottom: "conv4_3/x1/bn"
  top: "conv4_3/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_3/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_3/x1"
  top: "conv4_3/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_3/x2/scale"
  type: "Scale"
  bottom: "conv4_3/x2/bn"
  top: "conv4_3/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_3/x2"
  type: "ReLU"
  bottom: "conv4_3/x2/bn"
  top: "conv4_3/x2/bn"
}
layer {
  name: "conv4_3/x2"
  type: "Convolution"
  bottom: "conv4_3/x2/bn"
  top: "conv4_3/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_3"
  type: "Concat"
  bottom: "concat_4_2"
  bottom: "conv4_3/x2"
  top: "concat_4_3"
}
layer {
  name: "conv4_4/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_3"
  top: "conv4_4/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_4/x1/scale"
  type: "Scale"
  bottom: "conv4_4/x1/bn"
  top: "conv4_4/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_4/x1"
  type: "ReLU"
  bottom: "conv4_4/x1/bn"
  top: "conv4_4/x1/bn"
}
layer {
  name: "conv4_4/x1"
  type: "Convolution"
  bottom: "conv4_4/x1/bn"
  top: "conv4_4/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_4/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_4/x1"
  top: "conv4_4/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_4/x2/scale"
  type: "Scale"
  bottom: "conv4_4/x2/bn"
  top: "conv4_4/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_4/x2"
  type: "ReLU"
  bottom: "conv4_4/x2/bn"
  top: "conv4_4/x2/bn"
}
layer {
  name: "conv4_4/x2"
  type: "Convolution"
  bottom: "conv4_4/x2/bn"
  top: "conv4_4/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_4"
  type: "Concat"
  bottom: "concat_4_3"
  bottom: "conv4_4/x2"
  top: "concat_4_4"
}
layer {
  name: "conv4_5/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_4"
  top: "conv4_5/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_5/x1/scale"
  type: "Scale"
  bottom: "conv4_5/x1/bn"
  top: "conv4_5/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_5/x1"
  type: "ReLU"
  bottom: "conv4_5/x1/bn"
  top: "conv4_5/x1/bn"
}
layer {
  name: "conv4_5/x1"
  type: "Convolution"
  bottom: "conv4_5/x1/bn"
  top: "conv4_5/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_5/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_5/x1"
  top: "conv4_5/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_5/x2/scale"
  type: "Scale"
  bottom: "conv4_5/x2/bn"
  top: "conv4_5/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_5/x2"
  type: "ReLU"
  bottom: "conv4_5/x2/bn"
  top: "conv4_5/x2/bn"
}
layer {
  name: "conv4_5/x2"
  type: "Convolution"
  bottom: "conv4_5/x2/bn"
  top: "conv4_5/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_5"
  type: "Concat"
  bottom: "concat_4_4"
  bottom: "conv4_5/x2"
  top: "concat_4_5"
}
layer {
  name: "conv4_6/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_5"
  top: "conv4_6/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_6/x1/scale"
  type: "Scale"
  bottom: "conv4_6/x1/bn"
  top: "conv4_6/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_6/x1"
  type: "ReLU"
  bottom: "conv4_6/x1/bn"
  top: "conv4_6/x1/bn"
}
layer {
  name: "conv4_6/x1"
  type: "Convolution"
  bottom: "conv4_6/x1/bn"
  top: "conv4_6/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_6/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_6/x1"
  top: "conv4_6/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_6/x2/scale"
  type: "Scale"
  bottom: "conv4_6/x2/bn"
  top: "conv4_6/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_6/x2"
  type: "ReLU"
  bottom: "conv4_6/x2/bn"
  top: "conv4_6/x2/bn"
}
layer {
  name: "conv4_6/x2"
  type: "Convolution"
  bottom: "conv4_6/x2/bn"
  top: "conv4_6/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_6"
  type: "Concat"
  bottom: "concat_4_5"
  bottom: "conv4_6/x2"
  top: "concat_4_6"
}
layer {
  name: "conv4_7/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_6"
  top: "conv4_7/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_7/x1/scale"
  type: "Scale"
  bottom: "conv4_7/x1/bn"
  top: "conv4_7/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_7/x1"
  type: "ReLU"
  bottom: "conv4_7/x1/bn"
  top: "conv4_7/x1/bn"
}
layer {
  name: "conv4_7/x1"
  type: "Convolution"
  bottom: "conv4_7/x1/bn"
  top: "conv4_7/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_7/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_7/x1"
  top: "conv4_7/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_7/x2/scale"
  type: "Scale"
  bottom: "conv4_7/x2/bn"
  top: "conv4_7/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_7/x2"
  type: "ReLU"
  bottom: "conv4_7/x2/bn"
  top: "conv4_7/x2/bn"
}
layer {
  name: "conv4_7/x2"
  type: "Convolution"
  bottom: "conv4_7/x2/bn"
  top: "conv4_7/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_7"
  type: "Concat"
  bottom: "concat_4_6"
  bottom: "conv4_7/x2"
  top: "concat_4_7"
}
layer {
  name: "conv4_8/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_7"
  top: "conv4_8/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_8/x1/scale"
  type: "Scale"
  bottom: "conv4_8/x1/bn"
  top: "conv4_8/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_8/x1"
  type: "ReLU"
  bottom: "conv4_8/x1/bn"
  top: "conv4_8/x1/bn"
}
layer {
  name: "conv4_8/x1"
  type: "Convolution"
  bottom: "conv4_8/x1/bn"
  top: "conv4_8/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_8/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_8/x1"
  top: "conv4_8/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_8/x2/scale"
  type: "Scale"
  bottom: "conv4_8/x2/bn"
  top: "conv4_8/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_8/x2"
  type: "ReLU"
  bottom: "conv4_8/x2/bn"
  top: "conv4_8/x2/bn"
}
layer {
  name: "conv4_8/x2"
  type: "Convolution"
  bottom: "conv4_8/x2/bn"
  top: "conv4_8/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_8"
  type: "Concat"
  bottom: "concat_4_7"
  bottom: "conv4_8/x2"
  top: "concat_4_8"
}
layer {
  name: "conv4_9/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_8"
  top: "conv4_9/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_9/x1/scale"
  type: "Scale"
  bottom: "conv4_9/x1/bn"
  top: "conv4_9/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_9/x1"
  type: "ReLU"
  bottom: "conv4_9/x1/bn"
  top: "conv4_9/x1/bn"
}
layer {
  name: "conv4_9/x1"
  type: "Convolution"
  bottom: "conv4_9/x1/bn"
  top: "conv4_9/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_9/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_9/x1"
  top: "conv4_9/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_9/x2/scale"
  type: "Scale"
  bottom: "conv4_9/x2/bn"
  top: "conv4_9/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_9/x2"
  type: "ReLU"
  bottom: "conv4_9/x2/bn"
  top: "conv4_9/x2/bn"
}
layer {
  name: "conv4_9/x2"
  type: "Convolution"
  bottom: "conv4_9/x2/bn"
  top: "conv4_9/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_9"
  type: "Concat"
  bottom: "concat_4_8"
  bottom: "conv4_9/x2"
  top: "concat_4_9"
}
layer {
  name: "conv4_10/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_9"
  top: "conv4_10/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_10/x1/scale"
  type: "Scale"
  bottom: "conv4_10/x1/bn"
  top: "conv4_10/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_10/x1"
  type: "ReLU"
  bottom: "conv4_10/x1/bn"
  top: "conv4_10/x1/bn"
}
layer {
  name: "conv4_10/x1"
  type: "Convolution"
  bottom: "conv4_10/x1/bn"
  top: "conv4_10/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_10/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_10/x1"
  top: "conv4_10/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_10/x2/scale"
  type: "Scale"
  bottom: "conv4_10/x2/bn"
  top: "conv4_10/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_10/x2"
  type: "ReLU"
  bottom: "conv4_10/x2/bn"
  top: "conv4_10/x2/bn"
}
layer {
  name: "conv4_10/x2"
  type: "Convolution"
  bottom: "conv4_10/x2/bn"
  top: "conv4_10/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_10"
  type: "Concat"
  bottom: "concat_4_9"
  bottom: "conv4_10/x2"
  top: "concat_4_10"
}
layer {
  name: "conv4_11/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_10"
  top: "conv4_11/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_11/x1/scale"
  type: "Scale"
  bottom: "conv4_11/x1/bn"
  top: "conv4_11/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_11/x1"
  type: "ReLU"
  bottom: "conv4_11/x1/bn"
  top: "conv4_11/x1/bn"
}
layer {
  name: "conv4_11/x1"
  type: "Convolution"
  bottom: "conv4_11/x1/bn"
  top: "conv4_11/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_11/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_11/x1"
  top: "conv4_11/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_11/x2/scale"
  type: "Scale"
  bottom: "conv4_11/x2/bn"
  top: "conv4_11/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_11/x2"
  type: "ReLU"
  bottom: "conv4_11/x2/bn"
  top: "conv4_11/x2/bn"
}
layer {
  name: "conv4_11/x2"
  type: "Convolution"
  bottom: "conv4_11/x2/bn"
  top: "conv4_11/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_11"
  type: "Concat"
  bottom: "concat_4_10"
  bottom: "conv4_11/x2"
  top: "concat_4_11"
}
layer {
  name: "conv4_12/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_11"
  top: "conv4_12/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_12/x1/scale"
  type: "Scale"
  bottom: "conv4_12/x1/bn"
  top: "conv4_12/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_12/x1"
  type: "ReLU"
  bottom: "conv4_12/x1/bn"
  top: "conv4_12/x1/bn"
}
layer {
  name: "conv4_12/x1"
  type: "Convolution"
  bottom: "conv4_12/x1/bn"
  top: "conv4_12/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_12/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_12/x1"
  top: "conv4_12/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_12/x2/scale"
  type: "Scale"
  bottom: "conv4_12/x2/bn"
  top: "conv4_12/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_12/x2"
  type: "ReLU"
  bottom: "conv4_12/x2/bn"
  top: "conv4_12/x2/bn"
}
layer {
  name: "conv4_12/x2"
  type: "Convolution"
  bottom: "conv4_12/x2/bn"
  top: "conv4_12/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_12"
  type: "Concat"
  bottom: "concat_4_11"
  bottom: "conv4_12/x2"
  top: "concat_4_12"
}
layer {
  name: "conv4_13/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_12"
  top: "conv4_13/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_13/x1/scale"
  type: "Scale"
  bottom: "conv4_13/x1/bn"
  top: "conv4_13/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_13/x1"
  type: "ReLU"
  bottom: "conv4_13/x1/bn"
  top: "conv4_13/x1/bn"
}
layer {
  name: "conv4_13/x1"
  type: "Convolution"
  bottom: "conv4_13/x1/bn"
  top: "conv4_13/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_13/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_13/x1"
  top: "conv4_13/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_13/x2/scale"
  type: "Scale"
  bottom: "conv4_13/x2/bn"
  top: "conv4_13/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_13/x2"
  type: "ReLU"
  bottom: "conv4_13/x2/bn"
  top: "conv4_13/x2/bn"
}
layer {
  name: "conv4_13/x2"
  type: "Convolution"
  bottom: "conv4_13/x2/bn"
  top: "conv4_13/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_13"
  type: "Concat"
  bottom: "concat_4_12"
  bottom: "conv4_13/x2"
  top: "concat_4_13"
}
layer {
  name: "conv4_14/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_13"
  top: "conv4_14/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_14/x1/scale"
  type: "Scale"
  bottom: "conv4_14/x1/bn"
  top: "conv4_14/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_14/x1"
  type: "ReLU"
  bottom: "conv4_14/x1/bn"
  top: "conv4_14/x1/bn"
}
layer {
  name: "conv4_14/x1"
  type: "Convolution"
  bottom: "conv4_14/x1/bn"
  top: "conv4_14/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_14/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_14/x1"
  top: "conv4_14/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_14/x2/scale"
  type: "Scale"
  bottom: "conv4_14/x2/bn"
  top: "conv4_14/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_14/x2"
  type: "ReLU"
  bottom: "conv4_14/x2/bn"
  top: "conv4_14/x2/bn"
}
layer {
  name: "conv4_14/x2"
  type: "Convolution"
  bottom: "conv4_14/x2/bn"
  top: "conv4_14/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_14"
  type: "Concat"
  bottom: "concat_4_13"
  bottom: "conv4_14/x2"
  top: "concat_4_14"
}
layer {
  name: "conv4_15/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_14"
  top: "conv4_15/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_15/x1/scale"
  type: "Scale"
  bottom: "conv4_15/x1/bn"
  top: "conv4_15/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_15/x1"
  type: "ReLU"
  bottom: "conv4_15/x1/bn"
  top: "conv4_15/x1/bn"
}
layer {
  name: "conv4_15/x1"
  type: "Convolution"
  bottom: "conv4_15/x1/bn"
  top: "conv4_15/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_15/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_15/x1"
  top: "conv4_15/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_15/x2/scale"
  type: "Scale"
  bottom: "conv4_15/x2/bn"
  top: "conv4_15/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_15/x2"
  type: "ReLU"
  bottom: "conv4_15/x2/bn"
  top: "conv4_15/x2/bn"
}
layer {
  name: "conv4_15/x2"
  type: "Convolution"
  bottom: "conv4_15/x2/bn"
  top: "conv4_15/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_15"
  type: "Concat"
  bottom: "concat_4_14"
  bottom: "conv4_15/x2"
  top: "concat_4_15"
}
layer {
  name: "conv4_16/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_15"
  top: "conv4_16/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_16/x1/scale"
  type: "Scale"
  bottom: "conv4_16/x1/bn"
  top: "conv4_16/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_16/x1"
  type: "ReLU"
  bottom: "conv4_16/x1/bn"
  top: "conv4_16/x1/bn"
}
layer {
  name: "conv4_16/x1"
  type: "Convolution"
  bottom: "conv4_16/x1/bn"
  top: "conv4_16/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_16/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_16/x1"
  top: "conv4_16/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_16/x2/scale"
  type: "Scale"
  bottom: "conv4_16/x2/bn"
  top: "conv4_16/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_16/x2"
  type: "ReLU"
  bottom: "conv4_16/x2/bn"
  top: "conv4_16/x2/bn"
}
layer {
  name: "conv4_16/x2"
  type: "Convolution"
  bottom: "conv4_16/x2/bn"
  top: "conv4_16/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_16"
  type: "Concat"
  bottom: "concat_4_15"
  bottom: "conv4_16/x2"
  top: "concat_4_16"
}
layer {
  name: "conv4_17/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_16"
  top: "conv4_17/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_17/x1/scale"
  type: "Scale"
  bottom: "conv4_17/x1/bn"
  top: "conv4_17/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_17/x1"
  type: "ReLU"
  bottom: "conv4_17/x1/bn"
  top: "conv4_17/x1/bn"
}
layer {
  name: "conv4_17/x1"
  type: "Convolution"
  bottom: "conv4_17/x1/bn"
  top: "conv4_17/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_17/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_17/x1"
  top: "conv4_17/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_17/x2/scale"
  type: "Scale"
  bottom: "conv4_17/x2/bn"
  top: "conv4_17/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_17/x2"
  type: "ReLU"
  bottom: "conv4_17/x2/bn"
  top: "conv4_17/x2/bn"
}
layer {
  name: "conv4_17/x2"
  type: "Convolution"
  bottom: "conv4_17/x2/bn"
  top: "conv4_17/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_17"
  type: "Concat"
  bottom: "concat_4_16"
  bottom: "conv4_17/x2"
  top: "concat_4_17"
}
layer {
  name: "conv4_18/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_17"
  top: "conv4_18/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_18/x1/scale"
  type: "Scale"
  bottom: "conv4_18/x1/bn"
  top: "conv4_18/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_18/x1"
  type: "ReLU"
  bottom: "conv4_18/x1/bn"
  top: "conv4_18/x1/bn"
}
layer {
  name: "conv4_18/x1"
  type: "Convolution"
  bottom: "conv4_18/x1/bn"
  top: "conv4_18/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_18/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_18/x1"
  top: "conv4_18/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_18/x2/scale"
  type: "Scale"
  bottom: "conv4_18/x2/bn"
  top: "conv4_18/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_18/x2"
  type: "ReLU"
  bottom: "conv4_18/x2/bn"
  top: "conv4_18/x2/bn"
}
layer {
  name: "conv4_18/x2"
  type: "Convolution"
  bottom: "conv4_18/x2/bn"
  top: "conv4_18/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_18"
  type: "Concat"
  bottom: "concat_4_17"
  bottom: "conv4_18/x2"
  top: "concat_4_18"
}
layer {
  name: "conv4_19/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_18"
  top: "conv4_19/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_19/x1/scale"
  type: "Scale"
  bottom: "conv4_19/x1/bn"
  top: "conv4_19/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_19/x1"
  type: "ReLU"
  bottom: "conv4_19/x1/bn"
  top: "conv4_19/x1/bn"
}
layer {
  name: "conv4_19/x1"
  type: "Convolution"
  bottom: "conv4_19/x1/bn"
  top: "conv4_19/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_19/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_19/x1"
  top: "conv4_19/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_19/x2/scale"
  type: "Scale"
  bottom: "conv4_19/x2/bn"
  top: "conv4_19/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_19/x2"
  type: "ReLU"
  bottom: "conv4_19/x2/bn"
  top: "conv4_19/x2/bn"
}
layer {
  name: "conv4_19/x2"
  type: "Convolution"
  bottom: "conv4_19/x2/bn"
  top: "conv4_19/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_19"
  type: "Concat"
  bottom: "concat_4_18"
  bottom: "conv4_19/x2"
  top: "concat_4_19"
}
layer {
  name: "conv4_20/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_19"
  top: "conv4_20/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_20/x1/scale"
  type: "Scale"
  bottom: "conv4_20/x1/bn"
  top: "conv4_20/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_20/x1"
  type: "ReLU"
  bottom: "conv4_20/x1/bn"
  top: "conv4_20/x1/bn"
}
layer {
  name: "conv4_20/x1"
  type: "Convolution"
  bottom: "conv4_20/x1/bn"
  top: "conv4_20/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_20/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_20/x1"
  top: "conv4_20/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_20/x2/scale"
  type: "Scale"
  bottom: "conv4_20/x2/bn"
  top: "conv4_20/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_20/x2"
  type: "ReLU"
  bottom: "conv4_20/x2/bn"
  top: "conv4_20/x2/bn"
}
layer {
  name: "conv4_20/x2"
  type: "Convolution"
  bottom: "conv4_20/x2/bn"
  top: "conv4_20/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_20"
  type: "Concat"
  bottom: "concat_4_19"
  bottom: "conv4_20/x2"
  top: "concat_4_20"
}
layer {
  name: "conv4_21/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_20"
  top: "conv4_21/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_21/x1/scale"
  type: "Scale"
  bottom: "conv4_21/x1/bn"
  top: "conv4_21/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_21/x1"
  type: "ReLU"
  bottom: "conv4_21/x1/bn"
  top: "conv4_21/x1/bn"
}
layer {
  name: "conv4_21/x1"
  type: "Convolution"
  bottom: "conv4_21/x1/bn"
  top: "conv4_21/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_21/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_21/x1"
  top: "conv4_21/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_21/x2/scale"
  type: "Scale"
  bottom: "conv4_21/x2/bn"
  top: "conv4_21/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_21/x2"
  type: "ReLU"
  bottom: "conv4_21/x2/bn"
  top: "conv4_21/x2/bn"
}
layer {
  name: "conv4_21/x2"
  type: "Convolution"
  bottom: "conv4_21/x2/bn"
  top: "conv4_21/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_21"
  type: "Concat"
  bottom: "concat_4_20"
  bottom: "conv4_21/x2"
  top: "concat_4_21"
}
layer {
  name: "conv4_22/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_21"
  top: "conv4_22/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_22/x1/scale"
  type: "Scale"
  bottom: "conv4_22/x1/bn"
  top: "conv4_22/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_22/x1"
  type: "ReLU"
  bottom: "conv4_22/x1/bn"
  top: "conv4_22/x1/bn"
}
layer {
  name: "conv4_22/x1"
  type: "Convolution"
  bottom: "conv4_22/x1/bn"
  top: "conv4_22/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_22/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_22/x1"
  top: "conv4_22/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_22/x2/scale"
  type: "Scale"
  bottom: "conv4_22/x2/bn"
  top: "conv4_22/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_22/x2"
  type: "ReLU"
  bottom: "conv4_22/x2/bn"
  top: "conv4_22/x2/bn"
}
layer {
  name: "conv4_22/x2"
  type: "Convolution"
  bottom: "conv4_22/x2/bn"
  top: "conv4_22/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_22"
  type: "Concat"
  bottom: "concat_4_21"
  bottom: "conv4_22/x2"
  top: "concat_4_22"
}
layer {
  name: "conv4_23/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_22"
  top: "conv4_23/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_23/x1/scale"
  type: "Scale"
  bottom: "conv4_23/x1/bn"
  top: "conv4_23/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_23/x1"
  type: "ReLU"
  bottom: "conv4_23/x1/bn"
  top: "conv4_23/x1/bn"
}
layer {
  name: "conv4_23/x1"
  type: "Convolution"
  bottom: "conv4_23/x1/bn"
  top: "conv4_23/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_23/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_23/x1"
  top: "conv4_23/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_23/x2/scale"
  type: "Scale"
  bottom: "conv4_23/x2/bn"
  top: "conv4_23/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_23/x2"
  type: "ReLU"
  bottom: "conv4_23/x2/bn"
  top: "conv4_23/x2/bn"
}
layer {
  name: "conv4_23/x2"
  type: "Convolution"
  bottom: "conv4_23/x2/bn"
  top: "conv4_23/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_23"
  type: "Concat"
  bottom: "concat_4_22"
  bottom: "conv4_23/x2"
  top: "concat_4_23"
}
layer {
  name: "conv4_24/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_23"
  top: "conv4_24/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_24/x1/scale"
  type: "Scale"
  bottom: "conv4_24/x1/bn"
  top: "conv4_24/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_24/x1"
  type: "ReLU"
  bottom: "conv4_24/x1/bn"
  top: "conv4_24/x1/bn"
}
layer {
  name: "conv4_24/x1"
  type: "Convolution"
  bottom: "conv4_24/x1/bn"
  top: "conv4_24/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_24/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_24/x1"
  top: "conv4_24/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_24/x2/scale"
  type: "Scale"
  bottom: "conv4_24/x2/bn"
  top: "conv4_24/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_24/x2"
  type: "ReLU"
  bottom: "conv4_24/x2/bn"
  top: "conv4_24/x2/bn"
}
layer {
  name: "conv4_24/x2"
  type: "Convolution"
  bottom: "conv4_24/x2/bn"
  top: "conv4_24/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_24"
  type: "Concat"
  bottom: "concat_4_23"
  bottom: "conv4_24/x2"
  top: "concat_4_24"
}
layer {
  name: "conv4_25/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_24"
  top: "conv4_25/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_25/x1/scale"
  type: "Scale"
  bottom: "conv4_25/x1/bn"
  top: "conv4_25/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_25/x1"
  type: "ReLU"
  bottom: "conv4_25/x1/bn"
  top: "conv4_25/x1/bn"
}
layer {
  name: "conv4_25/x1"
  type: "Convolution"
  bottom: "conv4_25/x1/bn"
  top: "conv4_25/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_25/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_25/x1"
  top: "conv4_25/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_25/x2/scale"
  type: "Scale"
  bottom: "conv4_25/x2/bn"
  top: "conv4_25/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_25/x2"
  type: "ReLU"
  bottom: "conv4_25/x2/bn"
  top: "conv4_25/x2/bn"
}
layer {
  name: "conv4_25/x2"
  type: "Convolution"
  bottom: "conv4_25/x2/bn"
  top: "conv4_25/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_25"
  type: "Concat"
  bottom: "concat_4_24"
  bottom: "conv4_25/x2"
  top: "concat_4_25"
}
layer {
  name: "conv4_26/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_25"
  top: "conv4_26/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_26/x1/scale"
  type: "Scale"
  bottom: "conv4_26/x1/bn"
  top: "conv4_26/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_26/x1"
  type: "ReLU"
  bottom: "conv4_26/x1/bn"
  top: "conv4_26/x1/bn"
}
layer {
  name: "conv4_26/x1"
  type: "Convolution"
  bottom: "conv4_26/x1/bn"
  top: "conv4_26/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_26/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_26/x1"
  top: "conv4_26/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_26/x2/scale"
  type: "Scale"
  bottom: "conv4_26/x2/bn"
  top: "conv4_26/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_26/x2"
  type: "ReLU"
  bottom: "conv4_26/x2/bn"
  top: "conv4_26/x2/bn"
}
layer {
  name: "conv4_26/x2"
  type: "Convolution"
  bottom: "conv4_26/x2/bn"
  top: "conv4_26/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_26"
  type: "Concat"
  bottom: "concat_4_25"
  bottom: "conv4_26/x2"
  top: "concat_4_26"
}
layer {
  name: "conv4_27/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_26"
  top: "conv4_27/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_27/x1/scale"
  type: "Scale"
  bottom: "conv4_27/x1/bn"
  top: "conv4_27/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_27/x1"
  type: "ReLU"
  bottom: "conv4_27/x1/bn"
  top: "conv4_27/x1/bn"
}
layer {
  name: "conv4_27/x1"
  type: "Convolution"
  bottom: "conv4_27/x1/bn"
  top: "conv4_27/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_27/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_27/x1"
  top: "conv4_27/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_27/x2/scale"
  type: "Scale"
  bottom: "conv4_27/x2/bn"
  top: "conv4_27/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_27/x2"
  type: "ReLU"
  bottom: "conv4_27/x2/bn"
  top: "conv4_27/x2/bn"
}
layer {
  name: "conv4_27/x2"
  type: "Convolution"
  bottom: "conv4_27/x2/bn"
  top: "conv4_27/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_27"
  type: "Concat"
  bottom: "concat_4_26"
  bottom: "conv4_27/x2"
  top: "concat_4_27"
}
layer {
  name: "conv4_28/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_27"
  top: "conv4_28/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_28/x1/scale"
  type: "Scale"
  bottom: "conv4_28/x1/bn"
  top: "conv4_28/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_28/x1"
  type: "ReLU"
  bottom: "conv4_28/x1/bn"
  top: "conv4_28/x1/bn"
}
layer {
  name: "conv4_28/x1"
  type: "Convolution"
  bottom: "conv4_28/x1/bn"
  top: "conv4_28/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_28/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_28/x1"
  top: "conv4_28/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_28/x2/scale"
  type: "Scale"
  bottom: "conv4_28/x2/bn"
  top: "conv4_28/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_28/x2"
  type: "ReLU"
  bottom: "conv4_28/x2/bn"
  top: "conv4_28/x2/bn"
}
layer {
  name: "conv4_28/x2"
  type: "Convolution"
  bottom: "conv4_28/x2/bn"
  top: "conv4_28/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_28"
  type: "Concat"
  bottom: "concat_4_27"
  bottom: "conv4_28/x2"
  top: "concat_4_28"
}
layer {
  name: "conv4_29/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_28"
  top: "conv4_29/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_29/x1/scale"
  type: "Scale"
  bottom: "conv4_29/x1/bn"
  top: "conv4_29/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_29/x1"
  type: "ReLU"
  bottom: "conv4_29/x1/bn"
  top: "conv4_29/x1/bn"
}
layer {
  name: "conv4_29/x1"
  type: "Convolution"
  bottom: "conv4_29/x1/bn"
  top: "conv4_29/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_29/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_29/x1"
  top: "conv4_29/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_29/x2/scale"
  type: "Scale"
  bottom: "conv4_29/x2/bn"
  top: "conv4_29/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_29/x2"
  type: "ReLU"
  bottom: "conv4_29/x2/bn"
  top: "conv4_29/x2/bn"
}
layer {
  name: "conv4_29/x2"
  type: "Convolution"
  bottom: "conv4_29/x2/bn"
  top: "conv4_29/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_29"
  type: "Concat"
  bottom: "concat_4_28"
  bottom: "conv4_29/x2"
  top: "concat_4_29"
}
layer {
  name: "conv4_30/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_29"
  top: "conv4_30/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_30/x1/scale"
  type: "Scale"
  bottom: "conv4_30/x1/bn"
  top: "conv4_30/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_30/x1"
  type: "ReLU"
  bottom: "conv4_30/x1/bn"
  top: "conv4_30/x1/bn"
}
layer {
  name: "conv4_30/x1"
  type: "Convolution"
  bottom: "conv4_30/x1/bn"
  top: "conv4_30/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_30/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_30/x1"
  top: "conv4_30/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_30/x2/scale"
  type: "Scale"
  bottom: "conv4_30/x2/bn"
  top: "conv4_30/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_30/x2"
  type: "ReLU"
  bottom: "conv4_30/x2/bn"
  top: "conv4_30/x2/bn"
}
layer {
  name: "conv4_30/x2"
  type: "Convolution"
  bottom: "conv4_30/x2/bn"
  top: "conv4_30/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_30"
  type: "Concat"
  bottom: "concat_4_29"
  bottom: "conv4_30/x2"
  top: "concat_4_30"
}
layer {
  name: "conv4_31/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_30"
  top: "conv4_31/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_31/x1/scale"
  type: "Scale"
  bottom: "conv4_31/x1/bn"
  top: "conv4_31/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_31/x1"
  type: "ReLU"
  bottom: "conv4_31/x1/bn"
  top: "conv4_31/x1/bn"
}
layer {
  name: "conv4_31/x1"
  type: "Convolution"
  bottom: "conv4_31/x1/bn"
  top: "conv4_31/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_31/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_31/x1"
  top: "conv4_31/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_31/x2/scale"
  type: "Scale"
  bottom: "conv4_31/x2/bn"
  top: "conv4_31/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_31/x2"
  type: "ReLU"
  bottom: "conv4_31/x2/bn"
  top: "conv4_31/x2/bn"
}
layer {
  name: "conv4_31/x2"
  type: "Convolution"
  bottom: "conv4_31/x2/bn"
  top: "conv4_31/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_31"
  type: "Concat"
  bottom: "concat_4_30"
  bottom: "conv4_31/x2"
  top: "concat_4_31"
}
layer {
  name: "conv4_32/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_31"
  top: "conv4_32/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_32/x1/scale"
  type: "Scale"
  bottom: "conv4_32/x1/bn"
  top: "conv4_32/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_32/x1"
  type: "ReLU"
  bottom: "conv4_32/x1/bn"
  top: "conv4_32/x1/bn"
}
layer {
  name: "conv4_32/x1"
  type: "Convolution"
  bottom: "conv4_32/x1/bn"
  top: "conv4_32/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_32/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_32/x1"
  top: "conv4_32/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_32/x2/scale"
  type: "Scale"
  bottom: "conv4_32/x2/bn"
  top: "conv4_32/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_32/x2"
  type: "ReLU"
  bottom: "conv4_32/x2/bn"
  top: "conv4_32/x2/bn"
}
layer {
  name: "conv4_32/x2"
  type: "Convolution"
  bottom: "conv4_32/x2/bn"
  top: "conv4_32/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_32"
  type: "Concat"
  bottom: "concat_4_31"
  bottom: "conv4_32/x2"
  top: "concat_4_32"
}
layer {
  name: "conv4_33/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_32"
  top: "conv4_33/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_33/x1/scale"
  type: "Scale"
  bottom: "conv4_33/x1/bn"
  top: "conv4_33/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_33/x1"
  type: "ReLU"
  bottom: "conv4_33/x1/bn"
  top: "conv4_33/x1/bn"
}
layer {
  name: "conv4_33/x1"
  type: "Convolution"
  bottom: "conv4_33/x1/bn"
  top: "conv4_33/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_33/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_33/x1"
  top: "conv4_33/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_33/x2/scale"
  type: "Scale"
  bottom: "conv4_33/x2/bn"
  top: "conv4_33/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_33/x2"
  type: "ReLU"
  bottom: "conv4_33/x2/bn"
  top: "conv4_33/x2/bn"
}
layer {
  name: "conv4_33/x2"
  type: "Convolution"
  bottom: "conv4_33/x2/bn"
  top: "conv4_33/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_33"
  type: "Concat"
  bottom: "concat_4_32"
  bottom: "conv4_33/x2"
  top: "concat_4_33"
}
layer {
  name: "conv4_34/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_33"
  top: "conv4_34/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_34/x1/scale"
  type: "Scale"
  bottom: "conv4_34/x1/bn"
  top: "conv4_34/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_34/x1"
  type: "ReLU"
  bottom: "conv4_34/x1/bn"
  top: "conv4_34/x1/bn"
}
layer {
  name: "conv4_34/x1"
  type: "Convolution"
  bottom: "conv4_34/x1/bn"
  top: "conv4_34/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_34/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_34/x1"
  top: "conv4_34/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_34/x2/scale"
  type: "Scale"
  bottom: "conv4_34/x2/bn"
  top: "conv4_34/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_34/x2"
  type: "ReLU"
  bottom: "conv4_34/x2/bn"
  top: "conv4_34/x2/bn"
}
layer {
  name: "conv4_34/x2"
  type: "Convolution"
  bottom: "conv4_34/x2/bn"
  top: "conv4_34/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_34"
  type: "Concat"
  bottom: "concat_4_33"
  bottom: "conv4_34/x2"
  top: "concat_4_34"
}
layer {
  name: "conv4_35/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_34"
  top: "conv4_35/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_35/x1/scale"
  type: "Scale"
  bottom: "conv4_35/x1/bn"
  top: "conv4_35/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_35/x1"
  type: "ReLU"
  bottom: "conv4_35/x1/bn"
  top: "conv4_35/x1/bn"
}
layer {
  name: "conv4_35/x1"
  type: "Convolution"
  bottom: "conv4_35/x1/bn"
  top: "conv4_35/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_35/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_35/x1"
  top: "conv4_35/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_35/x2/scale"
  type: "Scale"
  bottom: "conv4_35/x2/bn"
  top: "conv4_35/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_35/x2"
  type: "ReLU"
  bottom: "conv4_35/x2/bn"
  top: "conv4_35/x2/bn"
}
layer {
  name: "conv4_35/x2"
  type: "Convolution"
  bottom: "conv4_35/x2/bn"
  top: "conv4_35/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_35"
  type: "Concat"
  bottom: "concat_4_34"
  bottom: "conv4_35/x2"
  top: "concat_4_35"
}
layer {
  name: "conv4_36/x1/bn"
  type: "BatchNorm"
  bottom: "concat_4_35"
  top: "conv4_36/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_36/x1/scale"
  type: "Scale"
  bottom: "conv4_36/x1/bn"
  top: "conv4_36/x1/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_36/x1"
  type: "ReLU"
  bottom: "conv4_36/x1/bn"
  top: "conv4_36/x1/bn"
}
layer {
  name: "conv4_36/x1"
  type: "Convolution"
  bottom: "conv4_36/x1/bn"
  top: "conv4_36/x1"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "conv4_36/x2/bn"
  type: "BatchNorm"
  bottom: "conv4_36/x1"
  top: "conv4_36/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_36/x2/scale"
  type: "Scale"
  bottom: "conv4_36/x2/bn"
  top: "conv4_36/x2/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_36/x2"
  type: "ReLU"
  bottom: "conv4_36/x2/bn"
  top: "conv4_36/x2/bn"
}
layer {
  name: "conv4_36/x2"
  type: "Convolution"
  bottom: "conv4_36/x2/bn"
  top: "conv4_36/x2"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "concat_4_36"
  type: "Concat"
  bottom: "concat_4_35"
  bottom: "conv4_36/x2"
  top: "concat_4_36"
}
layer {
  name: "conv4_blk/bn"
  type: "BatchNorm"
  bottom: "concat_4_36"
  top: "conv4_blk/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "conv4_blk/scale"
  type: "Scale"
  bottom: "conv4_blk/bn"
  top: "conv4_blk/bn"
  param { lr_mult : 0.0000 }
  param { lr_mult : 0.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_blk"
  type: "ReLU"
  bottom: "conv4_blk/bn"
  top: "conv4_blk/bn"
}
layer {
  name: "conv4_blk"
  type: "Convolution"
  bottom: "conv4_blk/bn"
  top: "conv4_blk"
  param { lr_mult : 0.0000 }
  convolution_param {
    num_output: 1056
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_blk"
  top: "pool4"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}

#########################################
##### Part003 size008_008/abs/conv5 #####
#########################################
layer {
  name: "size008_008/abs/conv5_1/x1/bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "size008_008/abs/conv5_1/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_1/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_1/x1/bn"
  top: "size008_008/abs/conv5_1/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_1/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_1/x1/bn"
  top: "size008_008/abs/conv5_1/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_1/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_1/x1/bn"
  top: "size008_008/abs/conv5_1/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_1/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_1/x1"
  top: "size008_008/abs/conv5_1/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_1/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_1/x2/bn"
  top: "size008_008/abs/conv5_1/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_1/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_1/x2/bn"
  top: "size008_008/abs/conv5_1/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_1/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_1/x2/bn"
  top: "size008_008/abs/conv5_1/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_1"
  type: "Concat"
  bottom: "pool4"
  bottom: "size008_008/abs/conv5_1/x2"
  top: "size008_008/abs/concat_5_1"
}
layer {
  name: "size008_008/abs/conv5_2/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_1"
  top: "size008_008/abs/conv5_2/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_2/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_2/x1/bn"
  top: "size008_008/abs/conv5_2/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_2/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_2/x1/bn"
  top: "size008_008/abs/conv5_2/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_2/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_2/x1/bn"
  top: "size008_008/abs/conv5_2/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_2/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_2/x1"
  top: "size008_008/abs/conv5_2/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_2/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_2/x2/bn"
  top: "size008_008/abs/conv5_2/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_2/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_2/x2/bn"
  top: "size008_008/abs/conv5_2/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_2/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_2/x2/bn"
  top: "size008_008/abs/conv5_2/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_2"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_1"
  bottom: "size008_008/abs/conv5_2/x2"
  top: "size008_008/abs/concat_5_2"
}
layer {
  name: "size008_008/abs/conv5_3/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_2"
  top: "size008_008/abs/conv5_3/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_3/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_3/x1/bn"
  top: "size008_008/abs/conv5_3/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_3/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_3/x1/bn"
  top: "size008_008/abs/conv5_3/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_3/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_3/x1/bn"
  top: "size008_008/abs/conv5_3/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_3/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_3/x1"
  top: "size008_008/abs/conv5_3/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_3/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_3/x2/bn"
  top: "size008_008/abs/conv5_3/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_3/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_3/x2/bn"
  top: "size008_008/abs/conv5_3/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_3/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_3/x2/bn"
  top: "size008_008/abs/conv5_3/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_3"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_2"
  bottom: "size008_008/abs/conv5_3/x2"
  top: "size008_008/abs/concat_5_3"
}
layer {
  name: "size008_008/abs/conv5_4/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_3"
  top: "size008_008/abs/conv5_4/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_4/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_4/x1/bn"
  top: "size008_008/abs/conv5_4/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_4/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_4/x1/bn"
  top: "size008_008/abs/conv5_4/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_4/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_4/x1/bn"
  top: "size008_008/abs/conv5_4/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_4/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_4/x1"
  top: "size008_008/abs/conv5_4/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_4/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_4/x2/bn"
  top: "size008_008/abs/conv5_4/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_4/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_4/x2/bn"
  top: "size008_008/abs/conv5_4/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_4/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_4/x2/bn"
  top: "size008_008/abs/conv5_4/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_4"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_3"
  bottom: "size008_008/abs/conv5_4/x2"
  top: "size008_008/abs/concat_5_4"
}
layer {
  name: "size008_008/abs/conv5_5/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_4"
  top: "size008_008/abs/conv5_5/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_5/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_5/x1/bn"
  top: "size008_008/abs/conv5_5/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_5/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_5/x1/bn"
  top: "size008_008/abs/conv5_5/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_5/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_5/x1/bn"
  top: "size008_008/abs/conv5_5/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_5/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_5/x1"
  top: "size008_008/abs/conv5_5/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_5/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_5/x2/bn"
  top: "size008_008/abs/conv5_5/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_5/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_5/x2/bn"
  top: "size008_008/abs/conv5_5/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_5/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_5/x2/bn"
  top: "size008_008/abs/conv5_5/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_5"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_4"
  bottom: "size008_008/abs/conv5_5/x2"
  top: "size008_008/abs/concat_5_5"
}
layer {
  name: "size008_008/abs/conv5_6/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_5"
  top: "size008_008/abs/conv5_6/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_6/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_6/x1/bn"
  top: "size008_008/abs/conv5_6/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_6/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_6/x1/bn"
  top: "size008_008/abs/conv5_6/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_6/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_6/x1/bn"
  top: "size008_008/abs/conv5_6/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_6/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_6/x1"
  top: "size008_008/abs/conv5_6/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_6/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_6/x2/bn"
  top: "size008_008/abs/conv5_6/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_6/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_6/x2/bn"
  top: "size008_008/abs/conv5_6/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_6/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_6/x2/bn"
  top: "size008_008/abs/conv5_6/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_6"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_5"
  bottom: "size008_008/abs/conv5_6/x2"
  top: "size008_008/abs/concat_5_6"
}
layer {
  name: "size008_008/abs/conv5_7/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_6"
  top: "size008_008/abs/conv5_7/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_7/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_7/x1/bn"
  top: "size008_008/abs/conv5_7/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_7/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_7/x1/bn"
  top: "size008_008/abs/conv5_7/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_7/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_7/x1/bn"
  top: "size008_008/abs/conv5_7/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_7/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_7/x1"
  top: "size008_008/abs/conv5_7/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_7/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_7/x2/bn"
  top: "size008_008/abs/conv5_7/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_7/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_7/x2/bn"
  top: "size008_008/abs/conv5_7/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_7/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_7/x2/bn"
  top: "size008_008/abs/conv5_7/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_7"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_6"
  bottom: "size008_008/abs/conv5_7/x2"
  top: "size008_008/abs/concat_5_7"
}
layer {
  name: "size008_008/abs/conv5_8/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_7"
  top: "size008_008/abs/conv5_8/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_8/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_8/x1/bn"
  top: "size008_008/abs/conv5_8/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_8/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_8/x1/bn"
  top: "size008_008/abs/conv5_8/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_8/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_8/x1/bn"
  top: "size008_008/abs/conv5_8/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_8/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_8/x1"
  top: "size008_008/abs/conv5_8/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_8/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_8/x2/bn"
  top: "size008_008/abs/conv5_8/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_8/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_8/x2/bn"
  top: "size008_008/abs/conv5_8/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_8/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_8/x2/bn"
  top: "size008_008/abs/conv5_8/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_8"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_7"
  bottom: "size008_008/abs/conv5_8/x2"
  top: "size008_008/abs/concat_5_8"
}
layer {
  name: "size008_008/abs/conv5_9/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_8"
  top: "size008_008/abs/conv5_9/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_9/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_9/x1/bn"
  top: "size008_008/abs/conv5_9/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_9/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_9/x1/bn"
  top: "size008_008/abs/conv5_9/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_9/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_9/x1/bn"
  top: "size008_008/abs/conv5_9/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_9/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_9/x1"
  top: "size008_008/abs/conv5_9/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_9/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_9/x2/bn"
  top: "size008_008/abs/conv5_9/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_9/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_9/x2/bn"
  top: "size008_008/abs/conv5_9/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_9/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_9/x2/bn"
  top: "size008_008/abs/conv5_9/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_9"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_8"
  bottom: "size008_008/abs/conv5_9/x2"
  top: "size008_008/abs/concat_5_9"
}
layer {
  name: "size008_008/abs/conv5_10/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_9"
  top: "size008_008/abs/conv5_10/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_10/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_10/x1/bn"
  top: "size008_008/abs/conv5_10/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_10/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_10/x1/bn"
  top: "size008_008/abs/conv5_10/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_10/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_10/x1/bn"
  top: "size008_008/abs/conv5_10/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_10/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_10/x1"
  top: "size008_008/abs/conv5_10/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_10/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_10/x2/bn"
  top: "size008_008/abs/conv5_10/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_10/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_10/x2/bn"
  top: "size008_008/abs/conv5_10/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_10/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_10/x2/bn"
  top: "size008_008/abs/conv5_10/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_10"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_9"
  bottom: "size008_008/abs/conv5_10/x2"
  top: "size008_008/abs/concat_5_10"
}
layer {
  name: "size008_008/abs/conv5_11/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_10"
  top: "size008_008/abs/conv5_11/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_11/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_11/x1/bn"
  top: "size008_008/abs/conv5_11/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_11/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_11/x1/bn"
  top: "size008_008/abs/conv5_11/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_11/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_11/x1/bn"
  top: "size008_008/abs/conv5_11/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_11/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_11/x1"
  top: "size008_008/abs/conv5_11/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_11/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_11/x2/bn"
  top: "size008_008/abs/conv5_11/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_11/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_11/x2/bn"
  top: "size008_008/abs/conv5_11/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_11/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_11/x2/bn"
  top: "size008_008/abs/conv5_11/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_11"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_10"
  bottom: "size008_008/abs/conv5_11/x2"
  top: "size008_008/abs/concat_5_11"
}
layer {
  name: "size008_008/abs/conv5_12/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_11"
  top: "size008_008/abs/conv5_12/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_12/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_12/x1/bn"
  top: "size008_008/abs/conv5_12/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_12/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_12/x1/bn"
  top: "size008_008/abs/conv5_12/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_12/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_12/x1/bn"
  top: "size008_008/abs/conv5_12/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_12/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_12/x1"
  top: "size008_008/abs/conv5_12/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_12/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_12/x2/bn"
  top: "size008_008/abs/conv5_12/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_12/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_12/x2/bn"
  top: "size008_008/abs/conv5_12/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_12/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_12/x2/bn"
  top: "size008_008/abs/conv5_12/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_12"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_11"
  bottom: "size008_008/abs/conv5_12/x2"
  top: "size008_008/abs/concat_5_12"
}
layer {
  name: "size008_008/abs/conv5_13/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_12"
  top: "size008_008/abs/conv5_13/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_13/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_13/x1/bn"
  top: "size008_008/abs/conv5_13/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_13/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_13/x1/bn"
  top: "size008_008/abs/conv5_13/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_13/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_13/x1/bn"
  top: "size008_008/abs/conv5_13/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_13/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_13/x1"
  top: "size008_008/abs/conv5_13/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_13/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_13/x2/bn"
  top: "size008_008/abs/conv5_13/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_13/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_13/x2/bn"
  top: "size008_008/abs/conv5_13/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_13/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_13/x2/bn"
  top: "size008_008/abs/conv5_13/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_13"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_12"
  bottom: "size008_008/abs/conv5_13/x2"
  top: "size008_008/abs/concat_5_13"
}
layer {
  name: "size008_008/abs/conv5_14/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_13"
  top: "size008_008/abs/conv5_14/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_14/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_14/x1/bn"
  top: "size008_008/abs/conv5_14/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_14/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_14/x1/bn"
  top: "size008_008/abs/conv5_14/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_14/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_14/x1/bn"
  top: "size008_008/abs/conv5_14/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_14/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_14/x1"
  top: "size008_008/abs/conv5_14/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_14/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_14/x2/bn"
  top: "size008_008/abs/conv5_14/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_14/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_14/x2/bn"
  top: "size008_008/abs/conv5_14/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_14/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_14/x2/bn"
  top: "size008_008/abs/conv5_14/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_14"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_13"
  bottom: "size008_008/abs/conv5_14/x2"
  top: "size008_008/abs/concat_5_14"
}
layer {
  name: "size008_008/abs/conv5_15/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_14"
  top: "size008_008/abs/conv5_15/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_15/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_15/x1/bn"
  top: "size008_008/abs/conv5_15/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_15/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_15/x1/bn"
  top: "size008_008/abs/conv5_15/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_15/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_15/x1/bn"
  top: "size008_008/abs/conv5_15/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_15/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_15/x1"
  top: "size008_008/abs/conv5_15/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_15/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_15/x2/bn"
  top: "size008_008/abs/conv5_15/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_15/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_15/x2/bn"
  top: "size008_008/abs/conv5_15/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_15/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_15/x2/bn"
  top: "size008_008/abs/conv5_15/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_15"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_14"
  bottom: "size008_008/abs/conv5_15/x2"
  top: "size008_008/abs/concat_5_15"
}
layer {
  name: "size008_008/abs/conv5_16/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_15"
  top: "size008_008/abs/conv5_16/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_16/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_16/x1/bn"
  top: "size008_008/abs/conv5_16/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_16/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_16/x1/bn"
  top: "size008_008/abs/conv5_16/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_16/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_16/x1/bn"
  top: "size008_008/abs/conv5_16/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_16/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_16/x1"
  top: "size008_008/abs/conv5_16/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_16/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_16/x2/bn"
  top: "size008_008/abs/conv5_16/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_16/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_16/x2/bn"
  top: "size008_008/abs/conv5_16/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_16/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_16/x2/bn"
  top: "size008_008/abs/conv5_16/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_16"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_15"
  bottom: "size008_008/abs/conv5_16/x2"
  top: "size008_008/abs/concat_5_16"
}
layer {
  name: "size008_008/abs/conv5_17/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_16"
  top: "size008_008/abs/conv5_17/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_17/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_17/x1/bn"
  top: "size008_008/abs/conv5_17/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_17/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_17/x1/bn"
  top: "size008_008/abs/conv5_17/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_17/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_17/x1/bn"
  top: "size008_008/abs/conv5_17/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_17/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_17/x1"
  top: "size008_008/abs/conv5_17/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_17/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_17/x2/bn"
  top: "size008_008/abs/conv5_17/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_17/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_17/x2/bn"
  top: "size008_008/abs/conv5_17/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_17/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_17/x2/bn"
  top: "size008_008/abs/conv5_17/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_17"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_16"
  bottom: "size008_008/abs/conv5_17/x2"
  top: "size008_008/abs/concat_5_17"
}
layer {
  name: "size008_008/abs/conv5_18/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_17"
  top: "size008_008/abs/conv5_18/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_18/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_18/x1/bn"
  top: "size008_008/abs/conv5_18/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_18/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_18/x1/bn"
  top: "size008_008/abs/conv5_18/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_18/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_18/x1/bn"
  top: "size008_008/abs/conv5_18/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_18/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_18/x1"
  top: "size008_008/abs/conv5_18/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_18/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_18/x2/bn"
  top: "size008_008/abs/conv5_18/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_18/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_18/x2/bn"
  top: "size008_008/abs/conv5_18/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_18/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_18/x2/bn"
  top: "size008_008/abs/conv5_18/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_18"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_17"
  bottom: "size008_008/abs/conv5_18/x2"
  top: "size008_008/abs/concat_5_18"
}
layer {
  name: "size008_008/abs/conv5_19/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_18"
  top: "size008_008/abs/conv5_19/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_19/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_19/x1/bn"
  top: "size008_008/abs/conv5_19/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_19/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_19/x1/bn"
  top: "size008_008/abs/conv5_19/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_19/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_19/x1/bn"
  top: "size008_008/abs/conv5_19/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_19/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_19/x1"
  top: "size008_008/abs/conv5_19/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_19/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_19/x2/bn"
  top: "size008_008/abs/conv5_19/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_19/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_19/x2/bn"
  top: "size008_008/abs/conv5_19/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_19/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_19/x2/bn"
  top: "size008_008/abs/conv5_19/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_19"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_18"
  bottom: "size008_008/abs/conv5_19/x2"
  top: "size008_008/abs/concat_5_19"
}
layer {
  name: "size008_008/abs/conv5_20/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_19"
  top: "size008_008/abs/conv5_20/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_20/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_20/x1/bn"
  top: "size008_008/abs/conv5_20/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_20/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_20/x1/bn"
  top: "size008_008/abs/conv5_20/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_20/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_20/x1/bn"
  top: "size008_008/abs/conv5_20/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_20/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_20/x1"
  top: "size008_008/abs/conv5_20/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_20/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_20/x2/bn"
  top: "size008_008/abs/conv5_20/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_20/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_20/x2/bn"
  top: "size008_008/abs/conv5_20/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_20/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_20/x2/bn"
  top: "size008_008/abs/conv5_20/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_20"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_19"
  bottom: "size008_008/abs/conv5_20/x2"
  top: "size008_008/abs/concat_5_20"
}
layer {
  name: "size008_008/abs/conv5_21/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_20"
  top: "size008_008/abs/conv5_21/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_21/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_21/x1/bn"
  top: "size008_008/abs/conv5_21/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_21/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_21/x1/bn"
  top: "size008_008/abs/conv5_21/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_21/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_21/x1/bn"
  top: "size008_008/abs/conv5_21/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_21/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_21/x1"
  top: "size008_008/abs/conv5_21/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_21/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_21/x2/bn"
  top: "size008_008/abs/conv5_21/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_21/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_21/x2/bn"
  top: "size008_008/abs/conv5_21/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_21/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_21/x2/bn"
  top: "size008_008/abs/conv5_21/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_21"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_20"
  bottom: "size008_008/abs/conv5_21/x2"
  top: "size008_008/abs/concat_5_21"
}
layer {
  name: "size008_008/abs/conv5_22/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_21"
  top: "size008_008/abs/conv5_22/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_22/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_22/x1/bn"
  top: "size008_008/abs/conv5_22/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_22/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_22/x1/bn"
  top: "size008_008/abs/conv5_22/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_22/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_22/x1/bn"
  top: "size008_008/abs/conv5_22/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_22/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_22/x1"
  top: "size008_008/abs/conv5_22/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_22/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_22/x2/bn"
  top: "size008_008/abs/conv5_22/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_22/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_22/x2/bn"
  top: "size008_008/abs/conv5_22/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_22/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_22/x2/bn"
  top: "size008_008/abs/conv5_22/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_22"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_21"
  bottom: "size008_008/abs/conv5_22/x2"
  top: "size008_008/abs/concat_5_22"
}
layer {
  name: "size008_008/abs/conv5_23/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_22"
  top: "size008_008/abs/conv5_23/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_23/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_23/x1/bn"
  top: "size008_008/abs/conv5_23/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_23/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_23/x1/bn"
  top: "size008_008/abs/conv5_23/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_23/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_23/x1/bn"
  top: "size008_008/abs/conv5_23/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_23/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_23/x1"
  top: "size008_008/abs/conv5_23/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_23/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_23/x2/bn"
  top: "size008_008/abs/conv5_23/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_23/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_23/x2/bn"
  top: "size008_008/abs/conv5_23/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_23/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_23/x2/bn"
  top: "size008_008/abs/conv5_23/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_23"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_22"
  bottom: "size008_008/abs/conv5_23/x2"
  top: "size008_008/abs/concat_5_23"
}
layer {
  name: "size008_008/abs/conv5_24/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_23"
  top: "size008_008/abs/conv5_24/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_24/x1/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_24/x1/bn"
  top: "size008_008/abs/conv5_24/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_24/x1"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_24/x1/bn"
  top: "size008_008/abs/conv5_24/x1/bn"
}
layer {
  name: "size008_008/abs/conv5_24/x1"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_24/x1/bn"
  top: "size008_008/abs/conv5_24/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/abs/conv5_24/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/conv5_24/x1"
  top: "size008_008/abs/conv5_24/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_24/x2/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_24/x2/bn"
  top: "size008_008/abs/conv5_24/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_24/x2"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_24/x2/bn"
  top: "size008_008/abs/conv5_24/x2/bn"
}
layer {
  name: "size008_008/abs/conv5_24/x2"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_24/x2/bn"
  top: "size008_008/abs/conv5_24/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/abs/concat_5_24"
  type: "Concat"
  bottom: "size008_008/abs/concat_5_23"
  bottom: "size008_008/abs/conv5_24/x2"
  top: "size008_008/abs/concat_5_24"
}
layer {
  name: "size008_008/abs/conv5_blk/bn"
  type: "BatchNorm"
  bottom: "size008_008/abs/concat_5_24"
  top: "size008_008/abs/conv5_blk/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/abs/conv5_blk/scale"
  type: "Scale"
  bottom: "size008_008/abs/conv5_blk/bn"
  top: "size008_008/abs/conv5_blk/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/abs/relu5_blk"
  type: "ReLU"
  bottom: "size008_008/abs/conv5_blk/bn"
  top: "size008_008/abs/conv5_blk/bn"
}

#################################################
##### Part004 loss at size008_008/abs/conv5 #####
#################################################
layer {
  name: "DenseNet16520or/pred_2D_008_008_ch068_true"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_blk/bn"
  top: "DenseNet16520or/pred_2D_008_008_ch068_true"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 68
    kernel_size: 1
    weight_filler{
      type: "xavier"
    }
  }
  
}

layer {
  name: "DenseNet16520or/pred_2D_008_008_ch068_false"
  type: "Convolution"
  bottom: "size008_008/abs/conv5_blk/bn"
  top: "DenseNet16520or/pred_2D_008_008_ch068_false"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 68
    kernel_size: 1
    weight_filler{
      type: "xavier"
    }
  }
}

layer {
  bottom: "DenseNet16520or/pred_2D_008_008_ch068_true"
  bottom: "DenseNet16520or/pred_2D_008_008_ch068_false"
  top: "DenseNet16520or/pred_2D_008_008_ch068_true_false_gap"
  name: "DenseNet16520or/pred_2D_008_008_ch068_true_false_gap"
  type: "Eltwise"
  eltwise_param {
        operation: 1 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
        coeff: 1
        coeff: -1
  }
}

layer {
  name: "DenseNet16520or/pred_2D_008_008_ch068"
  type: "Sigmoid"
  bottom: "DenseNet16520or/pred_2D_008_008_ch068_true_false_gap"
  top: "DenseNet16520or/pred_2D_008_008_ch068"
}

layer {
    name: "DenseNet16520or/pred_2D_008_008_ch068_norm"
    bottom: "DenseNet16520or/pred_2D_008_008_ch068"
    top: "DenseNet16520or/pred_2D_008_008_ch068_norm"
    type: "Power"
    power_param {
        power: 1
        scale: 0.999990
        shift: 0.000005
    }
}

layer {
    name: "DenseNet16520or/pred_2D_008_008_ch068_norm_inverse"
    bottom: "DenseNet16520or/pred_2D_008_008_ch068_norm"
    top: "DenseNet16520or/pred_2D_008_008_ch068_norm_inverse"
    type: "Power"
    power_param {
        power: 1
        scale: -1
        shift: 1
    }
}

layer {
    name: "DenseNet16520or/pred_2D_008_008_ch068_log"
    bottom: "DenseNet16520or/pred_2D_008_008_ch068_norm"
    top: "DenseNet16520or/pred_2D_008_008_ch068_log"
    type: "Log"
    log_param {
        base: -1 # default(=-1) -> base is set to e
        scale: 1
        shift: 0
    }
}

layer {
    name: "DenseNet16520or/pred_2D_008_008_ch068_inverse_log"
    bottom: "DenseNet16520or/pred_2D_008_008_ch068_norm_inverse"
    top: "DenseNet16520or/pred_2D_008_008_ch068_inverse_log"
    type: "Log"
    log_param {
        base: -1 # default(=-1) -> base is set to e
        scale: 1
        shift: 0
    }
}

layer {
  bottom: "DenseNet16520or/pred_2D_008_008_ch068_log"
  bottom: "label_008_008_ch068"
  top: "DenseNet16520or/loss_2D_008_008_ch068_true"
  name: "DenseNet16520or/loss_2D_008_008_ch068_true"
  type: "Eltwise" # Eltwise(PROD)
  eltwise_param {
        operation: 0 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
  }
}

layer {
  bottom: "DenseNet16520or/pred_2D_008_008_ch068_inverse_log"
  bottom: "label_008_008_ch068_inverse"
  top: "DenseNet16520or/loss_2D_008_008_ch068_false"
  name: "DenseNet16520or/loss_2D_008_008_ch068_false"
  type: "Eltwise" # Eltwise(PROD)
  eltwise_param {
        operation: 0 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
  }
}

layer {
  bottom: "DenseNet16520or/loss_2D_008_008_ch068_true"
  bottom: "DenseNet16520or/loss_2D_008_008_ch068_false"
  top: "DenseNet16520or/loss_2D_008_008_ch068"
  name: "DenseNet16520or/loss_2D_008_008_ch068"
  type: "Eltwise"
  eltwise_param {
        operation: 1 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
        coeff: -1
        coeff: -1
  }
}

layer {
    name: "DenseNet16520or/loss_2D_008_008_ch068_size_norm"
    bottom: "DenseNet16520or/loss_2D_008_008_ch068"
    top: "DenseNet16520or/loss_2D_008_008_ch068_size_norm"
    type: "Power"
    power_param {
        power: 1
        scale: 0.015625 # output 1/(H x W) = 1/(8 x 8) = 0.015625
        shift: 0
    }
}

layer { ## Requires user to set loss scale (For setting lr at each epoch)
  name: "DenseNet16520or/loss_2D_008_008_ch068_multiplication"
  type: "Scale"
  bottom: "DenseNet16520or/loss_2D_008_008_ch068_size_norm"
  top: "DenseNet16520or/loss_2D_008_008_ch068_multiplication"
  param { lr_mult: 0 decay_mult: 0 }
  scale_param {
    bias_term: false
  }
}

layer {
    bottom: "DenseNet16520or/loss_2D_008_008_ch068_multiplication"
    top: "DenseNet16520or/loss_2D_008_008_ch068_sum"
    name: "DenseNet16520or/loss_2D_008_008_ch068_sum"
    type:"Reduction"
    
    loss_weight: 1
}

#########################################
##### Part003 size008_008/rel/conv5 #####
#########################################
layer {
  name: "size008_008/rel/conv5_1/x1/bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "size008_008/rel/conv5_1/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_1/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_1/x1/bn"
  top: "size008_008/rel/conv5_1/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_1/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_1/x1/bn"
  top: "size008_008/rel/conv5_1/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_1/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_1/x1/bn"
  top: "size008_008/rel/conv5_1/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_1/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_1/x1"
  top: "size008_008/rel/conv5_1/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_1/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_1/x2/bn"
  top: "size008_008/rel/conv5_1/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_1/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_1/x2/bn"
  top: "size008_008/rel/conv5_1/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_1/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_1/x2/bn"
  top: "size008_008/rel/conv5_1/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_1"
  type: "Concat"
  bottom: "pool4"
  bottom: "size008_008/rel/conv5_1/x2"
  top: "size008_008/rel/concat_5_1"
}
layer {
  name: "size008_008/rel/conv5_2/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_1"
  top: "size008_008/rel/conv5_2/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_2/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_2/x1/bn"
  top: "size008_008/rel/conv5_2/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_2/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_2/x1/bn"
  top: "size008_008/rel/conv5_2/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_2/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_2/x1/bn"
  top: "size008_008/rel/conv5_2/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_2/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_2/x1"
  top: "size008_008/rel/conv5_2/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_2/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_2/x2/bn"
  top: "size008_008/rel/conv5_2/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_2/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_2/x2/bn"
  top: "size008_008/rel/conv5_2/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_2/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_2/x2/bn"
  top: "size008_008/rel/conv5_2/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_2"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_1"
  bottom: "size008_008/rel/conv5_2/x2"
  top: "size008_008/rel/concat_5_2"
}
layer {
  name: "size008_008/rel/conv5_3/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_2"
  top: "size008_008/rel/conv5_3/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_3/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_3/x1/bn"
  top: "size008_008/rel/conv5_3/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_3/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_3/x1/bn"
  top: "size008_008/rel/conv5_3/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_3/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_3/x1/bn"
  top: "size008_008/rel/conv5_3/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_3/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_3/x1"
  top: "size008_008/rel/conv5_3/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_3/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_3/x2/bn"
  top: "size008_008/rel/conv5_3/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_3/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_3/x2/bn"
  top: "size008_008/rel/conv5_3/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_3/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_3/x2/bn"
  top: "size008_008/rel/conv5_3/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_3"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_2"
  bottom: "size008_008/rel/conv5_3/x2"
  top: "size008_008/rel/concat_5_3"
}
layer {
  name: "size008_008/rel/conv5_4/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_3"
  top: "size008_008/rel/conv5_4/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_4/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_4/x1/bn"
  top: "size008_008/rel/conv5_4/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_4/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_4/x1/bn"
  top: "size008_008/rel/conv5_4/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_4/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_4/x1/bn"
  top: "size008_008/rel/conv5_4/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_4/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_4/x1"
  top: "size008_008/rel/conv5_4/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_4/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_4/x2/bn"
  top: "size008_008/rel/conv5_4/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_4/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_4/x2/bn"
  top: "size008_008/rel/conv5_4/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_4/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_4/x2/bn"
  top: "size008_008/rel/conv5_4/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_4"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_3"
  bottom: "size008_008/rel/conv5_4/x2"
  top: "size008_008/rel/concat_5_4"
}
layer {
  name: "size008_008/rel/conv5_5/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_4"
  top: "size008_008/rel/conv5_5/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_5/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_5/x1/bn"
  top: "size008_008/rel/conv5_5/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_5/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_5/x1/bn"
  top: "size008_008/rel/conv5_5/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_5/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_5/x1/bn"
  top: "size008_008/rel/conv5_5/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_5/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_5/x1"
  top: "size008_008/rel/conv5_5/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_5/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_5/x2/bn"
  top: "size008_008/rel/conv5_5/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_5/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_5/x2/bn"
  top: "size008_008/rel/conv5_5/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_5/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_5/x2/bn"
  top: "size008_008/rel/conv5_5/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_5"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_4"
  bottom: "size008_008/rel/conv5_5/x2"
  top: "size008_008/rel/concat_5_5"
}
layer {
  name: "size008_008/rel/conv5_6/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_5"
  top: "size008_008/rel/conv5_6/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_6/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_6/x1/bn"
  top: "size008_008/rel/conv5_6/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_6/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_6/x1/bn"
  top: "size008_008/rel/conv5_6/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_6/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_6/x1/bn"
  top: "size008_008/rel/conv5_6/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_6/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_6/x1"
  top: "size008_008/rel/conv5_6/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_6/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_6/x2/bn"
  top: "size008_008/rel/conv5_6/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_6/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_6/x2/bn"
  top: "size008_008/rel/conv5_6/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_6/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_6/x2/bn"
  top: "size008_008/rel/conv5_6/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_6"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_5"
  bottom: "size008_008/rel/conv5_6/x2"
  top: "size008_008/rel/concat_5_6"
}
layer {
  name: "size008_008/rel/conv5_7/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_6"
  top: "size008_008/rel/conv5_7/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_7/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_7/x1/bn"
  top: "size008_008/rel/conv5_7/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_7/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_7/x1/bn"
  top: "size008_008/rel/conv5_7/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_7/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_7/x1/bn"
  top: "size008_008/rel/conv5_7/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_7/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_7/x1"
  top: "size008_008/rel/conv5_7/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_7/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_7/x2/bn"
  top: "size008_008/rel/conv5_7/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_7/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_7/x2/bn"
  top: "size008_008/rel/conv5_7/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_7/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_7/x2/bn"
  top: "size008_008/rel/conv5_7/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_7"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_6"
  bottom: "size008_008/rel/conv5_7/x2"
  top: "size008_008/rel/concat_5_7"
}
layer {
  name: "size008_008/rel/conv5_8/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_7"
  top: "size008_008/rel/conv5_8/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_8/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_8/x1/bn"
  top: "size008_008/rel/conv5_8/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_8/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_8/x1/bn"
  top: "size008_008/rel/conv5_8/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_8/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_8/x1/bn"
  top: "size008_008/rel/conv5_8/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_8/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_8/x1"
  top: "size008_008/rel/conv5_8/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_8/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_8/x2/bn"
  top: "size008_008/rel/conv5_8/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_8/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_8/x2/bn"
  top: "size008_008/rel/conv5_8/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_8/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_8/x2/bn"
  top: "size008_008/rel/conv5_8/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_8"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_7"
  bottom: "size008_008/rel/conv5_8/x2"
  top: "size008_008/rel/concat_5_8"
}
layer {
  name: "size008_008/rel/conv5_9/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_8"
  top: "size008_008/rel/conv5_9/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_9/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_9/x1/bn"
  top: "size008_008/rel/conv5_9/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_9/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_9/x1/bn"
  top: "size008_008/rel/conv5_9/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_9/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_9/x1/bn"
  top: "size008_008/rel/conv5_9/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_9/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_9/x1"
  top: "size008_008/rel/conv5_9/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_9/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_9/x2/bn"
  top: "size008_008/rel/conv5_9/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_9/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_9/x2/bn"
  top: "size008_008/rel/conv5_9/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_9/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_9/x2/bn"
  top: "size008_008/rel/conv5_9/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_9"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_8"
  bottom: "size008_008/rel/conv5_9/x2"
  top: "size008_008/rel/concat_5_9"
}
layer {
  name: "size008_008/rel/conv5_10/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_9"
  top: "size008_008/rel/conv5_10/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_10/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_10/x1/bn"
  top: "size008_008/rel/conv5_10/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_10/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_10/x1/bn"
  top: "size008_008/rel/conv5_10/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_10/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_10/x1/bn"
  top: "size008_008/rel/conv5_10/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_10/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_10/x1"
  top: "size008_008/rel/conv5_10/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_10/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_10/x2/bn"
  top: "size008_008/rel/conv5_10/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_10/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_10/x2/bn"
  top: "size008_008/rel/conv5_10/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_10/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_10/x2/bn"
  top: "size008_008/rel/conv5_10/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_10"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_9"
  bottom: "size008_008/rel/conv5_10/x2"
  top: "size008_008/rel/concat_5_10"
}
layer {
  name: "size008_008/rel/conv5_11/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_10"
  top: "size008_008/rel/conv5_11/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_11/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_11/x1/bn"
  top: "size008_008/rel/conv5_11/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_11/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_11/x1/bn"
  top: "size008_008/rel/conv5_11/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_11/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_11/x1/bn"
  top: "size008_008/rel/conv5_11/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_11/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_11/x1"
  top: "size008_008/rel/conv5_11/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_11/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_11/x2/bn"
  top: "size008_008/rel/conv5_11/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_11/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_11/x2/bn"
  top: "size008_008/rel/conv5_11/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_11/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_11/x2/bn"
  top: "size008_008/rel/conv5_11/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_11"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_10"
  bottom: "size008_008/rel/conv5_11/x2"
  top: "size008_008/rel/concat_5_11"
}
layer {
  name: "size008_008/rel/conv5_12/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_11"
  top: "size008_008/rel/conv5_12/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_12/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_12/x1/bn"
  top: "size008_008/rel/conv5_12/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_12/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_12/x1/bn"
  top: "size008_008/rel/conv5_12/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_12/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_12/x1/bn"
  top: "size008_008/rel/conv5_12/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_12/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_12/x1"
  top: "size008_008/rel/conv5_12/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_12/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_12/x2/bn"
  top: "size008_008/rel/conv5_12/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_12/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_12/x2/bn"
  top: "size008_008/rel/conv5_12/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_12/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_12/x2/bn"
  top: "size008_008/rel/conv5_12/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_12"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_11"
  bottom: "size008_008/rel/conv5_12/x2"
  top: "size008_008/rel/concat_5_12"
}
layer {
  name: "size008_008/rel/conv5_13/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_12"
  top: "size008_008/rel/conv5_13/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_13/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_13/x1/bn"
  top: "size008_008/rel/conv5_13/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_13/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_13/x1/bn"
  top: "size008_008/rel/conv5_13/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_13/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_13/x1/bn"
  top: "size008_008/rel/conv5_13/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_13/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_13/x1"
  top: "size008_008/rel/conv5_13/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_13/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_13/x2/bn"
  top: "size008_008/rel/conv5_13/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_13/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_13/x2/bn"
  top: "size008_008/rel/conv5_13/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_13/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_13/x2/bn"
  top: "size008_008/rel/conv5_13/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_13"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_12"
  bottom: "size008_008/rel/conv5_13/x2"
  top: "size008_008/rel/concat_5_13"
}
layer {
  name: "size008_008/rel/conv5_14/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_13"
  top: "size008_008/rel/conv5_14/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_14/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_14/x1/bn"
  top: "size008_008/rel/conv5_14/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_14/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_14/x1/bn"
  top: "size008_008/rel/conv5_14/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_14/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_14/x1/bn"
  top: "size008_008/rel/conv5_14/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_14/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_14/x1"
  top: "size008_008/rel/conv5_14/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_14/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_14/x2/bn"
  top: "size008_008/rel/conv5_14/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_14/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_14/x2/bn"
  top: "size008_008/rel/conv5_14/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_14/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_14/x2/bn"
  top: "size008_008/rel/conv5_14/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_14"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_13"
  bottom: "size008_008/rel/conv5_14/x2"
  top: "size008_008/rel/concat_5_14"
}
layer {
  name: "size008_008/rel/conv5_15/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_14"
  top: "size008_008/rel/conv5_15/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_15/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_15/x1/bn"
  top: "size008_008/rel/conv5_15/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_15/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_15/x1/bn"
  top: "size008_008/rel/conv5_15/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_15/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_15/x1/bn"
  top: "size008_008/rel/conv5_15/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_15/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_15/x1"
  top: "size008_008/rel/conv5_15/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_15/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_15/x2/bn"
  top: "size008_008/rel/conv5_15/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_15/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_15/x2/bn"
  top: "size008_008/rel/conv5_15/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_15/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_15/x2/bn"
  top: "size008_008/rel/conv5_15/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_15"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_14"
  bottom: "size008_008/rel/conv5_15/x2"
  top: "size008_008/rel/concat_5_15"
}
layer {
  name: "size008_008/rel/conv5_16/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_15"
  top: "size008_008/rel/conv5_16/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_16/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_16/x1/bn"
  top: "size008_008/rel/conv5_16/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_16/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_16/x1/bn"
  top: "size008_008/rel/conv5_16/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_16/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_16/x1/bn"
  top: "size008_008/rel/conv5_16/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_16/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_16/x1"
  top: "size008_008/rel/conv5_16/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_16/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_16/x2/bn"
  top: "size008_008/rel/conv5_16/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_16/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_16/x2/bn"
  top: "size008_008/rel/conv5_16/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_16/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_16/x2/bn"
  top: "size008_008/rel/conv5_16/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_16"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_15"
  bottom: "size008_008/rel/conv5_16/x2"
  top: "size008_008/rel/concat_5_16"
}
layer {
  name: "size008_008/rel/conv5_17/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_16"
  top: "size008_008/rel/conv5_17/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_17/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_17/x1/bn"
  top: "size008_008/rel/conv5_17/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_17/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_17/x1/bn"
  top: "size008_008/rel/conv5_17/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_17/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_17/x1/bn"
  top: "size008_008/rel/conv5_17/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_17/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_17/x1"
  top: "size008_008/rel/conv5_17/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_17/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_17/x2/bn"
  top: "size008_008/rel/conv5_17/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_17/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_17/x2/bn"
  top: "size008_008/rel/conv5_17/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_17/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_17/x2/bn"
  top: "size008_008/rel/conv5_17/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_17"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_16"
  bottom: "size008_008/rel/conv5_17/x2"
  top: "size008_008/rel/concat_5_17"
}
layer {
  name: "size008_008/rel/conv5_18/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_17"
  top: "size008_008/rel/conv5_18/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_18/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_18/x1/bn"
  top: "size008_008/rel/conv5_18/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_18/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_18/x1/bn"
  top: "size008_008/rel/conv5_18/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_18/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_18/x1/bn"
  top: "size008_008/rel/conv5_18/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_18/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_18/x1"
  top: "size008_008/rel/conv5_18/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_18/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_18/x2/bn"
  top: "size008_008/rel/conv5_18/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_18/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_18/x2/bn"
  top: "size008_008/rel/conv5_18/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_18/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_18/x2/bn"
  top: "size008_008/rel/conv5_18/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_18"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_17"
  bottom: "size008_008/rel/conv5_18/x2"
  top: "size008_008/rel/concat_5_18"
}
layer {
  name: "size008_008/rel/conv5_19/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_18"
  top: "size008_008/rel/conv5_19/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_19/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_19/x1/bn"
  top: "size008_008/rel/conv5_19/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_19/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_19/x1/bn"
  top: "size008_008/rel/conv5_19/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_19/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_19/x1/bn"
  top: "size008_008/rel/conv5_19/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_19/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_19/x1"
  top: "size008_008/rel/conv5_19/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_19/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_19/x2/bn"
  top: "size008_008/rel/conv5_19/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_19/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_19/x2/bn"
  top: "size008_008/rel/conv5_19/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_19/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_19/x2/bn"
  top: "size008_008/rel/conv5_19/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_19"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_18"
  bottom: "size008_008/rel/conv5_19/x2"
  top: "size008_008/rel/concat_5_19"
}
layer {
  name: "size008_008/rel/conv5_20/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_19"
  top: "size008_008/rel/conv5_20/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_20/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_20/x1/bn"
  top: "size008_008/rel/conv5_20/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_20/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_20/x1/bn"
  top: "size008_008/rel/conv5_20/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_20/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_20/x1/bn"
  top: "size008_008/rel/conv5_20/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_20/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_20/x1"
  top: "size008_008/rel/conv5_20/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_20/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_20/x2/bn"
  top: "size008_008/rel/conv5_20/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_20/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_20/x2/bn"
  top: "size008_008/rel/conv5_20/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_20/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_20/x2/bn"
  top: "size008_008/rel/conv5_20/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_20"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_19"
  bottom: "size008_008/rel/conv5_20/x2"
  top: "size008_008/rel/concat_5_20"
}
layer {
  name: "size008_008/rel/conv5_21/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_20"
  top: "size008_008/rel/conv5_21/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_21/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_21/x1/bn"
  top: "size008_008/rel/conv5_21/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_21/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_21/x1/bn"
  top: "size008_008/rel/conv5_21/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_21/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_21/x1/bn"
  top: "size008_008/rel/conv5_21/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_21/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_21/x1"
  top: "size008_008/rel/conv5_21/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_21/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_21/x2/bn"
  top: "size008_008/rel/conv5_21/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_21/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_21/x2/bn"
  top: "size008_008/rel/conv5_21/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_21/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_21/x2/bn"
  top: "size008_008/rel/conv5_21/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_21"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_20"
  bottom: "size008_008/rel/conv5_21/x2"
  top: "size008_008/rel/concat_5_21"
}
layer {
  name: "size008_008/rel/conv5_22/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_21"
  top: "size008_008/rel/conv5_22/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_22/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_22/x1/bn"
  top: "size008_008/rel/conv5_22/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_22/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_22/x1/bn"
  top: "size008_008/rel/conv5_22/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_22/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_22/x1/bn"
  top: "size008_008/rel/conv5_22/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_22/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_22/x1"
  top: "size008_008/rel/conv5_22/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_22/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_22/x2/bn"
  top: "size008_008/rel/conv5_22/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_22/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_22/x2/bn"
  top: "size008_008/rel/conv5_22/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_22/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_22/x2/bn"
  top: "size008_008/rel/conv5_22/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_22"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_21"
  bottom: "size008_008/rel/conv5_22/x2"
  top: "size008_008/rel/concat_5_22"
}
layer {
  name: "size008_008/rel/conv5_23/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_22"
  top: "size008_008/rel/conv5_23/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_23/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_23/x1/bn"
  top: "size008_008/rel/conv5_23/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_23/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_23/x1/bn"
  top: "size008_008/rel/conv5_23/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_23/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_23/x1/bn"
  top: "size008_008/rel/conv5_23/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_23/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_23/x1"
  top: "size008_008/rel/conv5_23/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_23/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_23/x2/bn"
  top: "size008_008/rel/conv5_23/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_23/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_23/x2/bn"
  top: "size008_008/rel/conv5_23/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_23/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_23/x2/bn"
  top: "size008_008/rel/conv5_23/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_23"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_22"
  bottom: "size008_008/rel/conv5_23/x2"
  top: "size008_008/rel/concat_5_23"
}
layer {
  name: "size008_008/rel/conv5_24/x1/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_23"
  top: "size008_008/rel/conv5_24/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_24/x1/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_24/x1/bn"
  top: "size008_008/rel/conv5_24/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_24/x1"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_24/x1/bn"
  top: "size008_008/rel/conv5_24/x1/bn"
}
layer {
  name: "size008_008/rel/conv5_24/x1"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_24/x1/bn"
  top: "size008_008/rel/conv5_24/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size008_008/rel/conv5_24/x2/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/conv5_24/x1"
  top: "size008_008/rel/conv5_24/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_24/x2/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_24/x2/bn"
  top: "size008_008/rel/conv5_24/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_24/x2"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_24/x2/bn"
  top: "size008_008/rel/conv5_24/x2/bn"
}
layer {
  name: "size008_008/rel/conv5_24/x2"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_24/x2/bn"
  top: "size008_008/rel/conv5_24/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size008_008/rel/concat_5_24"
  type: "Concat"
  bottom: "size008_008/rel/concat_5_23"
  bottom: "size008_008/rel/conv5_24/x2"
  top: "size008_008/rel/concat_5_24"
}
layer {
  name: "size008_008/rel/conv5_blk/bn"
  type: "BatchNorm"
  bottom: "size008_008/rel/concat_5_24"
  top: "size008_008/rel/conv5_blk/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size008_008/rel/conv5_blk/scale"
  type: "Scale"
  bottom: "size008_008/rel/conv5_blk/bn"
  top: "size008_008/rel/conv5_blk/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size008_008/rel/relu5_blk"
  type: "ReLU"
  bottom: "size008_008/rel/conv5_blk/bn"
  top: "size008_008/rel/conv5_blk/bn"
}


#################################################
##### Part004 loss at size008_008/rel/conv5 #####
#################################################
layer {
  name: "DenseNet16521or/pred_2D_008_008_ch2560_true"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_blk/bn"
  top: "DenseNet16521or/pred_2D_008_008_ch2560_true"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 2560
    kernel_size: 1
    weight_filler{
      type: "xavier"
    }
  }
  
}

layer {
  name: "DenseNet16521or/pred_2D_008_008_ch2560_false"
  type: "Convolution"
  bottom: "size008_008/rel/conv5_blk/bn"
  top: "DenseNet16521or/pred_2D_008_008_ch2560_false"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 2560
    kernel_size: 1
    weight_filler{
      type: "xavier"
    }
  }
}

layer {
  bottom: "DenseNet16521or/pred_2D_008_008_ch2560_true"
  bottom: "DenseNet16521or/pred_2D_008_008_ch2560_false"
  top: "DenseNet16521or/pred_2D_008_008_ch2560_true_false_gap"
  name: "DenseNet16521or/pred_2D_008_008_ch2560_true_false_gap"
  type: "Eltwise"
  eltwise_param {
        operation: 1 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
        coeff: 1
        coeff: -1
  }
}

layer {
  name: "DenseNet16521or/pred_2D_008_008_ch2560"
  type: "Sigmoid"
  bottom: "DenseNet16521or/pred_2D_008_008_ch2560_true_false_gap"
  top: "DenseNet16521or/pred_2D_008_008_ch2560"
}

layer {
    name: "DenseNet16521or/pred_2D_008_008_ch2560_norm"
    bottom: "DenseNet16521or/pred_2D_008_008_ch2560"
    top: "DenseNet16521or/pred_2D_008_008_ch2560_norm"
    type: "Power"
    power_param {
        power: 1
        scale: 0.999990
        shift: 0.000005
    }
}

layer {
    name: "DenseNet16521or/pred_2D_008_008_ch2560_norm_inverse"
    bottom: "DenseNet16521or/pred_2D_008_008_ch2560_norm"
    top: "DenseNet16521or/pred_2D_008_008_ch2560_norm_inverse"
    type: "Power"
    power_param {
        power: 1
        scale: -1
        shift: 1
    }
}

layer {
    name: "DenseNet16521or/pred_2D_008_008_ch2560_log"
    bottom: "DenseNet16521or/pred_2D_008_008_ch2560_norm"
    top: "DenseNet16521or/pred_2D_008_008_ch2560_log"
    type: "Log"
    log_param {
        base: -1 # default(=-1) -> base is set to e
        scale: 1
        shift: 0
    }
}

layer {
    name: "DenseNet16521or/pred_2D_008_008_ch2560_inverse_log"
    bottom: "DenseNet16521or/pred_2D_008_008_ch2560_norm_inverse"
    top: "DenseNet16521or/pred_2D_008_008_ch2560_inverse_log"
    type: "Log"
    log_param {
        base: -1 # default(=-1) -> base is set to e
        scale: 1
        shift: 0
    }
}

layer {
  bottom: "DenseNet16521or/pred_2D_008_008_ch2560_log"
  bottom: "label_008_008_ch2560"
  top: "DenseNet16521or/loss_2D_008_008_ch2560_true"
  name: "DenseNet16521or/loss_2D_008_008_ch2560_true"
  type: "Eltwise" # Eltwise(PROD)
  eltwise_param {
        operation: 0 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
  }
}

layer {
  bottom: "DenseNet16521or/pred_2D_008_008_ch2560_inverse_log"
  bottom: "label_008_008_ch2560_inverse"
  top: "DenseNet16521or/loss_2D_008_008_ch2560_false"
  name: "DenseNet16521or/loss_2D_008_008_ch2560_false"
  type: "Eltwise" # Eltwise(PROD)
  eltwise_param {
        operation: 0 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
  }
}

layer {
  bottom: "DenseNet16521or/loss_2D_008_008_ch2560_true"
  bottom: "DenseNet16521or/loss_2D_008_008_ch2560_false"
  top: "DenseNet16521or/loss_2D_008_008_ch2560"
  name: "DenseNet16521or/loss_2D_008_008_ch2560"
  type: "Eltwise"
  eltwise_param {
        operation: 1 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
        coeff: -1
        coeff: -1
  }
}

layer {
    name: "DenseNet16521or/loss_2D_008_008_ch2560_size_norm"
    bottom: "DenseNet16521or/loss_2D_008_008_ch2560"
    top: "DenseNet16521or/loss_2D_008_008_ch2560_size_norm"
    type: "Power"
    power_param {
        power: 1
        scale: 0.015625 # output 1/(H x W) = 1/(8 x 8) = 0.015625
        shift: 0
    }
}

layer { ## Requires user to set loss scale (For setting lr at each epoch)
  name: "DenseNet16521or/loss_2D_008_008_ch2560_multiplication"
  type: "Scale"
  bottom: "DenseNet16521or/loss_2D_008_008_ch2560_size_norm"
  top: "DenseNet16521or/loss_2D_008_008_ch2560_multiplication"
  param { lr_mult: 0 decay_mult: 0 }
  scale_param {
    bias_term: false
  }
}

layer {
    bottom: "DenseNet16521or/loss_2D_008_008_ch2560_multiplication"
    top: "DenseNet16521or/loss_2D_008_008_ch2560_sum"
    name: "DenseNet16521or/loss_2D_008_008_ch2560_sum"
    type:"Reduction"
    
    loss_weight: 1
}

#########################################
##### Part003 size016_016/rel/conv5 #####
#########################################
layer {
  name: "size016_016/rel/conv5_1/x1/bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "size016_016/rel/conv5_1/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_1/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_1/x1/bn"
  top: "size016_016/rel/conv5_1/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_1/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_1/x1/bn"
  top: "size016_016/rel/conv5_1/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_1/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_1/x1/bn"
  top: "size016_016/rel/conv5_1/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_1/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_1/x1"
  top: "size016_016/rel/conv5_1/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_1/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_1/x2/bn"
  top: "size016_016/rel/conv5_1/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_1/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_1/x2/bn"
  top: "size016_016/rel/conv5_1/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_1/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_1/x2/bn"
  top: "size016_016/rel/conv5_1/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_1"
  type: "Concat"
  bottom: "pool4"
  bottom: "size016_016/rel/conv5_1/x2"
  top: "size016_016/rel/concat_5_1"
}
layer {
  name: "size016_016/rel/conv5_2/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_1"
  top: "size016_016/rel/conv5_2/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_2/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_2/x1/bn"
  top: "size016_016/rel/conv5_2/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_2/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_2/x1/bn"
  top: "size016_016/rel/conv5_2/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_2/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_2/x1/bn"
  top: "size016_016/rel/conv5_2/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_2/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_2/x1"
  top: "size016_016/rel/conv5_2/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_2/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_2/x2/bn"
  top: "size016_016/rel/conv5_2/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_2/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_2/x2/bn"
  top: "size016_016/rel/conv5_2/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_2/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_2/x2/bn"
  top: "size016_016/rel/conv5_2/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_2"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_1"
  bottom: "size016_016/rel/conv5_2/x2"
  top: "size016_016/rel/concat_5_2"
}
layer {
  name: "size016_016/rel/conv5_3/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_2"
  top: "size016_016/rel/conv5_3/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_3/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_3/x1/bn"
  top: "size016_016/rel/conv5_3/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_3/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_3/x1/bn"
  top: "size016_016/rel/conv5_3/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_3/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_3/x1/bn"
  top: "size016_016/rel/conv5_3/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_3/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_3/x1"
  top: "size016_016/rel/conv5_3/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_3/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_3/x2/bn"
  top: "size016_016/rel/conv5_3/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_3/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_3/x2/bn"
  top: "size016_016/rel/conv5_3/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_3/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_3/x2/bn"
  top: "size016_016/rel/conv5_3/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_3"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_2"
  bottom: "size016_016/rel/conv5_3/x2"
  top: "size016_016/rel/concat_5_3"
}
layer {
  name: "size016_016/rel/conv5_4/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_3"
  top: "size016_016/rel/conv5_4/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_4/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_4/x1/bn"
  top: "size016_016/rel/conv5_4/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_4/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_4/x1/bn"
  top: "size016_016/rel/conv5_4/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_4/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_4/x1/bn"
  top: "size016_016/rel/conv5_4/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_4/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_4/x1"
  top: "size016_016/rel/conv5_4/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_4/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_4/x2/bn"
  top: "size016_016/rel/conv5_4/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_4/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_4/x2/bn"
  top: "size016_016/rel/conv5_4/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_4/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_4/x2/bn"
  top: "size016_016/rel/conv5_4/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_4"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_3"
  bottom: "size016_016/rel/conv5_4/x2"
  top: "size016_016/rel/concat_5_4"
}
layer {
  name: "size016_016/rel/conv5_5/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_4"
  top: "size016_016/rel/conv5_5/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_5/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_5/x1/bn"
  top: "size016_016/rel/conv5_5/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_5/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_5/x1/bn"
  top: "size016_016/rel/conv5_5/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_5/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_5/x1/bn"
  top: "size016_016/rel/conv5_5/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_5/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_5/x1"
  top: "size016_016/rel/conv5_5/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_5/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_5/x2/bn"
  top: "size016_016/rel/conv5_5/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_5/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_5/x2/bn"
  top: "size016_016/rel/conv5_5/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_5/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_5/x2/bn"
  top: "size016_016/rel/conv5_5/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_5"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_4"
  bottom: "size016_016/rel/conv5_5/x2"
  top: "size016_016/rel/concat_5_5"
}
layer {
  name: "size016_016/rel/conv5_6/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_5"
  top: "size016_016/rel/conv5_6/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_6/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_6/x1/bn"
  top: "size016_016/rel/conv5_6/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_6/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_6/x1/bn"
  top: "size016_016/rel/conv5_6/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_6/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_6/x1/bn"
  top: "size016_016/rel/conv5_6/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_6/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_6/x1"
  top: "size016_016/rel/conv5_6/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_6/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_6/x2/bn"
  top: "size016_016/rel/conv5_6/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_6/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_6/x2/bn"
  top: "size016_016/rel/conv5_6/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_6/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_6/x2/bn"
  top: "size016_016/rel/conv5_6/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_6"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_5"
  bottom: "size016_016/rel/conv5_6/x2"
  top: "size016_016/rel/concat_5_6"
}
layer {
  name: "size016_016/rel/conv5_7/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_6"
  top: "size016_016/rel/conv5_7/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_7/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_7/x1/bn"
  top: "size016_016/rel/conv5_7/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_7/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_7/x1/bn"
  top: "size016_016/rel/conv5_7/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_7/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_7/x1/bn"
  top: "size016_016/rel/conv5_7/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_7/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_7/x1"
  top: "size016_016/rel/conv5_7/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_7/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_7/x2/bn"
  top: "size016_016/rel/conv5_7/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_7/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_7/x2/bn"
  top: "size016_016/rel/conv5_7/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_7/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_7/x2/bn"
  top: "size016_016/rel/conv5_7/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_7"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_6"
  bottom: "size016_016/rel/conv5_7/x2"
  top: "size016_016/rel/concat_5_7"
}
layer {
  name: "size016_016/rel/conv5_8/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_7"
  top: "size016_016/rel/conv5_8/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_8/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_8/x1/bn"
  top: "size016_016/rel/conv5_8/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_8/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_8/x1/bn"
  top: "size016_016/rel/conv5_8/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_8/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_8/x1/bn"
  top: "size016_016/rel/conv5_8/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_8/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_8/x1"
  top: "size016_016/rel/conv5_8/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_8/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_8/x2/bn"
  top: "size016_016/rel/conv5_8/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_8/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_8/x2/bn"
  top: "size016_016/rel/conv5_8/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_8/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_8/x2/bn"
  top: "size016_016/rel/conv5_8/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_8"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_7"
  bottom: "size016_016/rel/conv5_8/x2"
  top: "size016_016/rel/concat_5_8"
}
layer {
  name: "size016_016/rel/conv5_9/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_8"
  top: "size016_016/rel/conv5_9/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_9/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_9/x1/bn"
  top: "size016_016/rel/conv5_9/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_9/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_9/x1/bn"
  top: "size016_016/rel/conv5_9/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_9/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_9/x1/bn"
  top: "size016_016/rel/conv5_9/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_9/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_9/x1"
  top: "size016_016/rel/conv5_9/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_9/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_9/x2/bn"
  top: "size016_016/rel/conv5_9/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_9/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_9/x2/bn"
  top: "size016_016/rel/conv5_9/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_9/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_9/x2/bn"
  top: "size016_016/rel/conv5_9/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_9"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_8"
  bottom: "size016_016/rel/conv5_9/x2"
  top: "size016_016/rel/concat_5_9"
}
layer {
  name: "size016_016/rel/conv5_10/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_9"
  top: "size016_016/rel/conv5_10/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_10/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_10/x1/bn"
  top: "size016_016/rel/conv5_10/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_10/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_10/x1/bn"
  top: "size016_016/rel/conv5_10/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_10/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_10/x1/bn"
  top: "size016_016/rel/conv5_10/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_10/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_10/x1"
  top: "size016_016/rel/conv5_10/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_10/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_10/x2/bn"
  top: "size016_016/rel/conv5_10/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_10/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_10/x2/bn"
  top: "size016_016/rel/conv5_10/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_10/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_10/x2/bn"
  top: "size016_016/rel/conv5_10/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_10"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_9"
  bottom: "size016_016/rel/conv5_10/x2"
  top: "size016_016/rel/concat_5_10"
}
layer {
  name: "size016_016/rel/conv5_11/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_10"
  top: "size016_016/rel/conv5_11/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_11/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_11/x1/bn"
  top: "size016_016/rel/conv5_11/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_11/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_11/x1/bn"
  top: "size016_016/rel/conv5_11/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_11/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_11/x1/bn"
  top: "size016_016/rel/conv5_11/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_11/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_11/x1"
  top: "size016_016/rel/conv5_11/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_11/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_11/x2/bn"
  top: "size016_016/rel/conv5_11/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_11/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_11/x2/bn"
  top: "size016_016/rel/conv5_11/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_11/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_11/x2/bn"
  top: "size016_016/rel/conv5_11/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_11"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_10"
  bottom: "size016_016/rel/conv5_11/x2"
  top: "size016_016/rel/concat_5_11"
}
layer {
  name: "size016_016/rel/conv5_12/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_11"
  top: "size016_016/rel/conv5_12/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_12/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_12/x1/bn"
  top: "size016_016/rel/conv5_12/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_12/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_12/x1/bn"
  top: "size016_016/rel/conv5_12/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_12/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_12/x1/bn"
  top: "size016_016/rel/conv5_12/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_12/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_12/x1"
  top: "size016_016/rel/conv5_12/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_12/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_12/x2/bn"
  top: "size016_016/rel/conv5_12/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_12/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_12/x2/bn"
  top: "size016_016/rel/conv5_12/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_12/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_12/x2/bn"
  top: "size016_016/rel/conv5_12/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_12"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_11"
  bottom: "size016_016/rel/conv5_12/x2"
  top: "size016_016/rel/concat_5_12"
}
layer {
  name: "size016_016/rel/conv5_13/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_12"
  top: "size016_016/rel/conv5_13/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_13/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_13/x1/bn"
  top: "size016_016/rel/conv5_13/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_13/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_13/x1/bn"
  top: "size016_016/rel/conv5_13/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_13/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_13/x1/bn"
  top: "size016_016/rel/conv5_13/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_13/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_13/x1"
  top: "size016_016/rel/conv5_13/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_13/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_13/x2/bn"
  top: "size016_016/rel/conv5_13/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_13/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_13/x2/bn"
  top: "size016_016/rel/conv5_13/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_13/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_13/x2/bn"
  top: "size016_016/rel/conv5_13/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_13"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_12"
  bottom: "size016_016/rel/conv5_13/x2"
  top: "size016_016/rel/concat_5_13"
}
layer {
  name: "size016_016/rel/conv5_14/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_13"
  top: "size016_016/rel/conv5_14/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_14/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_14/x1/bn"
  top: "size016_016/rel/conv5_14/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_14/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_14/x1/bn"
  top: "size016_016/rel/conv5_14/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_14/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_14/x1/bn"
  top: "size016_016/rel/conv5_14/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_14/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_14/x1"
  top: "size016_016/rel/conv5_14/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_14/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_14/x2/bn"
  top: "size016_016/rel/conv5_14/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_14/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_14/x2/bn"
  top: "size016_016/rel/conv5_14/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_14/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_14/x2/bn"
  top: "size016_016/rel/conv5_14/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_14"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_13"
  bottom: "size016_016/rel/conv5_14/x2"
  top: "size016_016/rel/concat_5_14"
}
layer {
  name: "size016_016/rel/conv5_15/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_14"
  top: "size016_016/rel/conv5_15/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_15/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_15/x1/bn"
  top: "size016_016/rel/conv5_15/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_15/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_15/x1/bn"
  top: "size016_016/rel/conv5_15/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_15/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_15/x1/bn"
  top: "size016_016/rel/conv5_15/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_15/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_15/x1"
  top: "size016_016/rel/conv5_15/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_15/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_15/x2/bn"
  top: "size016_016/rel/conv5_15/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_15/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_15/x2/bn"
  top: "size016_016/rel/conv5_15/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_15/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_15/x2/bn"
  top: "size016_016/rel/conv5_15/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_15"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_14"
  bottom: "size016_016/rel/conv5_15/x2"
  top: "size016_016/rel/concat_5_15"
}
layer {
  name: "size016_016/rel/conv5_16/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_15"
  top: "size016_016/rel/conv5_16/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_16/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_16/x1/bn"
  top: "size016_016/rel/conv5_16/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_16/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_16/x1/bn"
  top: "size016_016/rel/conv5_16/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_16/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_16/x1/bn"
  top: "size016_016/rel/conv5_16/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_16/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_16/x1"
  top: "size016_016/rel/conv5_16/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_16/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_16/x2/bn"
  top: "size016_016/rel/conv5_16/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_16/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_16/x2/bn"
  top: "size016_016/rel/conv5_16/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_16/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_16/x2/bn"
  top: "size016_016/rel/conv5_16/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_16"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_15"
  bottom: "size016_016/rel/conv5_16/x2"
  top: "size016_016/rel/concat_5_16"
}
layer {
  name: "size016_016/rel/conv5_17/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_16"
  top: "size016_016/rel/conv5_17/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_17/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_17/x1/bn"
  top: "size016_016/rel/conv5_17/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_17/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_17/x1/bn"
  top: "size016_016/rel/conv5_17/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_17/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_17/x1/bn"
  top: "size016_016/rel/conv5_17/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_17/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_17/x1"
  top: "size016_016/rel/conv5_17/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_17/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_17/x2/bn"
  top: "size016_016/rel/conv5_17/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_17/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_17/x2/bn"
  top: "size016_016/rel/conv5_17/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_17/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_17/x2/bn"
  top: "size016_016/rel/conv5_17/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_17"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_16"
  bottom: "size016_016/rel/conv5_17/x2"
  top: "size016_016/rel/concat_5_17"
}
layer {
  name: "size016_016/rel/conv5_18/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_17"
  top: "size016_016/rel/conv5_18/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_18/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_18/x1/bn"
  top: "size016_016/rel/conv5_18/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_18/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_18/x1/bn"
  top: "size016_016/rel/conv5_18/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_18/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_18/x1/bn"
  top: "size016_016/rel/conv5_18/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_18/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_18/x1"
  top: "size016_016/rel/conv5_18/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_18/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_18/x2/bn"
  top: "size016_016/rel/conv5_18/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_18/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_18/x2/bn"
  top: "size016_016/rel/conv5_18/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_18/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_18/x2/bn"
  top: "size016_016/rel/conv5_18/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_18"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_17"
  bottom: "size016_016/rel/conv5_18/x2"
  top: "size016_016/rel/concat_5_18"
}
layer {
  name: "size016_016/rel/conv5_19/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_18"
  top: "size016_016/rel/conv5_19/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_19/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_19/x1/bn"
  top: "size016_016/rel/conv5_19/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_19/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_19/x1/bn"
  top: "size016_016/rel/conv5_19/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_19/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_19/x1/bn"
  top: "size016_016/rel/conv5_19/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_19/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_19/x1"
  top: "size016_016/rel/conv5_19/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_19/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_19/x2/bn"
  top: "size016_016/rel/conv5_19/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_19/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_19/x2/bn"
  top: "size016_016/rel/conv5_19/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_19/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_19/x2/bn"
  top: "size016_016/rel/conv5_19/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_19"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_18"
  bottom: "size016_016/rel/conv5_19/x2"
  top: "size016_016/rel/concat_5_19"
}
layer {
  name: "size016_016/rel/conv5_20/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_19"
  top: "size016_016/rel/conv5_20/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_20/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_20/x1/bn"
  top: "size016_016/rel/conv5_20/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_20/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_20/x1/bn"
  top: "size016_016/rel/conv5_20/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_20/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_20/x1/bn"
  top: "size016_016/rel/conv5_20/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_20/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_20/x1"
  top: "size016_016/rel/conv5_20/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_20/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_20/x2/bn"
  top: "size016_016/rel/conv5_20/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_20/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_20/x2/bn"
  top: "size016_016/rel/conv5_20/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_20/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_20/x2/bn"
  top: "size016_016/rel/conv5_20/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_20"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_19"
  bottom: "size016_016/rel/conv5_20/x2"
  top: "size016_016/rel/concat_5_20"
}
layer {
  name: "size016_016/rel/conv5_21/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_20"
  top: "size016_016/rel/conv5_21/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_21/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_21/x1/bn"
  top: "size016_016/rel/conv5_21/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_21/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_21/x1/bn"
  top: "size016_016/rel/conv5_21/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_21/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_21/x1/bn"
  top: "size016_016/rel/conv5_21/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_21/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_21/x1"
  top: "size016_016/rel/conv5_21/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_21/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_21/x2/bn"
  top: "size016_016/rel/conv5_21/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_21/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_21/x2/bn"
  top: "size016_016/rel/conv5_21/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_21/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_21/x2/bn"
  top: "size016_016/rel/conv5_21/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_21"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_20"
  bottom: "size016_016/rel/conv5_21/x2"
  top: "size016_016/rel/concat_5_21"
}
layer {
  name: "size016_016/rel/conv5_22/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_21"
  top: "size016_016/rel/conv5_22/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_22/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_22/x1/bn"
  top: "size016_016/rel/conv5_22/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_22/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_22/x1/bn"
  top: "size016_016/rel/conv5_22/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_22/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_22/x1/bn"
  top: "size016_016/rel/conv5_22/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_22/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_22/x1"
  top: "size016_016/rel/conv5_22/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_22/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_22/x2/bn"
  top: "size016_016/rel/conv5_22/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_22/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_22/x2/bn"
  top: "size016_016/rel/conv5_22/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_22/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_22/x2/bn"
  top: "size016_016/rel/conv5_22/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_22"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_21"
  bottom: "size016_016/rel/conv5_22/x2"
  top: "size016_016/rel/concat_5_22"
}
layer {
  name: "size016_016/rel/conv5_23/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_22"
  top: "size016_016/rel/conv5_23/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_23/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_23/x1/bn"
  top: "size016_016/rel/conv5_23/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_23/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_23/x1/bn"
  top: "size016_016/rel/conv5_23/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_23/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_23/x1/bn"
  top: "size016_016/rel/conv5_23/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_23/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_23/x1"
  top: "size016_016/rel/conv5_23/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_23/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_23/x2/bn"
  top: "size016_016/rel/conv5_23/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_23/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_23/x2/bn"
  top: "size016_016/rel/conv5_23/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_23/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_23/x2/bn"
  top: "size016_016/rel/conv5_23/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_23"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_22"
  bottom: "size016_016/rel/conv5_23/x2"
  top: "size016_016/rel/concat_5_23"
}
layer {
  name: "size016_016/rel/conv5_24/x1/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_23"
  top: "size016_016/rel/conv5_24/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_24/x1/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_24/x1/bn"
  top: "size016_016/rel/conv5_24/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_24/x1"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_24/x1/bn"
  top: "size016_016/rel/conv5_24/x1/bn"
}
layer {
  name: "size016_016/rel/conv5_24/x1"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_24/x1/bn"
  top: "size016_016/rel/conv5_24/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size016_016/rel/conv5_24/x2/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/conv5_24/x1"
  top: "size016_016/rel/conv5_24/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_24/x2/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_24/x2/bn"
  top: "size016_016/rel/conv5_24/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_24/x2"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_24/x2/bn"
  top: "size016_016/rel/conv5_24/x2/bn"
}
layer {
  name: "size016_016/rel/conv5_24/x2"
  type: "Convolution"
  bottom: "size016_016/rel/conv5_24/x2/bn"
  top: "size016_016/rel/conv5_24/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size016_016/rel/concat_5_24"
  type: "Concat"
  bottom: "size016_016/rel/concat_5_23"
  bottom: "size016_016/rel/conv5_24/x2"
  top: "size016_016/rel/concat_5_24"
}
layer {
  name: "size016_016/rel/conv5_blk/bn"
  type: "BatchNorm"
  bottom: "size016_016/rel/concat_5_24"
  top: "size016_016/rel/conv5_blk/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size016_016/rel/conv5_blk/scale"
  type: "Scale"
  bottom: "size016_016/rel/conv5_blk/bn"
  top: "size016_016/rel/conv5_blk/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size016_016/rel/relu5_blk"
  type: "ReLU"
  bottom: "size016_016/rel/conv5_blk/bn"
  top: "size016_016/rel/conv5_blk/bn"
}

###########################################################################
# size 2x  Inception
###########################################################################
layer {
    bottom: "size016_016/rel/conv5_blk/bn"
    top:    "size016_016/rel/x2_deconv"
    name:   "size016_016/rel/x2_deconv"
    type:   "Deconvolution" 
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 1664
        kernel_size: 4
        stride: 2
        pad: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}


# branch1
layer {
    bottom: "size016_016/rel/x2_deconv"
    top:    "size016_016/rel/x2_branch1_conv1"
    name:   "size016_016/rel/x2_branch1_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size016_016/rel/x2_branch1_conv1" top: "size016_016/rel/x2_branch1_conv1" name: "size016_016/rel/x2_branch1_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size016_016/rel/x2_branch1_conv1" top: "size016_016/rel/x2_branch1_conv1" name: "size016_016/rel/x2_branch1_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size016_016/rel/x2_branch1_conv1" top: "size016_016/rel/x2_branch1_conv1" name: "size016_016/rel/x2_branch1_relu1" type: "ReLU" }
# branch2
layer {
    bottom: "size016_016/rel/x2_deconv"
    top:    "size016_016/rel/x2_branch2_conv1"
    name:   "size016_016/rel/x2_branch2_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size016_016/rel/x2_branch2_conv1" top: "size016_016/rel/x2_branch2_conv1" name: "size016_016/rel/x2_branch2_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size016_016/rel/x2_branch2_conv1" top: "size016_016/rel/x2_branch2_conv1" name: "size016_016/rel/x2_branch2_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size016_016/rel/x2_branch2_conv1" top: "size016_016/rel/x2_branch2_conv1" name: "size016_016/rel/x2_branch2_relu1" type: "ReLU" }
layer {
    bottom: "size016_016/rel/x2_branch2_conv1"
    top:    "size016_016/rel/x2_branch2_conv2"
    name:   "size016_016/rel/x2_branch2_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size016_016/rel/x2_branch2_conv2" top: "size016_016/rel/x2_branch2_conv2" name: "size016_016/rel/x2_branch2_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size016_016/rel/x2_branch2_conv2" top: "size016_016/rel/x2_branch2_conv2" name: "size016_016/rel/x2_branch2_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size016_016/rel/x2_branch2_conv2" top: "size016_016/rel/x2_branch2_conv2" name: "size016_016/rel/x2_branch2_relu2" type: "ReLU" }
# branch3
layer {
    bottom: "size016_016/rel/x2_deconv"
    top:    "size016_016/rel/x2_branch3_conv1"
    name:   "size016_016/rel/x2_branch3_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size016_016/rel/x2_branch3_conv1" top: "size016_016/rel/x2_branch3_conv1" name: "size016_016/rel/x2_branch3_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size016_016/rel/x2_branch3_conv1" top: "size016_016/rel/x2_branch3_conv1" name: "size016_016/rel/x2_branch3_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size016_016/rel/x2_branch3_conv1" top: "size016_016/rel/x2_branch3_conv1" name: "size016_016/rel/x2_branch3_relu1" type: "ReLU" }
layer {
    bottom: "size016_016/rel/x2_branch3_conv1"
    top:    "size016_016/rel/x2_branch3_conv2"
    name:   "size016_016/rel/x2_branch3_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 5
        pad: 2
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size016_016/rel/x2_branch3_conv2" top: "size016_016/rel/x2_branch3_conv2" name: "size016_016/rel/x2_branch3_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size016_016/rel/x2_branch3_conv2" top: "size016_016/rel/x2_branch3_conv2" name: "size016_016/rel/x2_branch3_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size016_016/rel/x2_branch3_conv2" top: "size016_016/rel/x2_branch3_conv2" name: "size016_016/rel/x2_branch3_relu2" type: "ReLU" }
 
# branch5
layer {
    bottom: "size016_016/rel/x2_deconv"
    top:    "size016_016/rel/x2_branch5_conv1"
    name:   "size016_016/rel/x2_branch5_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size016_016/rel/x2_branch5_conv1" top: "size016_016/rel/x2_branch5_conv1" name: "size016_016/rel/x2_branch5_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size016_016/rel/x2_branch5_conv1" top: "size016_016/rel/x2_branch5_conv1" name: "size016_016/rel/x2_branch5_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size016_016/rel/x2_branch5_conv1" top: "size016_016/rel/x2_branch5_conv1" name: "size016_016/rel/x2_branch5_relu1" type: "ReLU" }

layer {
    bottom: "size016_016/rel/x2_branch5_conv1"
    top:    "size016_016/rel/x2_branch5_conv2"
    name:   "size016_016/rel/x2_branch5_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_w: 16
        kernel_h: 3
        pad_h: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size016_016/rel/x2_branch5_conv2" top: "size016_016/rel/x2_branch5_conv2" name: "size016_016/rel/x2_branch5_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size016_016/rel/x2_branch5_conv2" top: "size016_016/rel/x2_branch5_conv2" name: "size016_016/rel/x2_branch5_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size016_016/rel/x2_branch5_conv2" top: "size016_016/rel/x2_branch5_conv2" name: "size016_016/rel/x2_branch5_relu2" type: "ReLU" }
layer{ bottom: "size016_016/rel/x2_branch5_conv2" top: "size016_016/rel/x2_branch5_tile"  name: "size016_016/rel/x2_branch5_tile"  type: "Tile" tile_param { axis: 3 tiles: 16 } }


# branch6
layer {
    bottom: "size016_016/rel/x2_deconv"
    top:    "size016_016/rel/x2_branch6_conv1"
    name:   "size016_016/rel/x2_branch6_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size016_016/rel/x2_branch6_conv1" top: "size016_016/rel/x2_branch6_conv1" name: "size016_016/rel/x2_branch6_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size016_016/rel/x2_branch6_conv1" top: "size016_016/rel/x2_branch6_conv1" name: "size016_016/rel/x2_branch6_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size016_016/rel/x2_branch6_conv1" top: "size016_016/rel/x2_branch6_conv1" name: "size016_016/rel/x2_branch6_relu1" type: "ReLU" }
layer {
    bottom: "size016_016/rel/x2_branch6_conv1"
    top:    "size016_016/rel/x2_branch6_conv2"
    name:   "size016_016/rel/x2_branch6_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_w: 3
        kernel_h: 16
        pad_w: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size016_016/rel/x2_branch6_conv2" top: "size016_016/rel/x2_branch6_conv2" name: "size016_016/rel/x2_branch6_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size016_016/rel/x2_branch6_conv2" top: "size016_016/rel/x2_branch6_conv2" name: "size016_016/rel/x2_branch6_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size016_016/rel/x2_branch6_conv2" top: "size016_016/rel/x2_branch6_conv2" name: "size016_016/rel/x2_branch6_relu2" type: "ReLU" }
layer{ bottom: "size016_016/rel/x2_branch6_conv2" top: "size016_016/rel/x2_branch6_tile"  name: "size016_016/rel/x2_branch6_tile"  type: "Tile" tile_param { axis: 2 tiles: 16 } }

# Concat
layer {
    bottom: "size016_016/rel/x2_branch1_conv1"
    bottom: "size016_016/rel/x2_branch2_conv2"
    bottom: "size016_016/rel/x2_branch3_conv2" 
    bottom: "size016_016/rel/x2_branch5_tile"
    bottom: "size016_016/rel/x2_branch6_tile"
    top:    "size016_016/rel/x2_concat"
    name:   "size016_016/rel/x2_concat"
    type:   "Concat"
    concat_param {
        axis:1
    }
}

#################################################
##### Part004 loss at size016_016/rel/conv5 #####
#################################################
layer {
  name: "DenseNet16523or/pred_2D_016_016_ch1000_true"
  type: "Convolution"
  bottom: "size016_016/rel/x2_concat"
  top: "DenseNet16523or/pred_2D_016_016_ch1000_true"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler{
      type: "xavier"
    }
  }
  
}

layer {
  name: "DenseNet16523or/pred_2D_016_016_ch1000_false"
  type: "Convolution"
  bottom: "size016_016/rel/x2_concat"
  top: "DenseNet16523or/pred_2D_016_016_ch1000_false"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler{
      type: "xavier"
    }
  }
}

layer {
  bottom: "DenseNet16523or/pred_2D_016_016_ch1000_true"
  bottom: "DenseNet16523or/pred_2D_016_016_ch1000_false"
  top: "DenseNet16523or/pred_2D_016_016_ch1000_true_false_gap"
  name: "DenseNet16523or/pred_2D_016_016_ch1000_true_false_gap"
  type: "Eltwise"
  eltwise_param {
        operation: 1 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
        coeff: 1
        coeff: -1
  }
}

layer {
  name: "DenseNet16523or/pred_2D_016_016_ch1000"
  type: "Sigmoid"
  bottom: "DenseNet16523or/pred_2D_016_016_ch1000_true_false_gap"
  top: "DenseNet16523or/pred_2D_016_016_ch1000"
}

layer {
    name: "DenseNet16523or/pred_2D_016_016_ch1000_norm"
    bottom: "DenseNet16523or/pred_2D_016_016_ch1000"
    top: "DenseNet16523or/pred_2D_016_016_ch1000_norm"
    type: "Power"
    power_param {
        power: 1
        scale: 0.999990
        shift: 0.000005
    }
}

layer {
    name: "DenseNet16523or/pred_2D_016_016_ch1000_norm_inverse"
    bottom: "DenseNet16523or/pred_2D_016_016_ch1000_norm"
    top: "DenseNet16523or/pred_2D_016_016_ch1000_norm_inverse"
    type: "Power"
    power_param {
        power: 1
        scale: -1
        shift: 1
    }
}

layer {
    name: "DenseNet16523or/pred_2D_016_016_ch1000_log"
    bottom: "DenseNet16523or/pred_2D_016_016_ch1000_norm"
    top: "DenseNet16523or/pred_2D_016_016_ch1000_log"
    type: "Log"
    log_param {
        base: -1 # default(=-1) -> base is set to e
        scale: 1
        shift: 0
    }
}

layer {
    name: "DenseNet16523or/pred_2D_016_016_ch1000_inverse_log"
    bottom: "DenseNet16523or/pred_2D_016_016_ch1000_norm_inverse"
    top: "DenseNet16523or/pred_2D_016_016_ch1000_inverse_log"
    type: "Log"
    log_param {
        base: -1 # default(=-1) -> base is set to e
        scale: 1
        shift: 0
    }
}

layer {
  bottom: "DenseNet16523or/pred_2D_016_016_ch1000_log"
  bottom: "label_016_016_ch1000"
  top: "DenseNet16523or/loss_2D_016_016_ch1000_true"
  name: "DenseNet16523or/loss_2D_016_016_ch1000_true"
  type: "Eltwise" # Eltwise(PROD)
  eltwise_param {
        operation: 0 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
  }
}

layer {
  bottom: "DenseNet16523or/pred_2D_016_016_ch1000_inverse_log"
  bottom: "label_016_016_ch1000_inverse"
  top: "DenseNet16523or/loss_2D_016_016_ch1000_false"
  name: "DenseNet16523or/loss_2D_016_016_ch1000_false"
  type: "Eltwise" # Eltwise(PROD)
  eltwise_param {
        operation: 0 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
  }
}

layer {
  bottom: "DenseNet16523or/loss_2D_016_016_ch1000_true"
  bottom: "DenseNet16523or/loss_2D_016_016_ch1000_false"
  top: "DenseNet16523or/loss_2D_016_016_ch1000"
  name: "DenseNet16523or/loss_2D_016_016_ch1000"
  type: "Eltwise"
  eltwise_param {
        operation: 1 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
        coeff: -1
        coeff: -1
  }
}

layer {
    name: "DenseNet16523or/loss_2D_016_016_ch1000_size_norm"
    bottom: "DenseNet16523or/loss_2D_016_016_ch1000"
    top: "DenseNet16523or/loss_2D_016_016_ch1000_size_norm"
    type: "Power"
    power_param {
        power: 1
        scale: 0.00390625 # output 1/(H x W) = 1/(16 x 16) = 0.00390625
        shift: 0
    }
}

layer { ## Requires user to set loss scale (For setting lr at each epoch)
  name: "DenseNet16523or/loss_2D_016_016_ch1000_multiplication"
  type: "Scale"
  bottom: "DenseNet16523or/loss_2D_016_016_ch1000_size_norm"
  top: "DenseNet16523or/loss_2D_016_016_ch1000_multiplication"
  param { lr_mult: 0 decay_mult: 0 }
  scale_param {
    bias_term: false
  }
}

layer {
    bottom: "DenseNet16523or/loss_2D_016_016_ch1000_multiplication"
    top: "DenseNet16523or/loss_2D_016_016_ch1000_sum"
    name: "DenseNet16523or/loss_2D_016_016_ch1000_sum"
    type:"Reduction"
    
    loss_weight: 1
}

#########################################
##### Part003 size032_032/rel/conv5 #####
#########################################
layer {
  name: "size032_032/rel/conv5_1/x1/bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "size032_032/rel/conv5_1/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_1/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_1/x1/bn"
  top: "size032_032/rel/conv5_1/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_1/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_1/x1/bn"
  top: "size032_032/rel/conv5_1/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_1/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_1/x1/bn"
  top: "size032_032/rel/conv5_1/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_1/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_1/x1"
  top: "size032_032/rel/conv5_1/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_1/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_1/x2/bn"
  top: "size032_032/rel/conv5_1/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_1/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_1/x2/bn"
  top: "size032_032/rel/conv5_1/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_1/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_1/x2/bn"
  top: "size032_032/rel/conv5_1/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_1"
  type: "Concat"
  bottom: "pool4"
  bottom: "size032_032/rel/conv5_1/x2"
  top: "size032_032/rel/concat_5_1"
}
layer {
  name: "size032_032/rel/conv5_2/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_1"
  top: "size032_032/rel/conv5_2/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_2/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_2/x1/bn"
  top: "size032_032/rel/conv5_2/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_2/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_2/x1/bn"
  top: "size032_032/rel/conv5_2/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_2/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_2/x1/bn"
  top: "size032_032/rel/conv5_2/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_2/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_2/x1"
  top: "size032_032/rel/conv5_2/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_2/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_2/x2/bn"
  top: "size032_032/rel/conv5_2/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_2/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_2/x2/bn"
  top: "size032_032/rel/conv5_2/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_2/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_2/x2/bn"
  top: "size032_032/rel/conv5_2/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_2"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_1"
  bottom: "size032_032/rel/conv5_2/x2"
  top: "size032_032/rel/concat_5_2"
}
layer {
  name: "size032_032/rel/conv5_3/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_2"
  top: "size032_032/rel/conv5_3/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_3/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_3/x1/bn"
  top: "size032_032/rel/conv5_3/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_3/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_3/x1/bn"
  top: "size032_032/rel/conv5_3/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_3/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_3/x1/bn"
  top: "size032_032/rel/conv5_3/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_3/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_3/x1"
  top: "size032_032/rel/conv5_3/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_3/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_3/x2/bn"
  top: "size032_032/rel/conv5_3/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_3/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_3/x2/bn"
  top: "size032_032/rel/conv5_3/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_3/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_3/x2/bn"
  top: "size032_032/rel/conv5_3/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_3"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_2"
  bottom: "size032_032/rel/conv5_3/x2"
  top: "size032_032/rel/concat_5_3"
}
layer {
  name: "size032_032/rel/conv5_4/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_3"
  top: "size032_032/rel/conv5_4/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_4/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_4/x1/bn"
  top: "size032_032/rel/conv5_4/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_4/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_4/x1/bn"
  top: "size032_032/rel/conv5_4/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_4/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_4/x1/bn"
  top: "size032_032/rel/conv5_4/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_4/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_4/x1"
  top: "size032_032/rel/conv5_4/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_4/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_4/x2/bn"
  top: "size032_032/rel/conv5_4/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_4/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_4/x2/bn"
  top: "size032_032/rel/conv5_4/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_4/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_4/x2/bn"
  top: "size032_032/rel/conv5_4/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_4"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_3"
  bottom: "size032_032/rel/conv5_4/x2"
  top: "size032_032/rel/concat_5_4"
}
layer {
  name: "size032_032/rel/conv5_5/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_4"
  top: "size032_032/rel/conv5_5/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_5/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_5/x1/bn"
  top: "size032_032/rel/conv5_5/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_5/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_5/x1/bn"
  top: "size032_032/rel/conv5_5/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_5/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_5/x1/bn"
  top: "size032_032/rel/conv5_5/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_5/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_5/x1"
  top: "size032_032/rel/conv5_5/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_5/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_5/x2/bn"
  top: "size032_032/rel/conv5_5/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_5/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_5/x2/bn"
  top: "size032_032/rel/conv5_5/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_5/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_5/x2/bn"
  top: "size032_032/rel/conv5_5/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_5"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_4"
  bottom: "size032_032/rel/conv5_5/x2"
  top: "size032_032/rel/concat_5_5"
}
layer {
  name: "size032_032/rel/conv5_6/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_5"
  top: "size032_032/rel/conv5_6/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_6/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_6/x1/bn"
  top: "size032_032/rel/conv5_6/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_6/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_6/x1/bn"
  top: "size032_032/rel/conv5_6/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_6/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_6/x1/bn"
  top: "size032_032/rel/conv5_6/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_6/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_6/x1"
  top: "size032_032/rel/conv5_6/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_6/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_6/x2/bn"
  top: "size032_032/rel/conv5_6/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_6/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_6/x2/bn"
  top: "size032_032/rel/conv5_6/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_6/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_6/x2/bn"
  top: "size032_032/rel/conv5_6/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_6"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_5"
  bottom: "size032_032/rel/conv5_6/x2"
  top: "size032_032/rel/concat_5_6"
}
layer {
  name: "size032_032/rel/conv5_7/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_6"
  top: "size032_032/rel/conv5_7/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_7/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_7/x1/bn"
  top: "size032_032/rel/conv5_7/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_7/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_7/x1/bn"
  top: "size032_032/rel/conv5_7/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_7/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_7/x1/bn"
  top: "size032_032/rel/conv5_7/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_7/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_7/x1"
  top: "size032_032/rel/conv5_7/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_7/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_7/x2/bn"
  top: "size032_032/rel/conv5_7/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_7/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_7/x2/bn"
  top: "size032_032/rel/conv5_7/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_7/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_7/x2/bn"
  top: "size032_032/rel/conv5_7/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_7"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_6"
  bottom: "size032_032/rel/conv5_7/x2"
  top: "size032_032/rel/concat_5_7"
}
layer {
  name: "size032_032/rel/conv5_8/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_7"
  top: "size032_032/rel/conv5_8/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_8/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_8/x1/bn"
  top: "size032_032/rel/conv5_8/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_8/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_8/x1/bn"
  top: "size032_032/rel/conv5_8/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_8/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_8/x1/bn"
  top: "size032_032/rel/conv5_8/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_8/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_8/x1"
  top: "size032_032/rel/conv5_8/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_8/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_8/x2/bn"
  top: "size032_032/rel/conv5_8/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_8/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_8/x2/bn"
  top: "size032_032/rel/conv5_8/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_8/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_8/x2/bn"
  top: "size032_032/rel/conv5_8/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_8"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_7"
  bottom: "size032_032/rel/conv5_8/x2"
  top: "size032_032/rel/concat_5_8"
}
layer {
  name: "size032_032/rel/conv5_9/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_8"
  top: "size032_032/rel/conv5_9/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_9/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_9/x1/bn"
  top: "size032_032/rel/conv5_9/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_9/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_9/x1/bn"
  top: "size032_032/rel/conv5_9/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_9/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_9/x1/bn"
  top: "size032_032/rel/conv5_9/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_9/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_9/x1"
  top: "size032_032/rel/conv5_9/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_9/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_9/x2/bn"
  top: "size032_032/rel/conv5_9/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_9/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_9/x2/bn"
  top: "size032_032/rel/conv5_9/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_9/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_9/x2/bn"
  top: "size032_032/rel/conv5_9/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_9"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_8"
  bottom: "size032_032/rel/conv5_9/x2"
  top: "size032_032/rel/concat_5_9"
}
layer {
  name: "size032_032/rel/conv5_10/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_9"
  top: "size032_032/rel/conv5_10/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_10/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_10/x1/bn"
  top: "size032_032/rel/conv5_10/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_10/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_10/x1/bn"
  top: "size032_032/rel/conv5_10/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_10/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_10/x1/bn"
  top: "size032_032/rel/conv5_10/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_10/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_10/x1"
  top: "size032_032/rel/conv5_10/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_10/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_10/x2/bn"
  top: "size032_032/rel/conv5_10/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_10/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_10/x2/bn"
  top: "size032_032/rel/conv5_10/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_10/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_10/x2/bn"
  top: "size032_032/rel/conv5_10/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_10"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_9"
  bottom: "size032_032/rel/conv5_10/x2"
  top: "size032_032/rel/concat_5_10"
}
layer {
  name: "size032_032/rel/conv5_11/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_10"
  top: "size032_032/rel/conv5_11/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_11/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_11/x1/bn"
  top: "size032_032/rel/conv5_11/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_11/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_11/x1/bn"
  top: "size032_032/rel/conv5_11/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_11/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_11/x1/bn"
  top: "size032_032/rel/conv5_11/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_11/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_11/x1"
  top: "size032_032/rel/conv5_11/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_11/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_11/x2/bn"
  top: "size032_032/rel/conv5_11/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_11/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_11/x2/bn"
  top: "size032_032/rel/conv5_11/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_11/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_11/x2/bn"
  top: "size032_032/rel/conv5_11/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_11"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_10"
  bottom: "size032_032/rel/conv5_11/x2"
  top: "size032_032/rel/concat_5_11"
}
layer {
  name: "size032_032/rel/conv5_12/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_11"
  top: "size032_032/rel/conv5_12/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_12/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_12/x1/bn"
  top: "size032_032/rel/conv5_12/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_12/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_12/x1/bn"
  top: "size032_032/rel/conv5_12/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_12/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_12/x1/bn"
  top: "size032_032/rel/conv5_12/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_12/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_12/x1"
  top: "size032_032/rel/conv5_12/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_12/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_12/x2/bn"
  top: "size032_032/rel/conv5_12/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_12/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_12/x2/bn"
  top: "size032_032/rel/conv5_12/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_12/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_12/x2/bn"
  top: "size032_032/rel/conv5_12/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_12"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_11"
  bottom: "size032_032/rel/conv5_12/x2"
  top: "size032_032/rel/concat_5_12"
}
layer {
  name: "size032_032/rel/conv5_13/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_12"
  top: "size032_032/rel/conv5_13/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_13/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_13/x1/bn"
  top: "size032_032/rel/conv5_13/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_13/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_13/x1/bn"
  top: "size032_032/rel/conv5_13/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_13/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_13/x1/bn"
  top: "size032_032/rel/conv5_13/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_13/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_13/x1"
  top: "size032_032/rel/conv5_13/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_13/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_13/x2/bn"
  top: "size032_032/rel/conv5_13/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_13/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_13/x2/bn"
  top: "size032_032/rel/conv5_13/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_13/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_13/x2/bn"
  top: "size032_032/rel/conv5_13/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_13"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_12"
  bottom: "size032_032/rel/conv5_13/x2"
  top: "size032_032/rel/concat_5_13"
}
layer {
  name: "size032_032/rel/conv5_14/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_13"
  top: "size032_032/rel/conv5_14/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_14/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_14/x1/bn"
  top: "size032_032/rel/conv5_14/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_14/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_14/x1/bn"
  top: "size032_032/rel/conv5_14/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_14/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_14/x1/bn"
  top: "size032_032/rel/conv5_14/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_14/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_14/x1"
  top: "size032_032/rel/conv5_14/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_14/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_14/x2/bn"
  top: "size032_032/rel/conv5_14/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_14/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_14/x2/bn"
  top: "size032_032/rel/conv5_14/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_14/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_14/x2/bn"
  top: "size032_032/rel/conv5_14/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_14"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_13"
  bottom: "size032_032/rel/conv5_14/x2"
  top: "size032_032/rel/concat_5_14"
}
layer {
  name: "size032_032/rel/conv5_15/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_14"
  top: "size032_032/rel/conv5_15/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_15/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_15/x1/bn"
  top: "size032_032/rel/conv5_15/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_15/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_15/x1/bn"
  top: "size032_032/rel/conv5_15/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_15/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_15/x1/bn"
  top: "size032_032/rel/conv5_15/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_15/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_15/x1"
  top: "size032_032/rel/conv5_15/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_15/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_15/x2/bn"
  top: "size032_032/rel/conv5_15/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_15/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_15/x2/bn"
  top: "size032_032/rel/conv5_15/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_15/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_15/x2/bn"
  top: "size032_032/rel/conv5_15/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_15"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_14"
  bottom: "size032_032/rel/conv5_15/x2"
  top: "size032_032/rel/concat_5_15"
}
layer {
  name: "size032_032/rel/conv5_16/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_15"
  top: "size032_032/rel/conv5_16/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_16/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_16/x1/bn"
  top: "size032_032/rel/conv5_16/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_16/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_16/x1/bn"
  top: "size032_032/rel/conv5_16/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_16/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_16/x1/bn"
  top: "size032_032/rel/conv5_16/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_16/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_16/x1"
  top: "size032_032/rel/conv5_16/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_16/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_16/x2/bn"
  top: "size032_032/rel/conv5_16/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_16/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_16/x2/bn"
  top: "size032_032/rel/conv5_16/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_16/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_16/x2/bn"
  top: "size032_032/rel/conv5_16/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_16"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_15"
  bottom: "size032_032/rel/conv5_16/x2"
  top: "size032_032/rel/concat_5_16"
}
layer {
  name: "size032_032/rel/conv5_17/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_16"
  top: "size032_032/rel/conv5_17/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_17/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_17/x1/bn"
  top: "size032_032/rel/conv5_17/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_17/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_17/x1/bn"
  top: "size032_032/rel/conv5_17/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_17/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_17/x1/bn"
  top: "size032_032/rel/conv5_17/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_17/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_17/x1"
  top: "size032_032/rel/conv5_17/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_17/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_17/x2/bn"
  top: "size032_032/rel/conv5_17/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_17/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_17/x2/bn"
  top: "size032_032/rel/conv5_17/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_17/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_17/x2/bn"
  top: "size032_032/rel/conv5_17/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_17"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_16"
  bottom: "size032_032/rel/conv5_17/x2"
  top: "size032_032/rel/concat_5_17"
}
layer {
  name: "size032_032/rel/conv5_18/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_17"
  top: "size032_032/rel/conv5_18/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_18/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_18/x1/bn"
  top: "size032_032/rel/conv5_18/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_18/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_18/x1/bn"
  top: "size032_032/rel/conv5_18/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_18/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_18/x1/bn"
  top: "size032_032/rel/conv5_18/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_18/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_18/x1"
  top: "size032_032/rel/conv5_18/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_18/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_18/x2/bn"
  top: "size032_032/rel/conv5_18/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_18/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_18/x2/bn"
  top: "size032_032/rel/conv5_18/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_18/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_18/x2/bn"
  top: "size032_032/rel/conv5_18/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_18"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_17"
  bottom: "size032_032/rel/conv5_18/x2"
  top: "size032_032/rel/concat_5_18"
}
layer {
  name: "size032_032/rel/conv5_19/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_18"
  top: "size032_032/rel/conv5_19/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_19/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_19/x1/bn"
  top: "size032_032/rel/conv5_19/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_19/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_19/x1/bn"
  top: "size032_032/rel/conv5_19/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_19/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_19/x1/bn"
  top: "size032_032/rel/conv5_19/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_19/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_19/x1"
  top: "size032_032/rel/conv5_19/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_19/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_19/x2/bn"
  top: "size032_032/rel/conv5_19/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_19/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_19/x2/bn"
  top: "size032_032/rel/conv5_19/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_19/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_19/x2/bn"
  top: "size032_032/rel/conv5_19/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_19"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_18"
  bottom: "size032_032/rel/conv5_19/x2"
  top: "size032_032/rel/concat_5_19"
}
layer {
  name: "size032_032/rel/conv5_20/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_19"
  top: "size032_032/rel/conv5_20/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_20/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_20/x1/bn"
  top: "size032_032/rel/conv5_20/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_20/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_20/x1/bn"
  top: "size032_032/rel/conv5_20/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_20/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_20/x1/bn"
  top: "size032_032/rel/conv5_20/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_20/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_20/x1"
  top: "size032_032/rel/conv5_20/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_20/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_20/x2/bn"
  top: "size032_032/rel/conv5_20/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_20/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_20/x2/bn"
  top: "size032_032/rel/conv5_20/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_20/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_20/x2/bn"
  top: "size032_032/rel/conv5_20/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_20"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_19"
  bottom: "size032_032/rel/conv5_20/x2"
  top: "size032_032/rel/concat_5_20"
}
layer {
  name: "size032_032/rel/conv5_21/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_20"
  top: "size032_032/rel/conv5_21/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_21/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_21/x1/bn"
  top: "size032_032/rel/conv5_21/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_21/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_21/x1/bn"
  top: "size032_032/rel/conv5_21/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_21/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_21/x1/bn"
  top: "size032_032/rel/conv5_21/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_21/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_21/x1"
  top: "size032_032/rel/conv5_21/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_21/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_21/x2/bn"
  top: "size032_032/rel/conv5_21/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_21/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_21/x2/bn"
  top: "size032_032/rel/conv5_21/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_21/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_21/x2/bn"
  top: "size032_032/rel/conv5_21/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_21"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_20"
  bottom: "size032_032/rel/conv5_21/x2"
  top: "size032_032/rel/concat_5_21"
}
layer {
  name: "size032_032/rel/conv5_22/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_21"
  top: "size032_032/rel/conv5_22/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_22/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_22/x1/bn"
  top: "size032_032/rel/conv5_22/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_22/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_22/x1/bn"
  top: "size032_032/rel/conv5_22/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_22/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_22/x1/bn"
  top: "size032_032/rel/conv5_22/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_22/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_22/x1"
  top: "size032_032/rel/conv5_22/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_22/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_22/x2/bn"
  top: "size032_032/rel/conv5_22/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_22/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_22/x2/bn"
  top: "size032_032/rel/conv5_22/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_22/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_22/x2/bn"
  top: "size032_032/rel/conv5_22/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_22"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_21"
  bottom: "size032_032/rel/conv5_22/x2"
  top: "size032_032/rel/concat_5_22"
}
layer {
  name: "size032_032/rel/conv5_23/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_22"
  top: "size032_032/rel/conv5_23/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_23/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_23/x1/bn"
  top: "size032_032/rel/conv5_23/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_23/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_23/x1/bn"
  top: "size032_032/rel/conv5_23/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_23/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_23/x1/bn"
  top: "size032_032/rel/conv5_23/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_23/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_23/x1"
  top: "size032_032/rel/conv5_23/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_23/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_23/x2/bn"
  top: "size032_032/rel/conv5_23/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_23/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_23/x2/bn"
  top: "size032_032/rel/conv5_23/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_23/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_23/x2/bn"
  top: "size032_032/rel/conv5_23/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_23"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_22"
  bottom: "size032_032/rel/conv5_23/x2"
  top: "size032_032/rel/concat_5_23"
}
layer {
  name: "size032_032/rel/conv5_24/x1/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_23"
  top: "size032_032/rel/conv5_24/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_24/x1/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_24/x1/bn"
  top: "size032_032/rel/conv5_24/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_24/x1"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_24/x1/bn"
  top: "size032_032/rel/conv5_24/x1/bn"
}
layer {
  name: "size032_032/rel/conv5_24/x1"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_24/x1/bn"
  top: "size032_032/rel/conv5_24/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size032_032/rel/conv5_24/x2/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/conv5_24/x1"
  top: "size032_032/rel/conv5_24/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_24/x2/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_24/x2/bn"
  top: "size032_032/rel/conv5_24/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_24/x2"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_24/x2/bn"
  top: "size032_032/rel/conv5_24/x2/bn"
}
layer {
  name: "size032_032/rel/conv5_24/x2"
  type: "Convolution"
  bottom: "size032_032/rel/conv5_24/x2/bn"
  top: "size032_032/rel/conv5_24/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size032_032/rel/concat_5_24"
  type: "Concat"
  bottom: "size032_032/rel/concat_5_23"
  bottom: "size032_032/rel/conv5_24/x2"
  top: "size032_032/rel/concat_5_24"
}
layer {
  name: "size032_032/rel/conv5_blk/bn"
  type: "BatchNorm"
  bottom: "size032_032/rel/concat_5_24"
  top: "size032_032/rel/conv5_blk/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size032_032/rel/conv5_blk/scale"
  type: "Scale"
  bottom: "size032_032/rel/conv5_blk/bn"
  top: "size032_032/rel/conv5_blk/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size032_032/rel/relu5_blk"
  type: "ReLU"
  bottom: "size032_032/rel/conv5_blk/bn"
  top: "size032_032/rel/conv5_blk/bn"
}

###########################################################################
# size 2x  Inception
###########################################################################
layer {
    bottom: "size032_032/rel/conv5_blk/bn"
    top:    "size032_032/rel/x2_deconv"
    name:   "size032_032/rel/x2_deconv"
    type:   "Deconvolution" 
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 1664
        kernel_size: 4
        stride: 2
        pad: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}


# branch1
layer {
    bottom: "size032_032/rel/x2_deconv"
    top:    "size032_032/rel/x2_branch1_conv1"
    name:   "size032_032/rel/x2_branch1_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x2_branch1_conv1" top: "size032_032/rel/x2_branch1_conv1" name: "size032_032/rel/x2_branch1_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x2_branch1_conv1" top: "size032_032/rel/x2_branch1_conv1" name: "size032_032/rel/x2_branch1_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x2_branch1_conv1" top: "size032_032/rel/x2_branch1_conv1" name: "size032_032/rel/x2_branch1_relu1" type: "ReLU" }
# branch2
layer {
    bottom: "size032_032/rel/x2_deconv"
    top:    "size032_032/rel/x2_branch2_conv1"
    name:   "size032_032/rel/x2_branch2_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x2_branch2_conv1" top: "size032_032/rel/x2_branch2_conv1" name: "size032_032/rel/x2_branch2_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x2_branch2_conv1" top: "size032_032/rel/x2_branch2_conv1" name: "size032_032/rel/x2_branch2_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x2_branch2_conv1" top: "size032_032/rel/x2_branch2_conv1" name: "size032_032/rel/x2_branch2_relu1" type: "ReLU" }
layer {
    bottom: "size032_032/rel/x2_branch2_conv1"
    top:    "size032_032/rel/x2_branch2_conv2"
    name:   "size032_032/rel/x2_branch2_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x2_branch2_conv2" top: "size032_032/rel/x2_branch2_conv2" name: "size032_032/rel/x2_branch2_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x2_branch2_conv2" top: "size032_032/rel/x2_branch2_conv2" name: "size032_032/rel/x2_branch2_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x2_branch2_conv2" top: "size032_032/rel/x2_branch2_conv2" name: "size032_032/rel/x2_branch2_relu2" type: "ReLU" }
# branch3
layer {
    bottom: "size032_032/rel/x2_deconv"
    top:    "size032_032/rel/x2_branch3_conv1"
    name:   "size032_032/rel/x2_branch3_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x2_branch3_conv1" top: "size032_032/rel/x2_branch3_conv1" name: "size032_032/rel/x2_branch3_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x2_branch3_conv1" top: "size032_032/rel/x2_branch3_conv1" name: "size032_032/rel/x2_branch3_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x2_branch3_conv1" top: "size032_032/rel/x2_branch3_conv1" name: "size032_032/rel/x2_branch3_relu1" type: "ReLU" }
layer {
    bottom: "size032_032/rel/x2_branch3_conv1"
    top:    "size032_032/rel/x2_branch3_conv2"
    name:   "size032_032/rel/x2_branch3_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 5
        pad: 2
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x2_branch3_conv2" top: "size032_032/rel/x2_branch3_conv2" name: "size032_032/rel/x2_branch3_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x2_branch3_conv2" top: "size032_032/rel/x2_branch3_conv2" name: "size032_032/rel/x2_branch3_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x2_branch3_conv2" top: "size032_032/rel/x2_branch3_conv2" name: "size032_032/rel/x2_branch3_relu2" type: "ReLU" }
 
# branch5
layer {
    bottom: "size032_032/rel/x2_deconv"
    top:    "size032_032/rel/x2_branch5_conv1"
    name:   "size032_032/rel/x2_branch5_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x2_branch5_conv1" top: "size032_032/rel/x2_branch5_conv1" name: "size032_032/rel/x2_branch5_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x2_branch5_conv1" top: "size032_032/rel/x2_branch5_conv1" name: "size032_032/rel/x2_branch5_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x2_branch5_conv1" top: "size032_032/rel/x2_branch5_conv1" name: "size032_032/rel/x2_branch5_relu1" type: "ReLU" }

layer {
    bottom: "size032_032/rel/x2_branch5_conv1"
    top:    "size032_032/rel/x2_branch5_conv2"
    name:   "size032_032/rel/x2_branch5_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_w: 16
        kernel_h: 3
        pad_h: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x2_branch5_conv2" top: "size032_032/rel/x2_branch5_conv2" name: "size032_032/rel/x2_branch5_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x2_branch5_conv2" top: "size032_032/rel/x2_branch5_conv2" name: "size032_032/rel/x2_branch5_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x2_branch5_conv2" top: "size032_032/rel/x2_branch5_conv2" name: "size032_032/rel/x2_branch5_relu2" type: "ReLU" }
layer{ bottom: "size032_032/rel/x2_branch5_conv2" top: "size032_032/rel/x2_branch5_tile"  name: "size032_032/rel/x2_branch5_tile"  type: "Tile" tile_param { axis: 3 tiles: 16 } }


# branch6
layer {
    bottom: "size032_032/rel/x2_deconv"
    top:    "size032_032/rel/x2_branch6_conv1"
    name:   "size032_032/rel/x2_branch6_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x2_branch6_conv1" top: "size032_032/rel/x2_branch6_conv1" name: "size032_032/rel/x2_branch6_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x2_branch6_conv1" top: "size032_032/rel/x2_branch6_conv1" name: "size032_032/rel/x2_branch6_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x2_branch6_conv1" top: "size032_032/rel/x2_branch6_conv1" name: "size032_032/rel/x2_branch6_relu1" type: "ReLU" }
layer {
    bottom: "size032_032/rel/x2_branch6_conv1"
    top:    "size032_032/rel/x2_branch6_conv2"
    name:   "size032_032/rel/x2_branch6_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_w: 3
        kernel_h: 16
        pad_w: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x2_branch6_conv2" top: "size032_032/rel/x2_branch6_conv2" name: "size032_032/rel/x2_branch6_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x2_branch6_conv2" top: "size032_032/rel/x2_branch6_conv2" name: "size032_032/rel/x2_branch6_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x2_branch6_conv2" top: "size032_032/rel/x2_branch6_conv2" name: "size032_032/rel/x2_branch6_relu2" type: "ReLU" }
layer{ bottom: "size032_032/rel/x2_branch6_conv2" top: "size032_032/rel/x2_branch6_tile"  name: "size032_032/rel/x2_branch6_tile"  type: "Tile" tile_param { axis: 2 tiles: 16 } }

# Concat
layer {
    bottom: "size032_032/rel/x2_branch1_conv1"
    bottom: "size032_032/rel/x2_branch2_conv2"
    bottom: "size032_032/rel/x2_branch3_conv2" 
    bottom: "size032_032/rel/x2_branch5_tile"
    bottom: "size032_032/rel/x2_branch6_tile"
    top:    "size032_032/rel/x2_concat"
    name:   "size032_032/rel/x2_concat"
    type:   "Concat"
    concat_param {
        axis:1
    }
}

###########################################################################
# size 4x  Inception
###########################################################################
layer {
    bottom: "size032_032/rel/x2_concat"
    top:    "size032_032/rel/x4_deconv"
    name:   "size032_032/rel/x4_deconv"
    type:   "Deconvolution" 
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 832
        kernel_size: 4
        stride: 2
        pad: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}


# branch1
layer {
    bottom: "size032_032/rel/x4_deconv"
    top:    "size032_032/rel/x4_branch1_conv1"
    name:   "size032_032/rel/x4_branch1_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x4_branch1_conv1" top: "size032_032/rel/x4_branch1_conv1" name: "size032_032/rel/x4_branch1_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x4_branch1_conv1" top: "size032_032/rel/x4_branch1_conv1" name: "size032_032/rel/x4_branch1_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x4_branch1_conv1" top: "size032_032/rel/x4_branch1_conv1" name: "size032_032/rel/x4_branch1_relu1" type: "ReLU" }
# branch2
layer {
    bottom: "size032_032/rel/x4_deconv"
    top:    "size032_032/rel/x4_branch2_conv1"
    name:   "size032_032/rel/x4_branch2_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x4_branch2_conv1" top: "size032_032/rel/x4_branch2_conv1" name: "size032_032/rel/x4_branch2_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x4_branch2_conv1" top: "size032_032/rel/x4_branch2_conv1" name: "size032_032/rel/x4_branch2_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x4_branch2_conv1" top: "size032_032/rel/x4_branch2_conv1" name: "size032_032/rel/x4_branch2_relu1" type: "ReLU" }
layer {
    bottom: "size032_032/rel/x4_branch2_conv1"
    top:    "size032_032/rel/x4_branch2_conv2"
    name:   "size032_032/rel/x4_branch2_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x4_branch2_conv2" top: "size032_032/rel/x4_branch2_conv2" name: "size032_032/rel/x4_branch2_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x4_branch2_conv2" top: "size032_032/rel/x4_branch2_conv2" name: "size032_032/rel/x4_branch2_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x4_branch2_conv2" top: "size032_032/rel/x4_branch2_conv2" name: "size032_032/rel/x4_branch2_relu2" type: "ReLU" }
# branch3
layer {
    bottom: "size032_032/rel/x4_deconv"
    top:    "size032_032/rel/x4_branch3_conv1"
    name:   "size032_032/rel/x4_branch3_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x4_branch3_conv1" top: "size032_032/rel/x4_branch3_conv1" name: "size032_032/rel/x4_branch3_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x4_branch3_conv1" top: "size032_032/rel/x4_branch3_conv1" name: "size032_032/rel/x4_branch3_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x4_branch3_conv1" top: "size032_032/rel/x4_branch3_conv1" name: "size032_032/rel/x4_branch3_relu1" type: "ReLU" }
layer {
    bottom: "size032_032/rel/x4_branch3_conv1"
    top:    "size032_032/rel/x4_branch3_conv2"
    name:   "size032_032/rel/x4_branch3_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 5
        pad: 2
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x4_branch3_conv2" top: "size032_032/rel/x4_branch3_conv2" name: "size032_032/rel/x4_branch3_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x4_branch3_conv2" top: "size032_032/rel/x4_branch3_conv2" name: "size032_032/rel/x4_branch3_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x4_branch3_conv2" top: "size032_032/rel/x4_branch3_conv2" name: "size032_032/rel/x4_branch3_relu2" type: "ReLU" }
 
# branch5
layer {
    bottom: "size032_032/rel/x4_deconv"
    top:    "size032_032/rel/x4_branch5_conv1"
    name:   "size032_032/rel/x4_branch5_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x4_branch5_conv1" top: "size032_032/rel/x4_branch5_conv1" name: "size032_032/rel/x4_branch5_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x4_branch5_conv1" top: "size032_032/rel/x4_branch5_conv1" name: "size032_032/rel/x4_branch5_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x4_branch5_conv1" top: "size032_032/rel/x4_branch5_conv1" name: "size032_032/rel/x4_branch5_relu1" type: "ReLU" }

layer {
    bottom: "size032_032/rel/x4_branch5_conv1"
    top:    "size032_032/rel/x4_branch5_conv2"
    name:   "size032_032/rel/x4_branch5_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_w: 32
        kernel_h: 3
        pad_h: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x4_branch5_conv2" top: "size032_032/rel/x4_branch5_conv2" name: "size032_032/rel/x4_branch5_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x4_branch5_conv2" top: "size032_032/rel/x4_branch5_conv2" name: "size032_032/rel/x4_branch5_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x4_branch5_conv2" top: "size032_032/rel/x4_branch5_conv2" name: "size032_032/rel/x4_branch5_relu2" type: "ReLU" }
layer{ bottom: "size032_032/rel/x4_branch5_conv2" top: "size032_032/rel/x4_branch5_tile"  name: "size032_032/rel/x4_branch5_tile"  type: "Tile" tile_param { axis: 3 tiles: 32 } }


# branch6
layer {
    bottom: "size032_032/rel/x4_deconv"
    top:    "size032_032/rel/x4_branch6_conv1"
    name:   "size032_032/rel/x4_branch6_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x4_branch6_conv1" top: "size032_032/rel/x4_branch6_conv1" name: "size032_032/rel/x4_branch6_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x4_branch6_conv1" top: "size032_032/rel/x4_branch6_conv1" name: "size032_032/rel/x4_branch6_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x4_branch6_conv1" top: "size032_032/rel/x4_branch6_conv1" name: "size032_032/rel/x4_branch6_relu1" type: "ReLU" }
layer {
    bottom: "size032_032/rel/x4_branch6_conv1"
    top:    "size032_032/rel/x4_branch6_conv2"
    name:   "size032_032/rel/x4_branch6_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_w: 3
        kernel_h: 32
        pad_w: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size032_032/rel/x4_branch6_conv2" top: "size032_032/rel/x4_branch6_conv2" name: "size032_032/rel/x4_branch6_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size032_032/rel/x4_branch6_conv2" top: "size032_032/rel/x4_branch6_conv2" name: "size032_032/rel/x4_branch6_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size032_032/rel/x4_branch6_conv2" top: "size032_032/rel/x4_branch6_conv2" name: "size032_032/rel/x4_branch6_relu2" type: "ReLU" }
layer{ bottom: "size032_032/rel/x4_branch6_conv2" top: "size032_032/rel/x4_branch6_tile"  name: "size032_032/rel/x4_branch6_tile"  type: "Tile" tile_param { axis: 2 tiles: 32 } }

# Concat
layer {
    bottom: "size032_032/rel/x4_branch1_conv1"
    bottom: "size032_032/rel/x4_branch2_conv2"
    bottom: "size032_032/rel/x4_branch3_conv2" 
    bottom: "size032_032/rel/x4_branch5_tile"
    bottom: "size032_032/rel/x4_branch6_tile"
    top:    "size032_032/rel/x4_concat"
    name:   "size032_032/rel/x4_concat"
    type:   "Concat"
    concat_param {
        axis:1
    }
}

#################################################
##### Part004 loss at size032_032/rel/conv5 #####
#################################################
layer {
  name: "DenseNet16525or/pred_2D_032_032_ch1000_true"
  type: "Convolution"
  bottom: "size032_032/rel/x4_concat"
  top: "DenseNet16525or/pred_2D_032_032_ch1000_true"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler{
      type: "xavier"
    }
  }
  
}

layer {
  name: "DenseNet16525or/pred_2D_032_032_ch1000_false"
  type: "Convolution"
  bottom: "size032_032/rel/x4_concat"
  top: "DenseNet16525or/pred_2D_032_032_ch1000_false"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler{
      type: "xavier"
    }
  }
}

layer {
  bottom: "DenseNet16525or/pred_2D_032_032_ch1000_true"
  bottom: "DenseNet16525or/pred_2D_032_032_ch1000_false"
  top: "DenseNet16525or/pred_2D_032_032_ch1000_true_false_gap"
  name: "DenseNet16525or/pred_2D_032_032_ch1000_true_false_gap"
  type: "Eltwise"
  eltwise_param {
        operation: 1 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
        coeff: 1
        coeff: -1
  }
}

layer {
  name: "DenseNet16525or/pred_2D_032_032_ch1000"
  type: "Sigmoid"
  bottom: "DenseNet16525or/pred_2D_032_032_ch1000_true_false_gap"
  top: "DenseNet16525or/pred_2D_032_032_ch1000"
}

layer {
    name: "DenseNet16525or/pred_2D_032_032_ch1000_norm"
    bottom: "DenseNet16525or/pred_2D_032_032_ch1000"
    top: "DenseNet16525or/pred_2D_032_032_ch1000_norm"
    type: "Power"
    power_param {
        power: 1
        scale: 0.999990
        shift: 0.000005
    }
}

layer {
    name: "DenseNet16525or/pred_2D_032_032_ch1000_norm_inverse"
    bottom: "DenseNet16525or/pred_2D_032_032_ch1000_norm"
    top: "DenseNet16525or/pred_2D_032_032_ch1000_norm_inverse"
    type: "Power"
    power_param {
        power: 1
        scale: -1
        shift: 1
    }
}

layer {
    name: "DenseNet16525or/pred_2D_032_032_ch1000_log"
    bottom: "DenseNet16525or/pred_2D_032_032_ch1000_norm"
    top: "DenseNet16525or/pred_2D_032_032_ch1000_log"
    type: "Log"
    log_param {
        base: -1 # default(=-1) -> base is set to e
        scale: 1
        shift: 0
    }
}

layer {
    name: "DenseNet16525or/pred_2D_032_032_ch1000_inverse_log"
    bottom: "DenseNet16525or/pred_2D_032_032_ch1000_norm_inverse"
    top: "DenseNet16525or/pred_2D_032_032_ch1000_inverse_log"
    type: "Log"
    log_param {
        base: -1 # default(=-1) -> base is set to e
        scale: 1
        shift: 0
    }
}

layer {
  bottom: "DenseNet16525or/pred_2D_032_032_ch1000_log"
  bottom: "label_032_032_ch1000"
  top: "DenseNet16525or/loss_2D_032_032_ch1000_true"
  name: "DenseNet16525or/loss_2D_032_032_ch1000_true"
  type: "Eltwise" # Eltwise(PROD)
  eltwise_param {
        operation: 0 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
  }
}

layer {
  bottom: "DenseNet16525or/pred_2D_032_032_ch1000_inverse_log"
  bottom: "label_032_032_ch1000_inverse"
  top: "DenseNet16525or/loss_2D_032_032_ch1000_false"
  name: "DenseNet16525or/loss_2D_032_032_ch1000_false"
  type: "Eltwise" # Eltwise(PROD)
  eltwise_param {
        operation: 0 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
  }
}

layer {
  bottom: "DenseNet16525or/loss_2D_032_032_ch1000_true"
  bottom: "DenseNet16525or/loss_2D_032_032_ch1000_false"
  top: "DenseNet16525or/loss_2D_032_032_ch1000"
  name: "DenseNet16525or/loss_2D_032_032_ch1000"
  type: "Eltwise"
  eltwise_param {
        operation: 1 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
        coeff: -1
        coeff: -1
  }
}

layer {
    name: "DenseNet16525or/loss_2D_032_032_ch1000_size_norm"
    bottom: "DenseNet16525or/loss_2D_032_032_ch1000"
    top: "DenseNet16525or/loss_2D_032_032_ch1000_size_norm"
    type: "Power"
    power_param {
        power: 1
        scale: 0.00097656 # output 1/(H x W) = 1/(32 x 32) = 0.00097656
        shift: 0
    }
}

layer { ## Requires user to set loss scale (For setting lr at each epoch)
  name: "DenseNet16525or/loss_2D_032_032_ch1000_multiplication"
  type: "Scale"
  bottom: "DenseNet16525or/loss_2D_032_032_ch1000_size_norm"
  top: "DenseNet16525or/loss_2D_032_032_ch1000_multiplication"
  param { lr_mult: 0 decay_mult: 0 }
  scale_param {
    bias_term: false
  }
}

layer {
    bottom: "DenseNet16525or/loss_2D_032_032_ch1000_multiplication"
    top: "DenseNet16525or/loss_2D_032_032_ch1000_sum"
    name: "DenseNet16525or/loss_2D_032_032_ch1000_sum"
    type:"Reduction"
    
    loss_weight: 1
}

#########################################
##### Part003 size064_064/rel/conv5 #####
#########################################
layer {
  name: "size064_064/rel/conv5_1/x1/bn"
  type: "BatchNorm"
  bottom: "pool4"
  top: "size064_064/rel/conv5_1/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_1/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_1/x1/bn"
  top: "size064_064/rel/conv5_1/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_1/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_1/x1/bn"
  top: "size064_064/rel/conv5_1/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_1/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_1/x1/bn"
  top: "size064_064/rel/conv5_1/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_1/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_1/x1"
  top: "size064_064/rel/conv5_1/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_1/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_1/x2/bn"
  top: "size064_064/rel/conv5_1/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_1/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_1/x2/bn"
  top: "size064_064/rel/conv5_1/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_1/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_1/x2/bn"
  top: "size064_064/rel/conv5_1/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_1"
  type: "Concat"
  bottom: "pool4"
  bottom: "size064_064/rel/conv5_1/x2"
  top: "size064_064/rel/concat_5_1"
}
layer {
  name: "size064_064/rel/conv5_2/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_1"
  top: "size064_064/rel/conv5_2/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_2/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_2/x1/bn"
  top: "size064_064/rel/conv5_2/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_2/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_2/x1/bn"
  top: "size064_064/rel/conv5_2/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_2/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_2/x1/bn"
  top: "size064_064/rel/conv5_2/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_2/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_2/x1"
  top: "size064_064/rel/conv5_2/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_2/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_2/x2/bn"
  top: "size064_064/rel/conv5_2/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_2/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_2/x2/bn"
  top: "size064_064/rel/conv5_2/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_2/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_2/x2/bn"
  top: "size064_064/rel/conv5_2/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_2"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_1"
  bottom: "size064_064/rel/conv5_2/x2"
  top: "size064_064/rel/concat_5_2"
}
layer {
  name: "size064_064/rel/conv5_3/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_2"
  top: "size064_064/rel/conv5_3/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_3/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_3/x1/bn"
  top: "size064_064/rel/conv5_3/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_3/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_3/x1/bn"
  top: "size064_064/rel/conv5_3/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_3/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_3/x1/bn"
  top: "size064_064/rel/conv5_3/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_3/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_3/x1"
  top: "size064_064/rel/conv5_3/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_3/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_3/x2/bn"
  top: "size064_064/rel/conv5_3/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_3/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_3/x2/bn"
  top: "size064_064/rel/conv5_3/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_3/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_3/x2/bn"
  top: "size064_064/rel/conv5_3/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_3"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_2"
  bottom: "size064_064/rel/conv5_3/x2"
  top: "size064_064/rel/concat_5_3"
}
layer {
  name: "size064_064/rel/conv5_4/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_3"
  top: "size064_064/rel/conv5_4/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_4/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_4/x1/bn"
  top: "size064_064/rel/conv5_4/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_4/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_4/x1/bn"
  top: "size064_064/rel/conv5_4/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_4/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_4/x1/bn"
  top: "size064_064/rel/conv5_4/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_4/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_4/x1"
  top: "size064_064/rel/conv5_4/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_4/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_4/x2/bn"
  top: "size064_064/rel/conv5_4/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_4/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_4/x2/bn"
  top: "size064_064/rel/conv5_4/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_4/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_4/x2/bn"
  top: "size064_064/rel/conv5_4/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_4"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_3"
  bottom: "size064_064/rel/conv5_4/x2"
  top: "size064_064/rel/concat_5_4"
}
layer {
  name: "size064_064/rel/conv5_5/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_4"
  top: "size064_064/rel/conv5_5/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_5/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_5/x1/bn"
  top: "size064_064/rel/conv5_5/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_5/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_5/x1/bn"
  top: "size064_064/rel/conv5_5/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_5/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_5/x1/bn"
  top: "size064_064/rel/conv5_5/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_5/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_5/x1"
  top: "size064_064/rel/conv5_5/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_5/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_5/x2/bn"
  top: "size064_064/rel/conv5_5/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_5/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_5/x2/bn"
  top: "size064_064/rel/conv5_5/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_5/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_5/x2/bn"
  top: "size064_064/rel/conv5_5/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_5"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_4"
  bottom: "size064_064/rel/conv5_5/x2"
  top: "size064_064/rel/concat_5_5"
}
layer {
  name: "size064_064/rel/conv5_6/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_5"
  top: "size064_064/rel/conv5_6/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_6/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_6/x1/bn"
  top: "size064_064/rel/conv5_6/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_6/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_6/x1/bn"
  top: "size064_064/rel/conv5_6/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_6/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_6/x1/bn"
  top: "size064_064/rel/conv5_6/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_6/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_6/x1"
  top: "size064_064/rel/conv5_6/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_6/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_6/x2/bn"
  top: "size064_064/rel/conv5_6/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_6/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_6/x2/bn"
  top: "size064_064/rel/conv5_6/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_6/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_6/x2/bn"
  top: "size064_064/rel/conv5_6/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_6"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_5"
  bottom: "size064_064/rel/conv5_6/x2"
  top: "size064_064/rel/concat_5_6"
}
layer {
  name: "size064_064/rel/conv5_7/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_6"
  top: "size064_064/rel/conv5_7/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_7/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_7/x1/bn"
  top: "size064_064/rel/conv5_7/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_7/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_7/x1/bn"
  top: "size064_064/rel/conv5_7/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_7/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_7/x1/bn"
  top: "size064_064/rel/conv5_7/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_7/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_7/x1"
  top: "size064_064/rel/conv5_7/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_7/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_7/x2/bn"
  top: "size064_064/rel/conv5_7/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_7/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_7/x2/bn"
  top: "size064_064/rel/conv5_7/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_7/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_7/x2/bn"
  top: "size064_064/rel/conv5_7/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_7"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_6"
  bottom: "size064_064/rel/conv5_7/x2"
  top: "size064_064/rel/concat_5_7"
}
layer {
  name: "size064_064/rel/conv5_8/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_7"
  top: "size064_064/rel/conv5_8/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_8/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_8/x1/bn"
  top: "size064_064/rel/conv5_8/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_8/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_8/x1/bn"
  top: "size064_064/rel/conv5_8/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_8/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_8/x1/bn"
  top: "size064_064/rel/conv5_8/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_8/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_8/x1"
  top: "size064_064/rel/conv5_8/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_8/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_8/x2/bn"
  top: "size064_064/rel/conv5_8/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_8/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_8/x2/bn"
  top: "size064_064/rel/conv5_8/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_8/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_8/x2/bn"
  top: "size064_064/rel/conv5_8/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_8"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_7"
  bottom: "size064_064/rel/conv5_8/x2"
  top: "size064_064/rel/concat_5_8"
}
layer {
  name: "size064_064/rel/conv5_9/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_8"
  top: "size064_064/rel/conv5_9/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_9/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_9/x1/bn"
  top: "size064_064/rel/conv5_9/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_9/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_9/x1/bn"
  top: "size064_064/rel/conv5_9/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_9/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_9/x1/bn"
  top: "size064_064/rel/conv5_9/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_9/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_9/x1"
  top: "size064_064/rel/conv5_9/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_9/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_9/x2/bn"
  top: "size064_064/rel/conv5_9/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_9/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_9/x2/bn"
  top: "size064_064/rel/conv5_9/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_9/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_9/x2/bn"
  top: "size064_064/rel/conv5_9/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_9"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_8"
  bottom: "size064_064/rel/conv5_9/x2"
  top: "size064_064/rel/concat_5_9"
}
layer {
  name: "size064_064/rel/conv5_10/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_9"
  top: "size064_064/rel/conv5_10/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_10/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_10/x1/bn"
  top: "size064_064/rel/conv5_10/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_10/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_10/x1/bn"
  top: "size064_064/rel/conv5_10/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_10/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_10/x1/bn"
  top: "size064_064/rel/conv5_10/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_10/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_10/x1"
  top: "size064_064/rel/conv5_10/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_10/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_10/x2/bn"
  top: "size064_064/rel/conv5_10/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_10/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_10/x2/bn"
  top: "size064_064/rel/conv5_10/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_10/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_10/x2/bn"
  top: "size064_064/rel/conv5_10/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_10"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_9"
  bottom: "size064_064/rel/conv5_10/x2"
  top: "size064_064/rel/concat_5_10"
}
layer {
  name: "size064_064/rel/conv5_11/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_10"
  top: "size064_064/rel/conv5_11/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_11/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_11/x1/bn"
  top: "size064_064/rel/conv5_11/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_11/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_11/x1/bn"
  top: "size064_064/rel/conv5_11/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_11/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_11/x1/bn"
  top: "size064_064/rel/conv5_11/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_11/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_11/x1"
  top: "size064_064/rel/conv5_11/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_11/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_11/x2/bn"
  top: "size064_064/rel/conv5_11/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_11/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_11/x2/bn"
  top: "size064_064/rel/conv5_11/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_11/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_11/x2/bn"
  top: "size064_064/rel/conv5_11/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_11"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_10"
  bottom: "size064_064/rel/conv5_11/x2"
  top: "size064_064/rel/concat_5_11"
}
layer {
  name: "size064_064/rel/conv5_12/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_11"
  top: "size064_064/rel/conv5_12/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_12/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_12/x1/bn"
  top: "size064_064/rel/conv5_12/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_12/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_12/x1/bn"
  top: "size064_064/rel/conv5_12/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_12/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_12/x1/bn"
  top: "size064_064/rel/conv5_12/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_12/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_12/x1"
  top: "size064_064/rel/conv5_12/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_12/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_12/x2/bn"
  top: "size064_064/rel/conv5_12/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_12/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_12/x2/bn"
  top: "size064_064/rel/conv5_12/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_12/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_12/x2/bn"
  top: "size064_064/rel/conv5_12/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_12"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_11"
  bottom: "size064_064/rel/conv5_12/x2"
  top: "size064_064/rel/concat_5_12"
}
layer {
  name: "size064_064/rel/conv5_13/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_12"
  top: "size064_064/rel/conv5_13/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_13/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_13/x1/bn"
  top: "size064_064/rel/conv5_13/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_13/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_13/x1/bn"
  top: "size064_064/rel/conv5_13/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_13/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_13/x1/bn"
  top: "size064_064/rel/conv5_13/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_13/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_13/x1"
  top: "size064_064/rel/conv5_13/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_13/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_13/x2/bn"
  top: "size064_064/rel/conv5_13/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_13/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_13/x2/bn"
  top: "size064_064/rel/conv5_13/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_13/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_13/x2/bn"
  top: "size064_064/rel/conv5_13/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_13"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_12"
  bottom: "size064_064/rel/conv5_13/x2"
  top: "size064_064/rel/concat_5_13"
}
layer {
  name: "size064_064/rel/conv5_14/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_13"
  top: "size064_064/rel/conv5_14/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_14/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_14/x1/bn"
  top: "size064_064/rel/conv5_14/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_14/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_14/x1/bn"
  top: "size064_064/rel/conv5_14/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_14/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_14/x1/bn"
  top: "size064_064/rel/conv5_14/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_14/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_14/x1"
  top: "size064_064/rel/conv5_14/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_14/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_14/x2/bn"
  top: "size064_064/rel/conv5_14/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_14/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_14/x2/bn"
  top: "size064_064/rel/conv5_14/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_14/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_14/x2/bn"
  top: "size064_064/rel/conv5_14/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_14"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_13"
  bottom: "size064_064/rel/conv5_14/x2"
  top: "size064_064/rel/concat_5_14"
}
layer {
  name: "size064_064/rel/conv5_15/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_14"
  top: "size064_064/rel/conv5_15/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_15/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_15/x1/bn"
  top: "size064_064/rel/conv5_15/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_15/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_15/x1/bn"
  top: "size064_064/rel/conv5_15/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_15/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_15/x1/bn"
  top: "size064_064/rel/conv5_15/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_15/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_15/x1"
  top: "size064_064/rel/conv5_15/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_15/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_15/x2/bn"
  top: "size064_064/rel/conv5_15/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_15/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_15/x2/bn"
  top: "size064_064/rel/conv5_15/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_15/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_15/x2/bn"
  top: "size064_064/rel/conv5_15/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_15"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_14"
  bottom: "size064_064/rel/conv5_15/x2"
  top: "size064_064/rel/concat_5_15"
}
layer {
  name: "size064_064/rel/conv5_16/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_15"
  top: "size064_064/rel/conv5_16/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_16/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_16/x1/bn"
  top: "size064_064/rel/conv5_16/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_16/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_16/x1/bn"
  top: "size064_064/rel/conv5_16/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_16/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_16/x1/bn"
  top: "size064_064/rel/conv5_16/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_16/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_16/x1"
  top: "size064_064/rel/conv5_16/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_16/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_16/x2/bn"
  top: "size064_064/rel/conv5_16/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_16/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_16/x2/bn"
  top: "size064_064/rel/conv5_16/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_16/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_16/x2/bn"
  top: "size064_064/rel/conv5_16/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_16"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_15"
  bottom: "size064_064/rel/conv5_16/x2"
  top: "size064_064/rel/concat_5_16"
}
layer {
  name: "size064_064/rel/conv5_17/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_16"
  top: "size064_064/rel/conv5_17/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_17/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_17/x1/bn"
  top: "size064_064/rel/conv5_17/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_17/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_17/x1/bn"
  top: "size064_064/rel/conv5_17/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_17/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_17/x1/bn"
  top: "size064_064/rel/conv5_17/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_17/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_17/x1"
  top: "size064_064/rel/conv5_17/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_17/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_17/x2/bn"
  top: "size064_064/rel/conv5_17/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_17/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_17/x2/bn"
  top: "size064_064/rel/conv5_17/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_17/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_17/x2/bn"
  top: "size064_064/rel/conv5_17/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_17"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_16"
  bottom: "size064_064/rel/conv5_17/x2"
  top: "size064_064/rel/concat_5_17"
}
layer {
  name: "size064_064/rel/conv5_18/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_17"
  top: "size064_064/rel/conv5_18/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_18/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_18/x1/bn"
  top: "size064_064/rel/conv5_18/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_18/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_18/x1/bn"
  top: "size064_064/rel/conv5_18/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_18/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_18/x1/bn"
  top: "size064_064/rel/conv5_18/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_18/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_18/x1"
  top: "size064_064/rel/conv5_18/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_18/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_18/x2/bn"
  top: "size064_064/rel/conv5_18/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_18/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_18/x2/bn"
  top: "size064_064/rel/conv5_18/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_18/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_18/x2/bn"
  top: "size064_064/rel/conv5_18/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_18"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_17"
  bottom: "size064_064/rel/conv5_18/x2"
  top: "size064_064/rel/concat_5_18"
}
layer {
  name: "size064_064/rel/conv5_19/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_18"
  top: "size064_064/rel/conv5_19/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_19/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_19/x1/bn"
  top: "size064_064/rel/conv5_19/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_19/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_19/x1/bn"
  top: "size064_064/rel/conv5_19/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_19/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_19/x1/bn"
  top: "size064_064/rel/conv5_19/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_19/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_19/x1"
  top: "size064_064/rel/conv5_19/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_19/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_19/x2/bn"
  top: "size064_064/rel/conv5_19/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_19/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_19/x2/bn"
  top: "size064_064/rel/conv5_19/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_19/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_19/x2/bn"
  top: "size064_064/rel/conv5_19/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_19"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_18"
  bottom: "size064_064/rel/conv5_19/x2"
  top: "size064_064/rel/concat_5_19"
}
layer {
  name: "size064_064/rel/conv5_20/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_19"
  top: "size064_064/rel/conv5_20/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_20/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_20/x1/bn"
  top: "size064_064/rel/conv5_20/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_20/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_20/x1/bn"
  top: "size064_064/rel/conv5_20/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_20/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_20/x1/bn"
  top: "size064_064/rel/conv5_20/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_20/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_20/x1"
  top: "size064_064/rel/conv5_20/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_20/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_20/x2/bn"
  top: "size064_064/rel/conv5_20/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_20/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_20/x2/bn"
  top: "size064_064/rel/conv5_20/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_20/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_20/x2/bn"
  top: "size064_064/rel/conv5_20/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_20"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_19"
  bottom: "size064_064/rel/conv5_20/x2"
  top: "size064_064/rel/concat_5_20"
}
layer {
  name: "size064_064/rel/conv5_21/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_20"
  top: "size064_064/rel/conv5_21/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_21/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_21/x1/bn"
  top: "size064_064/rel/conv5_21/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_21/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_21/x1/bn"
  top: "size064_064/rel/conv5_21/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_21/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_21/x1/bn"
  top: "size064_064/rel/conv5_21/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_21/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_21/x1"
  top: "size064_064/rel/conv5_21/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_21/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_21/x2/bn"
  top: "size064_064/rel/conv5_21/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_21/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_21/x2/bn"
  top: "size064_064/rel/conv5_21/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_21/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_21/x2/bn"
  top: "size064_064/rel/conv5_21/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_21"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_20"
  bottom: "size064_064/rel/conv5_21/x2"
  top: "size064_064/rel/concat_5_21"
}
layer {
  name: "size064_064/rel/conv5_22/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_21"
  top: "size064_064/rel/conv5_22/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_22/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_22/x1/bn"
  top: "size064_064/rel/conv5_22/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_22/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_22/x1/bn"
  top: "size064_064/rel/conv5_22/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_22/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_22/x1/bn"
  top: "size064_064/rel/conv5_22/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_22/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_22/x1"
  top: "size064_064/rel/conv5_22/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_22/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_22/x2/bn"
  top: "size064_064/rel/conv5_22/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_22/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_22/x2/bn"
  top: "size064_064/rel/conv5_22/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_22/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_22/x2/bn"
  top: "size064_064/rel/conv5_22/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_22"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_21"
  bottom: "size064_064/rel/conv5_22/x2"
  top: "size064_064/rel/concat_5_22"
}
layer {
  name: "size064_064/rel/conv5_23/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_22"
  top: "size064_064/rel/conv5_23/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_23/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_23/x1/bn"
  top: "size064_064/rel/conv5_23/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_23/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_23/x1/bn"
  top: "size064_064/rel/conv5_23/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_23/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_23/x1/bn"
  top: "size064_064/rel/conv5_23/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_23/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_23/x1"
  top: "size064_064/rel/conv5_23/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_23/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_23/x2/bn"
  top: "size064_064/rel/conv5_23/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_23/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_23/x2/bn"
  top: "size064_064/rel/conv5_23/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_23/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_23/x2/bn"
  top: "size064_064/rel/conv5_23/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_23"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_22"
  bottom: "size064_064/rel/conv5_23/x2"
  top: "size064_064/rel/concat_5_23"
}
layer {
  name: "size064_064/rel/conv5_24/x1/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_23"
  top: "size064_064/rel/conv5_24/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_24/x1/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_24/x1/bn"
  top: "size064_064/rel/conv5_24/x1/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_24/x1"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_24/x1/bn"
  top: "size064_064/rel/conv5_24/x1/bn"
}
layer {
  name: "size064_064/rel/conv5_24/x1"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_24/x1/bn"
  top: "size064_064/rel/conv5_24/x1"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 192
    bias_term: false
    kernel_size: 1
  }
}
layer {
  name: "size064_064/rel/conv5_24/x2/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/conv5_24/x1"
  top: "size064_064/rel/conv5_24/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_24/x2/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_24/x2/bn"
  top: "size064_064/rel/conv5_24/x2/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_24/x2"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_24/x2/bn"
  top: "size064_064/rel/conv5_24/x2/bn"
}
layer {
  name: "size064_064/rel/conv5_24/x2"
  type: "Convolution"
  bottom: "size064_064/rel/conv5_24/x2/bn"
  top: "size064_064/rel/conv5_24/x2"
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "size064_064/rel/concat_5_24"
  type: "Concat"
  bottom: "size064_064/rel/concat_5_23"
  bottom: "size064_064/rel/conv5_24/x2"
  top: "size064_064/rel/concat_5_24"
}
layer {
  name: "size064_064/rel/conv5_blk/bn"
  type: "BatchNorm"
  bottom: "size064_064/rel/concat_5_24"
  top: "size064_064/rel/conv5_blk/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  batch_norm_param {
    eps: 1e-5
  }
}
layer {
  name: "size064_064/rel/conv5_blk/scale"
  type: "Scale"
  bottom: "size064_064/rel/conv5_blk/bn"
  top: "size064_064/rel/conv5_blk/bn"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "size064_064/rel/relu5_blk"
  type: "ReLU"
  bottom: "size064_064/rel/conv5_blk/bn"
  top: "size064_064/rel/conv5_blk/bn"
}

###########################################################################
# size 2x  Inception
###########################################################################
layer {
    bottom: "size064_064/rel/conv5_blk/bn"
    top:    "size064_064/rel/x2_deconv"
    name:   "size064_064/rel/x2_deconv"
    type:   "Deconvolution" 
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 1664
        kernel_size: 4
        stride: 2
        pad: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}


# branch1
layer {
    bottom: "size064_064/rel/x2_deconv"
    top:    "size064_064/rel/x2_branch1_conv1"
    name:   "size064_064/rel/x2_branch1_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x2_branch1_conv1" top: "size064_064/rel/x2_branch1_conv1" name: "size064_064/rel/x2_branch1_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x2_branch1_conv1" top: "size064_064/rel/x2_branch1_conv1" name: "size064_064/rel/x2_branch1_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x2_branch1_conv1" top: "size064_064/rel/x2_branch1_conv1" name: "size064_064/rel/x2_branch1_relu1" type: "ReLU" }
# branch2
layer {
    bottom: "size064_064/rel/x2_deconv"
    top:    "size064_064/rel/x2_branch2_conv1"
    name:   "size064_064/rel/x2_branch2_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x2_branch2_conv1" top: "size064_064/rel/x2_branch2_conv1" name: "size064_064/rel/x2_branch2_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x2_branch2_conv1" top: "size064_064/rel/x2_branch2_conv1" name: "size064_064/rel/x2_branch2_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x2_branch2_conv1" top: "size064_064/rel/x2_branch2_conv1" name: "size064_064/rel/x2_branch2_relu1" type: "ReLU" }
layer {
    bottom: "size064_064/rel/x2_branch2_conv1"
    top:    "size064_064/rel/x2_branch2_conv2"
    name:   "size064_064/rel/x2_branch2_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x2_branch2_conv2" top: "size064_064/rel/x2_branch2_conv2" name: "size064_064/rel/x2_branch2_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x2_branch2_conv2" top: "size064_064/rel/x2_branch2_conv2" name: "size064_064/rel/x2_branch2_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x2_branch2_conv2" top: "size064_064/rel/x2_branch2_conv2" name: "size064_064/rel/x2_branch2_relu2" type: "ReLU" }
# branch3
layer {
    bottom: "size064_064/rel/x2_deconv"
    top:    "size064_064/rel/x2_branch3_conv1"
    name:   "size064_064/rel/x2_branch3_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x2_branch3_conv1" top: "size064_064/rel/x2_branch3_conv1" name: "size064_064/rel/x2_branch3_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x2_branch3_conv1" top: "size064_064/rel/x2_branch3_conv1" name: "size064_064/rel/x2_branch3_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x2_branch3_conv1" top: "size064_064/rel/x2_branch3_conv1" name: "size064_064/rel/x2_branch3_relu1" type: "ReLU" }
layer {
    bottom: "size064_064/rel/x2_branch3_conv1"
    top:    "size064_064/rel/x2_branch3_conv2"
    name:   "size064_064/rel/x2_branch3_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 5
        pad: 2
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x2_branch3_conv2" top: "size064_064/rel/x2_branch3_conv2" name: "size064_064/rel/x2_branch3_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x2_branch3_conv2" top: "size064_064/rel/x2_branch3_conv2" name: "size064_064/rel/x2_branch3_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x2_branch3_conv2" top: "size064_064/rel/x2_branch3_conv2" name: "size064_064/rel/x2_branch3_relu2" type: "ReLU" }
 
# branch5
layer {
    bottom: "size064_064/rel/x2_deconv"
    top:    "size064_064/rel/x2_branch5_conv1"
    name:   "size064_064/rel/x2_branch5_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x2_branch5_conv1" top: "size064_064/rel/x2_branch5_conv1" name: "size064_064/rel/x2_branch5_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x2_branch5_conv1" top: "size064_064/rel/x2_branch5_conv1" name: "size064_064/rel/x2_branch5_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x2_branch5_conv1" top: "size064_064/rel/x2_branch5_conv1" name: "size064_064/rel/x2_branch5_relu1" type: "ReLU" }

layer {
    bottom: "size064_064/rel/x2_branch5_conv1"
    top:    "size064_064/rel/x2_branch5_conv2"
    name:   "size064_064/rel/x2_branch5_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_w: 16
        kernel_h: 3
        pad_h: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x2_branch5_conv2" top: "size064_064/rel/x2_branch5_conv2" name: "size064_064/rel/x2_branch5_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x2_branch5_conv2" top: "size064_064/rel/x2_branch5_conv2" name: "size064_064/rel/x2_branch5_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x2_branch5_conv2" top: "size064_064/rel/x2_branch5_conv2" name: "size064_064/rel/x2_branch5_relu2" type: "ReLU" }
layer{ bottom: "size064_064/rel/x2_branch5_conv2" top: "size064_064/rel/x2_branch5_tile"  name: "size064_064/rel/x2_branch5_tile"  type: "Tile" tile_param { axis: 3 tiles: 16 } }


# branch6
layer {
    bottom: "size064_064/rel/x2_deconv"
    top:    "size064_064/rel/x2_branch6_conv1"
    name:   "size064_064/rel/x2_branch6_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x2_branch6_conv1" top: "size064_064/rel/x2_branch6_conv1" name: "size064_064/rel/x2_branch6_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x2_branch6_conv1" top: "size064_064/rel/x2_branch6_conv1" name: "size064_064/rel/x2_branch6_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x2_branch6_conv1" top: "size064_064/rel/x2_branch6_conv1" name: "size064_064/rel/x2_branch6_relu1" type: "ReLU" }
layer {
    bottom: "size064_064/rel/x2_branch6_conv1"
    top:    "size064_064/rel/x2_branch6_conv2"
    name:   "size064_064/rel/x2_branch6_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_w: 3
        kernel_h: 16
        pad_w: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x2_branch6_conv2" top: "size064_064/rel/x2_branch6_conv2" name: "size064_064/rel/x2_branch6_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x2_branch6_conv2" top: "size064_064/rel/x2_branch6_conv2" name: "size064_064/rel/x2_branch6_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x2_branch6_conv2" top: "size064_064/rel/x2_branch6_conv2" name: "size064_064/rel/x2_branch6_relu2" type: "ReLU" }
layer{ bottom: "size064_064/rel/x2_branch6_conv2" top: "size064_064/rel/x2_branch6_tile"  name: "size064_064/rel/x2_branch6_tile"  type: "Tile" tile_param { axis: 2 tiles: 16 } }

# Concat
layer {
    bottom: "size064_064/rel/x2_branch1_conv1"
    bottom: "size064_064/rel/x2_branch2_conv2"
    bottom: "size064_064/rel/x2_branch3_conv2" 
    bottom: "size064_064/rel/x2_branch5_tile"
    bottom: "size064_064/rel/x2_branch6_tile"
    top:    "size064_064/rel/x2_concat"
    name:   "size064_064/rel/x2_concat"
    type:   "Concat"
    concat_param {
        axis:1
    }
}

###########################################################################
# size 4x  Inception
###########################################################################
layer {
    bottom: "size064_064/rel/x2_concat"
    top:    "size064_064/rel/x4_deconv"
    name:   "size064_064/rel/x4_deconv"
    type:   "Deconvolution" 
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 832
        kernel_size: 4
        stride: 2
        pad: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}


# branch1
layer {
    bottom: "size064_064/rel/x4_deconv"
    top:    "size064_064/rel/x4_branch1_conv1"
    name:   "size064_064/rel/x4_branch1_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x4_branch1_conv1" top: "size064_064/rel/x4_branch1_conv1" name: "size064_064/rel/x4_branch1_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x4_branch1_conv1" top: "size064_064/rel/x4_branch1_conv1" name: "size064_064/rel/x4_branch1_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x4_branch1_conv1" top: "size064_064/rel/x4_branch1_conv1" name: "size064_064/rel/x4_branch1_relu1" type: "ReLU" }
# branch2
layer {
    bottom: "size064_064/rel/x4_deconv"
    top:    "size064_064/rel/x4_branch2_conv1"
    name:   "size064_064/rel/x4_branch2_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x4_branch2_conv1" top: "size064_064/rel/x4_branch2_conv1" name: "size064_064/rel/x4_branch2_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x4_branch2_conv1" top: "size064_064/rel/x4_branch2_conv1" name: "size064_064/rel/x4_branch2_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x4_branch2_conv1" top: "size064_064/rel/x4_branch2_conv1" name: "size064_064/rel/x4_branch2_relu1" type: "ReLU" }
layer {
    bottom: "size064_064/rel/x4_branch2_conv1"
    top:    "size064_064/rel/x4_branch2_conv2"
    name:   "size064_064/rel/x4_branch2_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x4_branch2_conv2" top: "size064_064/rel/x4_branch2_conv2" name: "size064_064/rel/x4_branch2_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x4_branch2_conv2" top: "size064_064/rel/x4_branch2_conv2" name: "size064_064/rel/x4_branch2_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x4_branch2_conv2" top: "size064_064/rel/x4_branch2_conv2" name: "size064_064/rel/x4_branch2_relu2" type: "ReLU" }
# branch3
layer {
    bottom: "size064_064/rel/x4_deconv"
    top:    "size064_064/rel/x4_branch3_conv1"
    name:   "size064_064/rel/x4_branch3_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x4_branch3_conv1" top: "size064_064/rel/x4_branch3_conv1" name: "size064_064/rel/x4_branch3_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x4_branch3_conv1" top: "size064_064/rel/x4_branch3_conv1" name: "size064_064/rel/x4_branch3_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x4_branch3_conv1" top: "size064_064/rel/x4_branch3_conv1" name: "size064_064/rel/x4_branch3_relu1" type: "ReLU" }
layer {
    bottom: "size064_064/rel/x4_branch3_conv1"
    top:    "size064_064/rel/x4_branch3_conv2"
    name:   "size064_064/rel/x4_branch3_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 208
        kernel_size: 5
        pad: 2
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x4_branch3_conv2" top: "size064_064/rel/x4_branch3_conv2" name: "size064_064/rel/x4_branch3_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x4_branch3_conv2" top: "size064_064/rel/x4_branch3_conv2" name: "size064_064/rel/x4_branch3_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x4_branch3_conv2" top: "size064_064/rel/x4_branch3_conv2" name: "size064_064/rel/x4_branch3_relu2" type: "ReLU" }
 
# branch5
layer {
    bottom: "size064_064/rel/x4_deconv"
    top:    "size064_064/rel/x4_branch5_conv1"
    name:   "size064_064/rel/x4_branch5_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x4_branch5_conv1" top: "size064_064/rel/x4_branch5_conv1" name: "size064_064/rel/x4_branch5_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x4_branch5_conv1" top: "size064_064/rel/x4_branch5_conv1" name: "size064_064/rel/x4_branch5_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x4_branch5_conv1" top: "size064_064/rel/x4_branch5_conv1" name: "size064_064/rel/x4_branch5_relu1" type: "ReLU" }

layer {
    bottom: "size064_064/rel/x4_branch5_conv1"
    top:    "size064_064/rel/x4_branch5_conv2"
    name:   "size064_064/rel/x4_branch5_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_w: 32
        kernel_h: 3
        pad_h: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x4_branch5_conv2" top: "size064_064/rel/x4_branch5_conv2" name: "size064_064/rel/x4_branch5_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x4_branch5_conv2" top: "size064_064/rel/x4_branch5_conv2" name: "size064_064/rel/x4_branch5_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x4_branch5_conv2" top: "size064_064/rel/x4_branch5_conv2" name: "size064_064/rel/x4_branch5_relu2" type: "ReLU" }
layer{ bottom: "size064_064/rel/x4_branch5_conv2" top: "size064_064/rel/x4_branch5_tile"  name: "size064_064/rel/x4_branch5_tile"  type: "Tile" tile_param { axis: 3 tiles: 32 } }


# branch6
layer {
    bottom: "size064_064/rel/x4_deconv"
    top:    "size064_064/rel/x4_branch6_conv1"
    name:   "size064_064/rel/x4_branch6_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x4_branch6_conv1" top: "size064_064/rel/x4_branch6_conv1" name: "size064_064/rel/x4_branch6_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x4_branch6_conv1" top: "size064_064/rel/x4_branch6_conv1" name: "size064_064/rel/x4_branch6_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x4_branch6_conv1" top: "size064_064/rel/x4_branch6_conv1" name: "size064_064/rel/x4_branch6_relu1" type: "ReLU" }
layer {
    bottom: "size064_064/rel/x4_branch6_conv1"
    top:    "size064_064/rel/x4_branch6_conv2"
    name:   "size064_064/rel/x4_branch6_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_w: 3
        kernel_h: 32
        pad_w: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x4_branch6_conv2" top: "size064_064/rel/x4_branch6_conv2" name: "size064_064/rel/x4_branch6_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x4_branch6_conv2" top: "size064_064/rel/x4_branch6_conv2" name: "size064_064/rel/x4_branch6_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x4_branch6_conv2" top: "size064_064/rel/x4_branch6_conv2" name: "size064_064/rel/x4_branch6_relu2" type: "ReLU" }
layer{ bottom: "size064_064/rel/x4_branch6_conv2" top: "size064_064/rel/x4_branch6_tile"  name: "size064_064/rel/x4_branch6_tile"  type: "Tile" tile_param { axis: 2 tiles: 32 } }

# Concat
layer {
    bottom: "size064_064/rel/x4_branch1_conv1"
    bottom: "size064_064/rel/x4_branch2_conv2"
    bottom: "size064_064/rel/x4_branch3_conv2" 
    bottom: "size064_064/rel/x4_branch5_tile"
    bottom: "size064_064/rel/x4_branch6_tile"
    top:    "size064_064/rel/x4_concat"
    name:   "size064_064/rel/x4_concat"
    type:   "Concat"
    concat_param {
        axis:1
    }
}

###########################################################################
# size 8x  Inception
###########################################################################
layer {
    bottom: "size064_064/rel/x4_concat"
    top:    "size064_064/rel/x8_deconv"
    name:   "size064_064/rel/x8_deconv"
    type:   "Deconvolution" 
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 416
        kernel_size: 4
        stride: 2
        pad: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}


# branch1
layer {
    bottom: "size064_064/rel/x8_deconv"
    top:    "size064_064/rel/x8_branch1_conv1"
    name:   "size064_064/rel/x8_branch1_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x8_branch1_conv1" top: "size064_064/rel/x8_branch1_conv1" name: "size064_064/rel/x8_branch1_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x8_branch1_conv1" top: "size064_064/rel/x8_branch1_conv1" name: "size064_064/rel/x8_branch1_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x8_branch1_conv1" top: "size064_064/rel/x8_branch1_conv1" name: "size064_064/rel/x8_branch1_relu1" type: "ReLU" }
# branch2
layer {
    bottom: "size064_064/rel/x8_deconv"
    top:    "size064_064/rel/x8_branch2_conv1"
    name:   "size064_064/rel/x8_branch2_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x8_branch2_conv1" top: "size064_064/rel/x8_branch2_conv1" name: "size064_064/rel/x8_branch2_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x8_branch2_conv1" top: "size064_064/rel/x8_branch2_conv1" name: "size064_064/rel/x8_branch2_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x8_branch2_conv1" top: "size064_064/rel/x8_branch2_conv1" name: "size064_064/rel/x8_branch2_relu1" type: "ReLU" }
layer {
    bottom: "size064_064/rel/x8_branch2_conv1"
    top:    "size064_064/rel/x8_branch2_conv2"
    name:   "size064_064/rel/x8_branch2_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x8_branch2_conv2" top: "size064_064/rel/x8_branch2_conv2" name: "size064_064/rel/x8_branch2_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x8_branch2_conv2" top: "size064_064/rel/x8_branch2_conv2" name: "size064_064/rel/x8_branch2_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x8_branch2_conv2" top: "size064_064/rel/x8_branch2_conv2" name: "size064_064/rel/x8_branch2_relu2" type: "ReLU" }
# branch3
layer {
    bottom: "size064_064/rel/x8_deconv"
    top:    "size064_064/rel/x8_branch3_conv1"
    name:   "size064_064/rel/x8_branch3_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x8_branch3_conv1" top: "size064_064/rel/x8_branch3_conv1" name: "size064_064/rel/x8_branch3_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x8_branch3_conv1" top: "size064_064/rel/x8_branch3_conv1" name: "size064_064/rel/x8_branch3_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x8_branch3_conv1" top: "size064_064/rel/x8_branch3_conv1" name: "size064_064/rel/x8_branch3_relu1" type: "ReLU" }
layer {
    bottom: "size064_064/rel/x8_branch3_conv1"
    top:    "size064_064/rel/x8_branch3_conv2"
    name:   "size064_064/rel/x8_branch3_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 104
        kernel_size: 5
        pad: 2
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x8_branch3_conv2" top: "size064_064/rel/x8_branch3_conv2" name: "size064_064/rel/x8_branch3_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x8_branch3_conv2" top: "size064_064/rel/x8_branch3_conv2" name: "size064_064/rel/x8_branch3_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x8_branch3_conv2" top: "size064_064/rel/x8_branch3_conv2" name: "size064_064/rel/x8_branch3_relu2" type: "ReLU" }
 
# branch5
layer {
    bottom: "size064_064/rel/x8_deconv"
    top:    "size064_064/rel/x8_branch5_conv1"
    name:   "size064_064/rel/x8_branch5_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 52
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x8_branch5_conv1" top: "size064_064/rel/x8_branch5_conv1" name: "size064_064/rel/x8_branch5_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x8_branch5_conv1" top: "size064_064/rel/x8_branch5_conv1" name: "size064_064/rel/x8_branch5_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x8_branch5_conv1" top: "size064_064/rel/x8_branch5_conv1" name: "size064_064/rel/x8_branch5_relu1" type: "ReLU" }

layer {
    bottom: "size064_064/rel/x8_branch5_conv1"
    top:    "size064_064/rel/x8_branch5_conv2"
    name:   "size064_064/rel/x8_branch5_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 52
        kernel_w: 64
        kernel_h: 3
        pad_h: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x8_branch5_conv2" top: "size064_064/rel/x8_branch5_conv2" name: "size064_064/rel/x8_branch5_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x8_branch5_conv2" top: "size064_064/rel/x8_branch5_conv2" name: "size064_064/rel/x8_branch5_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x8_branch5_conv2" top: "size064_064/rel/x8_branch5_conv2" name: "size064_064/rel/x8_branch5_relu2" type: "ReLU" }
layer{ bottom: "size064_064/rel/x8_branch5_conv2" top: "size064_064/rel/x8_branch5_tile"  name: "size064_064/rel/x8_branch5_tile"  type: "Tile" tile_param { axis: 3 tiles: 64 } }


# branch6
layer {
    bottom: "size064_064/rel/x8_deconv"
    top:    "size064_064/rel/x8_branch6_conv1"
    name:   "size064_064/rel/x8_branch6_conv1"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 52
        kernel_size: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x8_branch6_conv1" top: "size064_064/rel/x8_branch6_conv1" name: "size064_064/rel/x8_branch6_bn1" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x8_branch6_conv1" top: "size064_064/rel/x8_branch6_conv1" name: "size064_064/rel/x8_branch6_sc1" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x8_branch6_conv1" top: "size064_064/rel/x8_branch6_conv1" name: "size064_064/rel/x8_branch6_relu1" type: "ReLU" }
layer {
    bottom: "size064_064/rel/x8_branch6_conv1"
    top:    "size064_064/rel/x8_branch6_conv2"
    name:   "size064_064/rel/x8_branch6_conv2"
    type:   "Convolution"
    param { lr_mult : 1.0000 }
    param { lr_mult : 1.0000 }
    convolution_param {
        num_output: 52
        kernel_w: 3
        kernel_h: 64
        pad_w: 1
        stride: 1
        weight_filler{ type: "msra" }
        bias_filler{ type: "constant" value:0 }
    }
}
layer{ bottom: "size064_064/rel/x8_branch6_conv2" top: "size064_064/rel/x8_branch6_conv2" name: "size064_064/rel/x8_branch6_bn2" type: "BatchNorm" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } }
layer{ bottom: "size064_064/rel/x8_branch6_conv2" top: "size064_064/rel/x8_branch6_conv2" name: "size064_064/rel/x8_branch6_sc2" type: "Scale" param { lr_mult : 1.0000 } param { lr_mult : 1.0000 } scale_param{ bias_term: true} }
layer{ bottom: "size064_064/rel/x8_branch6_conv2" top: "size064_064/rel/x8_branch6_conv2" name: "size064_064/rel/x8_branch6_relu2" type: "ReLU" }
layer{ bottom: "size064_064/rel/x8_branch6_conv2" top: "size064_064/rel/x8_branch6_tile"  name: "size064_064/rel/x8_branch6_tile"  type: "Tile" tile_param { axis: 2 tiles: 64 } }

# Concat
layer {
    bottom: "size064_064/rel/x8_branch1_conv1"
    bottom: "size064_064/rel/x8_branch2_conv2"
    bottom: "size064_064/rel/x8_branch3_conv2" 
    bottom: "size064_064/rel/x8_branch5_tile"
    bottom: "size064_064/rel/x8_branch6_tile"
    top:    "size064_064/rel/x8_concat"
    name:   "size064_064/rel/x8_concat"
    type:   "Concat"
    concat_param {
        axis:1
    }
}

#################################################
##### Part004 loss at size064_064/rel/conv5 #####
#################################################
layer {
  name: "DenseNet16527or/pred_2D_064_064_ch1000_true"
  type: "Convolution"
  bottom: "size064_064/rel/x8_concat"
  top: "DenseNet16527or/pred_2D_064_064_ch1000_true"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler{
      type: "xavier"
    }
  }
  
}

layer {
  name: "DenseNet16527or/pred_2D_064_064_ch1000_false"
  type: "Convolution"
  bottom: "size064_064/rel/x8_concat"
  top: "DenseNet16527or/pred_2D_064_064_ch1000_false"
  param { lr_mult : 1.0000 }
  param { lr_mult : 1.0000 }
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler{
      type: "xavier"
    }
  }
}

layer {
  bottom: "DenseNet16527or/pred_2D_064_064_ch1000_true"
  bottom: "DenseNet16527or/pred_2D_064_064_ch1000_false"
  top: "DenseNet16527or/pred_2D_064_064_ch1000_true_false_gap"
  name: "DenseNet16527or/pred_2D_064_064_ch1000_true_false_gap"
  type: "Eltwise"
  eltwise_param {
        operation: 1 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
        coeff: 1
        coeff: -1
  }
}

layer {
  name: "DenseNet16527or/pred_2D_064_064_ch1000"
  type: "Sigmoid"
  bottom: "DenseNet16527or/pred_2D_064_064_ch1000_true_false_gap"
  top: "DenseNet16527or/pred_2D_064_064_ch1000"
}

layer {
    name: "DenseNet16527or/pred_2D_064_064_ch1000_norm"
    bottom: "DenseNet16527or/pred_2D_064_064_ch1000"
    top: "DenseNet16527or/pred_2D_064_064_ch1000_norm"
    type: "Power"
    power_param {
        power: 1
        scale: 0.999990
        shift: 0.000005
    }
}

layer {
    name: "DenseNet16527or/pred_2D_064_064_ch1000_norm_inverse"
    bottom: "DenseNet16527or/pred_2D_064_064_ch1000_norm"
    top: "DenseNet16527or/pred_2D_064_064_ch1000_norm_inverse"
    type: "Power"
    power_param {
        power: 1
        scale: -1
        shift: 1
    }
}

layer {
    name: "DenseNet16527or/pred_2D_064_064_ch1000_log"
    bottom: "DenseNet16527or/pred_2D_064_064_ch1000_norm"
    top: "DenseNet16527or/pred_2D_064_064_ch1000_log"
    type: "Log"
    log_param {
        base: -1 # default(=-1) -> base is set to e
        scale: 1
        shift: 0
    }
}

layer {
    name: "DenseNet16527or/pred_2D_064_064_ch1000_inverse_log"
    bottom: "DenseNet16527or/pred_2D_064_064_ch1000_norm_inverse"
    top: "DenseNet16527or/pred_2D_064_064_ch1000_inverse_log"
    type: "Log"
    log_param {
        base: -1 # default(=-1) -> base is set to e
        scale: 1
        shift: 0
    }
}

layer {
  bottom: "DenseNet16527or/pred_2D_064_064_ch1000_log"
  bottom: "label_064_064_ch1000"
  top: "DenseNet16527or/loss_2D_064_064_ch1000_true"
  name: "DenseNet16527or/loss_2D_064_064_ch1000_true"
  type: "Eltwise" # Eltwise(PROD)
  eltwise_param {
        operation: 0 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
  }
}

layer {
  bottom: "DenseNet16527or/pred_2D_064_064_ch1000_inverse_log"
  bottom: "label_064_064_ch1000_inverse"
  top: "DenseNet16527or/loss_2D_064_064_ch1000_false"
  name: "DenseNet16527or/loss_2D_064_064_ch1000_false"
  type: "Eltwise" # Eltwise(PROD)
  eltwise_param {
        operation: 0 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
  }
}

layer {
  bottom: "DenseNet16527or/loss_2D_064_064_ch1000_true"
  bottom: "DenseNet16527or/loss_2D_064_064_ch1000_false"
  top: "DenseNet16527or/loss_2D_064_064_ch1000"
  name: "DenseNet16527or/loss_2D_064_064_ch1000"
  type: "Eltwise"
  eltwise_param {
        operation: 1 # 0:PROD, 1:SUM, 2:MAX (default:SUM)
        coeff: -1
        coeff: -1
  }
}

layer {
    name: "DenseNet16527or/loss_2D_064_064_ch1000_size_norm"
    bottom: "DenseNet16527or/loss_2D_064_064_ch1000"
    top: "DenseNet16527or/loss_2D_064_064_ch1000_size_norm"
    type: "Power"
    power_param {
        power: 1
        scale: 0.00024414 # output 1/(H x W) = 1/(64 x 64) = 0.00024414
        shift: 0
    }
}

layer { ## Requires user to set loss scale (For setting lr at each epoch)
  name: "DenseNet16527or/loss_2D_064_064_ch1000_multiplication"
  type: "Scale"
  bottom: "DenseNet16527or/loss_2D_064_064_ch1000_size_norm"
  top: "DenseNet16527or/loss_2D_064_064_ch1000_multiplication"
  param { lr_mult: 0 decay_mult: 0 }
  scale_param {
    bias_term: false
  }
}

layer {
    bottom: "DenseNet16527or/loss_2D_064_064_ch1000_multiplication"
    top: "DenseNet16527or/loss_2D_064_064_ch1000_sum"
    name: "DenseNet16527or/loss_2D_064_064_ch1000_sum"
    type:"Reduction"
    
    loss_weight: 1
}

